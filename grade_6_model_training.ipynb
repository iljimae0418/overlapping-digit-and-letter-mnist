{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# environment: Paperspace Quadro P6000 GPU  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras # run pip install keras==2.3 beforehand for compatability \n",
    "from tensorflow.keras import Input, Model \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import random \n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import shuffle # shuffle dataset before splitting into folds \n",
    "from scipy.ndimage.filters import gaussian_filter # for elastic distortion \n",
    "from scipy.ndimage.interpolation import map_coordinates # for elastic distortion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in file and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './storage/modified_mnist_dataset/train.csv'  \n",
    "test_path = './storage/modified_mnist_dataset/test.csv' \n",
    "submission_path = './storage/modified_mnist_dataset/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path) \n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types of digit and letter columns to categorical \n",
    "train.iloc[:,1] = pd.Categorical(train.iloc[:,1])\n",
    "train.iloc[:,2] = pd.Categorical(train.iloc[:,2]) \n",
    "test.iloc[:,1] = pd.Categorical(test.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types of digit and letter columns to categorical \n",
    "train.iloc[:,1] = pd.Categorical(train.iloc[:,1])\n",
    "train.iloc[:,2] = pd.Categorical(train.iloc[:,2]) \n",
    "test.iloc[:,1] = pd.Categorical(test.iloc[:,1])\n",
    "\n",
    "# define and re-format train and test data \n",
    "x_train = train.iloc[:,3:].values.reshape(-1,28,28,1).astype(np.float32) \n",
    "y_train = train.iloc[:,1].values\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "train_letters = train.iloc[:,2].values\n",
    "\n",
    "x_test = test.iloc[:,2:].values.reshape(-1,28,28,1).astype(np.float32)  \n",
    "test_letters = test.iloc[:,1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 28, 28, 1), (2048, 10), (20480, 28, 28, 1), (2048, 26), (20480, 26))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letters_numeric = [] \n",
    "test_letters_numeric = [] \n",
    "for letter in train_letters: \n",
    "    train_letters_numeric.append(ord(letter) - ord(\"A\"))\n",
    "for letter in test_letters: \n",
    "    test_letters_numeric.append(ord(letter) - ord(\"A\")) \n",
    "    \n",
    "train_letters_numeric = np.asarray(train_letters_numeric) \n",
    "test_letters_numeric = np.asarray(test_letters_numeric) \n",
    "\n",
    "train_letters_numeric = to_categorical(train_letters_numeric, num_classes = 26) \n",
    "test_letters_numeric = to_categorical(test_letters_numeric, num_classes = 26)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, train_letters_numeric.shape, test_letters_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max scaling \n",
    "x_train /= 255.0 \n",
    "x_test /= 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data\n",
    "\n",
    "For now, we will try augmenting the data using the following methods \n",
    "- rotation \n",
    "- adding noise  \n",
    "- adding gaussian blur \n",
    "- shifting image \n",
    "\n",
    "Please refer to [this notebook](https://github.com/iljimae0418/overlapping-digit-and-letter-mnist/blob/master/Examples%20of%20data%20augmentations.ipynb) for examples.  \n",
    "\n",
    "Some more augmentations were decided to be added. They are \n",
    "- modifying brightness \n",
    "- ZCA Whitening \n",
    "- random crops\n",
    "- elastic distortions\n",
    "- Autoencoder generated images \n",
    "\n",
    "some more augmentations that are being planned are \n",
    "- GAN generated images\n",
    "\n",
    "Please refer to [this notebook](https://github.com/iljimae0418/overlapping-digit-and-letter-mnist/blob/master/Examples%20of%20augmentation%202%20(further%20augmentation).ipynb) for examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rotations \n",
    "x_train_rotated = [] \n",
    "for x_data in x_train:\n",
    "    rotated_img = rotate(x_data, angle = random.randint(10,40))\n",
    "    x_train_rotated.append(rotated_img) \n",
    "x_train_rotated = np.asarray(x_train_rotated) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply clockwise rotations \n",
    "x_train_rotated_2 = [] \n",
    "for x_data in x_train: \n",
    "    rotated_img = rotate(x_data, angle = -random.randint(10,40)) \n",
    "    x_train_rotated_2.append(rotated_img)\n",
    "x_train_rotated_2 = np.asarray(x_train_rotated_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise \n",
    "x_noised = [] \n",
    "for x_data in x_train: \n",
    "    noised_img = random_noise(x_data) \n",
    "    x_noised.append(noised_img)\n",
    "x_noised = np.asarray(x_noised) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gaussian blur \n",
    "x_blurred = [] \n",
    "for x_data in x_train:\n",
    "    kernel_size = random.choice([3,5,9]) \n",
    "    blurred = cv2.GaussianBlur(x_data, (kernel_size, kernel_size), 0) \n",
    "    x_blurred.append(blurred)\n",
    "x_blurred = np.asarray(x_blurred)\n",
    "x_blurred = x_blurred.reshape(-1,28,28,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift image \n",
    "x_shifted = [] \n",
    "for x_data in x_train: \n",
    "    dx = random.choice([-2,-1,1,2])\n",
    "    dy = random.choice([-2,-1,1,2])\n",
    "    transform = AffineTransform(translation = (dx,dy))\n",
    "    warp_img = warp(x_data, transform, mode = \"wrap\")\n",
    "    x_shifted.append(warp_img) \n",
    "x_shifted = np.asarray(x_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply brightness modifications \n",
    "x_brightness = [] \n",
    "for x_data in x_train: \n",
    "    brightness = 0.5\n",
    "    alpha = 1.0 + random.uniform(-brightness, brightness) \n",
    "    brightness_modified = x_data * alpha \n",
    "    x_brightness.append(brightness_modified) \n",
    "\n",
    "x_brightness = np.asarray(x_brightness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply zca whitening \n",
    "def zca_whitening(sample): \n",
    "    sample = sample - sample.mean(axis=0)\n",
    "    cov = np.cov(sample, rowvar = False)\n",
    "    U,S,V = np.linalg.svd(cov) \n",
    "    epsilon = 0.1\n",
    "    X_ZCA = U.dot(np.diag(1.0/np.sqrt(S + epsilon))).dot(U.T).dot(sample.T).T\n",
    "    X_ZCA_rescaled = (X_ZCA - X_ZCA.min()) / (X_ZCA.max() - X_ZCA.min())\n",
    "    X_ZCA_rescaled = X_ZCA_rescaled.reshape((28,28,1)) \n",
    "    return X_ZCA_rescaled \n",
    "\n",
    "x_zca_whitened = [] \n",
    "for x_data in x_train: \n",
    "    zca_whitened = zca_whitening(x_data.reshape((28,28))) \n",
    "    x_zca_whitened.append(zca_whitened) \n",
    "    \n",
    "x_zca_whitened = np.asarray(x_zca_whitened) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random cropping (zooming effect)\n",
    "def random_crop(img): \n",
    "    img = img.copy() \n",
    "    size = random.randint(22,24) # this seems to be a good balance, since our image size is 28 by 28\n",
    "    crop_size = (size,size)\n",
    "    w,h = img.shape[:2]\n",
    "    x,y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
    "    img = img[y:y+crop_size[0], x:x+crop_size[1]] \n",
    "    return img \n",
    "\n",
    "x_random_crop = []\n",
    "for x_data in x_train: \n",
    "    cropped = random_crop(x_data) \n",
    "    cropped = resize(cropped, (28,28,1))\n",
    "    x_random_crop.append(cropped)\n",
    "\n",
    "x_random_crop = np.asarray(x_random_crop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elastic distortions \n",
    "# from https://www.kaggle.com/babbler/mnist-data-augmentation-with-elastic-distortion\n",
    "def elastic_transform(image, alpha_range, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "       \n",
    "   # Arguments\n",
    "       image: Numpy array with shape (height, width, channels). \n",
    "       alpha_range: Float for fixed value or [lower, upper] for random value from uniform distribution.\n",
    "           Controls intensity of deformation.\n",
    "       sigma: Float, sigma of gaussian filter that smooths the displacement fields.\n",
    "       random_state: `numpy.random.RandomState` object for generating displacement fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "        \n",
    "    if np.isscalar(alpha_range):\n",
    "        alpha = alpha_range\n",
    "    else:\n",
    "        alpha = np.random.uniform(low=alpha_range[0], high=alpha_range[1])\n",
    "    \n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "    indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
    "\n",
    "x_elastic_distort = [] \n",
    "for x_data in x_train: \n",
    "    distorted = elastic_transform(x_data, [8,10], 3) \n",
    "    x_elastic_distort.append(distorted) \n",
    "    \n",
    "x_elastic_distort = np.asarray(x_elastic_distort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autoencoder generated images \n",
    "x_en = np.load('./storage/ae_gen_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22528, 28, 28, 1), (22528, 10), (22528, 26))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating augmented data to the original \n",
    "x_train = np.concatenate((x_train, x_train_rotated, x_train_rotated_2, x_noised, x_blurred, x_shifted, x_brightness, x_zca_whitened, x_random_crop, x_elastic_distort, x_en), axis = 0) \n",
    "y_train = np.concatenate((y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train), axis = 0) \n",
    "train_letters_numeric = np.concatenate((train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric), axis = 0)\n",
    "\n",
    "x_train.shape, y_train.shape, train_letters_numeric.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test data generators \n",
    "# this \"replaces\" the train data. It does not add to it \n",
    "# I am not using this for now. I am directly adding augmented data \n",
    "train_datagen = ImageDataGenerator(width_shift_range = 0.1, \n",
    "                                  height_shift_range = 0.1, \n",
    "                                  shear_range = 0.1,\n",
    "                                  zoom_range = 0.1,\n",
    "                                  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses skip connections and also adds information from both MaxPooling2D and AveragePooling2D \n",
    "def conv2d_block(input_layer, n_filters, kernel):\n",
    "    conv1 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = Add()([conv1, conv2])   \n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    maxpool = MaxPooling2D((2,2))(conv1) \n",
    "    avgpool = AveragePooling2D((2,2))(conv1)\n",
    "    ret = Add()([maxpool,avgpool])\n",
    "    return ret \n",
    "\n",
    "# obtains around 82% validation accuracy on a 9:1 train/validation split\n",
    "# the most promising model so far, until we come up with a potentially more powerful grade 5 model \n",
    "def base_cnn_grade_4(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))    \n",
    "    conv1 = conv2d_block(inputs, 64, 7) \n",
    "    conv2 = conv2d_block(inputs, 64, 5) \n",
    "    conv3 = conv2d_block(inputs, 64, 3) \n",
    "    conv = Concatenate()([conv1,conv2,conv3])   \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv = Concatenate()([conv1,conv2,conv3]) \n",
    "    outputs = Flatten()(conv) \n",
    "    outputs = Concatenate()([outputs,letter_input])\n",
    "    for unit in [512, 256, 128]: \n",
    "        outputs = Dense(unit, activation = 'relu')(outputs)  \n",
    "        outputs = BatchNormalization()(outputs) \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "# obtains 91.2% accuracy on public leaderboard. \n",
    "# increased to three convolutional blocks \n",
    "# batchnorm input layer to normalize the input layer  \n",
    "def base_cnn_grade_5(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))  \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv1 = conv2d_block(bn, 64, 7) \n",
    "    conv2 = conv2d_block(bn, 64, 5) \n",
    "    conv3 = conv2d_block(bn, 64, 3) \n",
    "    conv4 = conv2d_block(bn, 64, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv4 = conv2d_block(conv, 32, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    conv1 = conv2d_block(conv, 16, 7)\n",
    "    conv2 = conv2d_block(conv, 16, 5)\n",
    "    conv3 = conv2d_block(conv, 16, 3)   \n",
    "    conv4 = conv2d_block(conv, 16, 1)       \n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4]) \n",
    "    conv = BatchNormalization()(conv) \n",
    "    outputs = Flatten()(conv) \n",
    "    outputs = Concatenate()([outputs, letter_input]) \n",
    "    for units in [512, 256, 128]: \n",
    "        outputs = Dense(units, activation = 'relu', kernel_initializer = 'he_normal')(outputs) \n",
    "        outputs = BatchNormalization()(outputs)  \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "\n",
    "# reduced to two convolutional blocks, but used one more filter size. \n",
    "# more dense layers at the end \n",
    "# batchnorm input layer to normalize the input layer \n",
    "def base_cnn_grade_6(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))  \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv1 = conv2d_block(bn, 64, 7) \n",
    "    conv2 = conv2d_block(bn, 64, 5) \n",
    "    conv3 = conv2d_block(bn, 64, 4)\n",
    "    conv4 = conv2d_block(bn, 64, 3) \n",
    "    conv5 = conv2d_block(bn, 64, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4,conv5])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 4) \n",
    "    conv4 = conv2d_block(conv, 32, 3) \n",
    "    conv5 = conv2d_block(conv, 32, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4,conv5])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    outputs = Flatten()(conv)  \n",
    "    outputs = Concatenate()([outputs, letter_input])\n",
    "    for units in [1024, 512, 256, 128]: \n",
    "        outputs = Dense(units, activation = 'relu', kernel_initializer = 'he_normal')(outputs) \n",
    "        outputs = BatchNormalization()(outputs)  \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Fold 1 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.7739 - accuracy: 0.4258\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59813, saving model to ./storage/mnist_test_2/kfold1/epoch_001_val_1.198_acc_0.598.h5\n",
      "20276/20276 [==============================] - 30s 1ms/sample - loss: 1.7728 - accuracy: 0.4260 - val_loss: 1.1980 - val_accuracy: 0.5981\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.6587\n",
      "Epoch 00002: val_accuracy improved from 0.59813 to 0.69805, saving model to ./storage/mnist_test_2/kfold1/epoch_002_val_0.894_acc_0.698.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0331 - accuracy: 0.6588 - val_loss: 0.8938 - val_accuracy: 0.6980\n",
      "Epoch 3/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.7343 - accuracy: 0.7617\n",
      "Epoch 00003: val_accuracy improved from 0.69805 to 0.80417, saving model to ./storage/mnist_test_2/kfold1/epoch_003_val_0.642_acc_0.804.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7349 - accuracy: 0.7614 - val_loss: 0.6422 - val_accuracy: 0.8042\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5577 - accuracy: 0.8179\n",
      "Epoch 00004: val_accuracy improved from 0.80417 to 0.80639, saving model to ./storage/mnist_test_2/kfold1/epoch_004_val_0.633_acc_0.806.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5577 - accuracy: 0.8179 - val_loss: 0.6325 - val_accuracy: 0.8064\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4250 - accuracy: 0.8617\n",
      "Epoch 00005: val_accuracy did not improve from 0.80639\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.4249 - accuracy: 0.8617 - val_loss: 0.7168 - val_accuracy: 0.7713\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8865\n",
      "Epoch 00006: val_accuracy improved from 0.80639 to 0.83925, saving model to ./storage/mnist_test_2/kfold1/epoch_006_val_0.526_acc_0.839.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3499 - accuracy: 0.8865 - val_loss: 0.5264 - val_accuracy: 0.8393\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2783 - accuracy: 0.9111\n",
      "Epoch 00007: val_accuracy did not improve from 0.83925\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2785 - accuracy: 0.9111 - val_loss: 0.5452 - val_accuracy: 0.8268\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9275\n",
      "Epoch 00008: val_accuracy improved from 0.83925 to 0.86146, saving model to ./storage/mnist_test_2/kfold1/epoch_008_val_0.482_acc_0.861.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2306 - accuracy: 0.9275 - val_loss: 0.4822 - val_accuracy: 0.8615\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2128 - accuracy: 0.9314\n",
      "Epoch 00009: val_accuracy improved from 0.86146 to 0.86989, saving model to ./storage/mnist_test_2/kfold1/epoch_009_val_0.452_acc_0.870.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2127 - accuracy: 0.9314 - val_loss: 0.4521 - val_accuracy: 0.8699\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9397\n",
      "Epoch 00010: val_accuracy did not improve from 0.86989\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1873 - accuracy: 0.9397 - val_loss: 0.4479 - val_accuracy: 0.8681\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9534\n",
      "Epoch 00011: val_accuracy improved from 0.86989 to 0.87522, saving model to ./storage/mnist_test_2/kfold1/epoch_011_val_0.491_acc_0.875.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1453 - accuracy: 0.9534 - val_loss: 0.4911 - val_accuracy: 0.8752\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9593\n",
      "Epoch 00012: val_accuracy did not improve from 0.87522\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1231 - accuracy: 0.9592 - val_loss: 0.4868 - val_accuracy: 0.8672\n",
      "Epoch 13/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1364 - accuracy: 0.9557\n",
      "Epoch 00013: val_accuracy improved from 0.87522 to 0.87922, saving model to ./storage/mnist_test_2/kfold1/epoch_013_val_0.444_acc_0.879.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1363 - accuracy: 0.9558 - val_loss: 0.4440 - val_accuracy: 0.8792\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9591\n",
      "Epoch 00014: val_accuracy did not improve from 0.87922\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1220 - accuracy: 0.9591 - val_loss: 0.5379 - val_accuracy: 0.8672\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9638\n",
      "Epoch 00015: val_accuracy did not improve from 0.87922\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1102 - accuracy: 0.9638 - val_loss: 0.4601 - val_accuracy: 0.8774\n",
      "Epoch 16/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 0.9722\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.87922\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0854 - accuracy: 0.9722 - val_loss: 0.5363 - val_accuracy: 0.8743\n",
      "Epoch 17/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9778\n",
      "Epoch 00017: val_accuracy improved from 0.87922 to 0.89742, saving model to ./storage/mnist_test_2/kfold1/epoch_017_val_0.441_acc_0.897.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0678 - accuracy: 0.9777 - val_loss: 0.4405 - val_accuracy: 0.8974\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9826\n",
      "Epoch 00018: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0528 - accuracy: 0.9826 - val_loss: 0.4429 - val_accuracy: 0.8939\n",
      "Epoch 19/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9825\n",
      "Epoch 00019: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.4976 - val_accuracy: 0.8881\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9819\n",
      "Epoch 00020: val_accuracy improved from 0.89742 to 0.89876, saving model to ./storage/mnist_test_2/kfold1/epoch_020_val_0.446_acc_0.899.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0552 - accuracy: 0.9818 - val_loss: 0.4458 - val_accuracy: 0.8988\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9789\n",
      "Epoch 00021: val_accuracy did not improve from 0.89876\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0659 - accuracy: 0.9788 - val_loss: 0.4973 - val_accuracy: 0.8899\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9837\n",
      "Epoch 00022: val_accuracy did not improve from 0.89876\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0557 - accuracy: 0.9837 - val_loss: 0.4429 - val_accuracy: 0.8961\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9880\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89876\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.4622 - val_accuracy: 0.8925\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9889\n",
      "Epoch 00024: val_accuracy improved from 0.89876 to 0.90275, saving model to ./storage/mnist_test_2/kfold1/epoch_024_val_0.441_acc_0.903.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.4410 - val_accuracy: 0.9028\n",
      "Epoch 25/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9896\n",
      "Epoch 00025: val_accuracy did not improve from 0.90275\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.4726 - val_accuracy: 0.8988\n",
      "Epoch 26/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9908\n",
      "Epoch 00026: val_accuracy did not improve from 0.90275\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.4987 - val_accuracy: 0.8917\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9892\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90275\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.4779 - val_accuracy: 0.8952\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9909\n",
      "Epoch 00028: val_accuracy did not improve from 0.90275\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.4750 - val_accuracy: 0.8948\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy did not improve from 0.90275\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.4709 - val_accuracy: 0.8983\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9927\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90275\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.4877 - val_accuracy: 0.8943\n",
      "Epoch 31/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9954\n",
      "Epoch 00031: val_accuracy improved from 0.90275 to 0.90497, saving model to ./storage/mnist_test_2/kfold1/epoch_031_val_0.460_acc_0.905.h5\n",
      "20276/20276 [==============================] - 23s 1ms/sample - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.4603 - val_accuracy: 0.9050\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 00032: val_accuracy did not improve from 0.90497\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.4987 - val_accuracy: 0.9041\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 00033: val_accuracy did not improve from 0.90497\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.5108 - val_accuracy: 0.8965\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9940\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90497\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.4581 - val_accuracy: 0.9050\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 00035: val_accuracy improved from 0.90497 to 0.90853, saving model to ./storage/mnist_test_2/kfold1/epoch_035_val_0.456_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.4556 - val_accuracy: 0.9085\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 00036: val_accuracy improved from 0.90853 to 0.90897, saving model to ./storage/mnist_test_2/kfold1/epoch_036_val_0.458_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.4577 - val_accuracy: 0.9090\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9974\n",
      "Epoch 00037: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.4556 - val_accuracy: 0.9081\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9974 ETA: 1s - loss: 0.0085 - accuracy:  - ETA: 0s - los\n",
      "Epoch 00038: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.4906 - val_accuracy: 0.9085\n",
      "Epoch 39/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4829 - val_accuracy: 0.9050\n",
      "Epoch 40/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00040: val_accuracy improved from 0.90897 to 0.91208, saving model to ./storage/mnist_test_2/kfold1/epoch_040_val_0.458_acc_0.912.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.4581 - val_accuracy: 0.9121\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00041: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.4804 - val_accuracy: 0.9036\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 00042: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4929 - val_accuracy: 0.9045\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4901 - val_accuracy: 0.9063\n",
      "Epoch 44/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 00044: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.4871 - val_accuracy: 0.9085\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 00045: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.4830 - val_accuracy: 0.9094\n",
      "Epoch 46/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4818 - val_accuracy: 0.9116\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00047: val_accuracy improved from 0.91208 to 0.91252, saving model to ./storage/mnist_test_2/kfold1/epoch_047_val_0.492_acc_0.913.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4924 - val_accuracy: 0.9125\n",
      "Epoch 48/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00048: val_accuracy improved from 0.91252 to 0.91297, saving model to ./storage/mnist_test_2/kfold1/epoch_048_val_0.499_acc_0.913.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.4986 - val_accuracy: 0.9130\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00049: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4806 - val_accuracy: 0.9094\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 00050: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4802 - val_accuracy: 0.9094\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.4967 - val_accuracy: 0.9099\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 00052: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.4993 - val_accuracy: 0.9081\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00053: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4890 - val_accuracy: 0.9059\n",
      "Epoch 54/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4830 - val_accuracy: 0.9103\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00055: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.4942 - val_accuracy: 0.9103\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00056: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4880 - val_accuracy: 0.9130\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00057: val_accuracy improved from 0.91297 to 0.91474, saving model to ./storage/mnist_test_2/kfold1/epoch_057_val_0.493_acc_0.915.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4933 - val_accuracy: 0.9147\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00058: val_accuracy did not improve from 0.91474\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4957 - val_accuracy: 0.9143\n",
      "Epoch 59/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 00059: val_accuracy did not improve from 0.91474\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.4992 - val_accuracy: 0.9094\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.91474\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4847 - val_accuracy: 0.9116\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00061: val_accuracy improved from 0.91474 to 0.91696, saving model to ./storage/mnist_test_2/kfold1/epoch_061_val_0.478_acc_0.917.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.4780 - val_accuracy: 0.9170\n",
      "Epoch 62/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 00062: val_accuracy did not improve from 0.91696\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.4745 - val_accuracy: 0.9152\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00063: val_accuracy improved from 0.91696 to 0.91829, saving model to ./storage/mnist_test_2/kfold1/epoch_063_val_0.480_acc_0.918.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.4797 - val_accuracy: 0.9183\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00064: val_accuracy did not improve from 0.91829\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4851 - val_accuracy: 0.9174\n",
      "Epoch 65/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00065: val_accuracy improved from 0.91829 to 0.91963, saving model to ./storage/mnist_test_2/kfold1/epoch_065_val_0.478_acc_0.920.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4782 - val_accuracy: 0.9196\n",
      "Epoch 66/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 00066: val_accuracy improved from 0.91963 to 0.92096, saving model to ./storage/mnist_test_2/kfold1/epoch_066_val_0.475_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.4748 - val_accuracy: 0.9210\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.0769e-04 - accuracy: 0.9998\n",
      "Epoch 00067: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.0695e-04 - accuracy: 0.9998 - val_loss: 0.4799 - val_accuracy: 0.9210\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4816 - val_accuracy: 0.9187\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4717 - val_accuracy: 0.9183\n",
      "Epoch 70/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.4196e-04 - accuracy: 1.0000\n",
      "Epoch 00070: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.4068e-04 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.9183\n",
      "Epoch 71/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.1619e-04 - accuracy: 0.9999\n",
      "Epoch 00071: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.1442e-04 - accuracy: 0.9999 - val_loss: 0.4781 - val_accuracy: 0.9196\n",
      "Epoch 72/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.9680e-04 - accuracy: 0.9999\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.1145e-04 - accuracy: 0.9999 - val_loss: 0.4870 - val_accuracy: 0.9179\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.4836 - val_accuracy: 0.9152\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.1364e-04 - accuracy: 0.9999\n",
      "Epoch 00074: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.1290e-04 - accuracy: 0.9999 - val_loss: 0.4850 - val_accuracy: 0.9196\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.6068e-04 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy improved from 0.92096 to 0.92229, saving model to ./storage/mnist_test_2/kfold1/epoch_075_val_0.483_acc_0.922.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 9.5974e-04 - accuracy: 0.9997 - val_loss: 0.4825 - val_accuracy: 0.9223\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.8434e-04 - accuracy: 0.9998\n",
      "Epoch 00076: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.8391e-04 - accuracy: 0.9998 - val_loss: 0.4874 - val_accuracy: 0.9170\n",
      "Epoch 77/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.4762e-04 - accuracy: 0.9998\n",
      "Epoch 00077: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.4684e-04 - accuracy: 0.9998 - val_loss: 0.4904 - val_accuracy: 0.9183\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.5732e-04 - accuracy: 0.9998\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.5653e-04 - accuracy: 0.9998 - val_loss: 0.4808 - val_accuracy: 0.9187\n",
      "Epoch 79/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.6982e-04 - accuracy: 0.9999\n",
      "Epoch 00079: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.7276e-04 - accuracy: 0.9999 - val_loss: 0.4856 - val_accuracy: 0.9205\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.9435e-04 - accuracy: 0.9999\n",
      "Epoch 00080: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.9379e-04 - accuracy: 0.9999 - val_loss: 0.4844 - val_accuracy: 0.9192\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3644e-04 - accuracy: 0.9999\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3601e-04 - accuracy: 0.9999 - val_loss: 0.4788 - val_accuracy: 0.9179\n",
      "Epoch 82/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.9510e-04 - accuracy: 0.9999\n",
      "Epoch 00082: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.9392e-04 - accuracy: 0.9999 - val_loss: 0.4829 - val_accuracy: 0.9179\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3011e-04 - accuracy: 1.0000\n",
      "Epoch 00083: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.2987e-04 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.9170\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2202e-04 - accuracy: 0.9999\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.2210e-04 - accuracy: 0.9999 - val_loss: 0.4747 - val_accuracy: 0.9170\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1346e-04 - accuracy: 0.9999\n",
      "Epoch 00085: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.1309e-04 - accuracy: 0.9999 - val_loss: 0.4677 - val_accuracy: 0.9214\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0808e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.1277e-04 - accuracy: 0.9999 - val_loss: 0.4704 - val_accuracy: 0.9214\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.1429e-04 - accuracy: 0.9999\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.1387e-04 - accuracy: 0.9999 - val_loss: 0.4769 - val_accuracy: 0.9201\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.0699e-04 - accuracy: 0.9998\n",
      "Epoch 00088: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.8260e-04 - accuracy: 0.9998 - val_loss: 0.4687 - val_accuracy: 0.9223\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7074e-04 - accuracy: 0.9998\n",
      "Epoch 00089: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.6322e-04 - accuracy: 0.9997 - val_loss: 0.4722 - val_accuracy: 0.9201\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.5181e-04 - accuracy: 0.9997\n",
      "Epoch 00090: val_accuracy improved from 0.92229 to 0.92274, saving model to ./storage/mnist_test_2/kfold1/epoch_090_val_0.476_acc_0.923.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 7.5116e-04 - accuracy: 0.9997 - val_loss: 0.4759 - val_accuracy: 0.9227\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9286e-04 - accuracy: 0.9999\n",
      "Epoch 00091: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9300e-04 - accuracy: 0.9999 - val_loss: 0.4756 - val_accuracy: 0.9227\n",
      "Epoch 92/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.9153e-04 - accuracy: 1.0000\n",
      "Epoch 00092: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9056e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9214\n",
      "Epoch 93/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.5258e-04 - accuracy: 0.9998\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.5097e-04 - accuracy: 0.9998 - val_loss: 0.4755 - val_accuracy: 0.9223\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3105e-04 - accuracy: 1.0000\n",
      "Epoch 00094: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.6765e-04 - accuracy: 0.9999 - val_loss: 0.4780 - val_accuracy: 0.9192\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3894e-04 - accuracy: 0.9999\n",
      "Epoch 00095: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.5656e-04 - accuracy: 0.9999 - val_loss: 0.4758 - val_accuracy: 0.9214\n",
      "Epoch 96/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.3206e-04 - accuracy: 0.9997\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.3154e-04 - accuracy: 0.9997 - val_loss: 0.4808 - val_accuracy: 0.9205\n",
      "Epoch 97/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.4533e-04 - accuracy: 1.0000\n",
      "Epoch 00097: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.4699e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9201\n",
      "Epoch 98/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.6921e-04 - accuracy: 0.9998\n",
      "Epoch 00098: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.6891e-04 - accuracy: 0.9998 - val_loss: 0.4829 - val_accuracy: 0.9223\n",
      "Epoch 99/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4823e-04 - accuracy: 0.9998\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.4801e-04 - accuracy: 0.9998 - val_loss: 0.4746 - val_accuracy: 0.9227\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4070e-04 - accuracy: 1.0000\n",
      "Epoch 00100: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.4051e-04 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9214\n",
      "Epoch 101/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.7103e-04 - accuracy: 0.9999\n",
      "Epoch 00101: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.7039e-04 - accuracy: 0.9999 - val_loss: 0.4788 - val_accuracy: 0.9196\n",
      "Epoch 102/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.5854e-04 - accuracy: 0.9999\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.6148e-04 - accuracy: 0.9999 - val_loss: 0.4842 - val_accuracy: 0.9205\n",
      "Epoch 103/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4536e-04 - accuracy: 1.0000\n",
      "Epoch 00103: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.4503e-04 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9205\n",
      "Epoch 104/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.5545e-04 - accuracy: 0.9998\n",
      "Epoch 00104: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5443e-04 - accuracy: 0.9998 - val_loss: 0.4778 - val_accuracy: 0.9210\n",
      "Epoch 105/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.2410e-04 - accuracy: 0.9998\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.2365e-04 - accuracy: 0.9998 - val_loss: 0.4818 - val_accuracy: 0.9201\n",
      "Epoch 106/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.5210e-04 - accuracy: 1.0000\n",
      "Epoch 00106: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.5198e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9210\n",
      "Epoch 107/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.7906e-04 - accuracy: 1.0000\n",
      "Epoch 00107: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.7908e-04 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9210\n",
      "Epoch 108/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9377e-04 - accuracy: 0.9999\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9363e-04 - accuracy: 0.9999 - val_loss: 0.4771 - val_accuracy: 0.9201\n",
      "Epoch 109/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.9624e-04 - accuracy: 0.9998\n",
      "Epoch 00109: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.9514e-04 - accuracy: 0.9998 - val_loss: 0.4787 - val_accuracy: 0.9192\n",
      "Epoch 110/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.4143e-04 - accuracy: 0.9998\n",
      "Epoch 00110: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.4080e-04 - accuracy: 0.9998 - val_loss: 0.4833 - val_accuracy: 0.9214\n",
      "Epoch 111/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7783e-04 - accuracy: 0.9999\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7746e-04 - accuracy: 0.9999 - val_loss: 0.4817 - val_accuracy: 0.9210\n",
      "Epoch 112/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8576e-04 - accuracy: 1.0000\n",
      "Epoch 00112: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.8559e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9192\n",
      "Epoch 113/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2446e-04 - accuracy: 1.0000\n",
      "Epoch 00113: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.2466e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9201\n",
      "Epoch 114/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5658e-04 - accuracy: 1.0000\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.5640e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9214\n",
      "Epoch 115/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.6536e-04 - accuracy: 0.9999\n",
      "Epoch 00115: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.6560e-04 - accuracy: 0.9999 - val_loss: 0.4769 - val_accuracy: 0.9192\n",
      "************ Fold 2 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7920 - accuracy: 0.4196\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60435, saving model to ./storage/mnist_test_2/kfold2/epoch_001_val_1.155_acc_0.604.h5\n",
      "20276/20276 [==============================] - 28s 1ms/sample - loss: 1.7913 - accuracy: 0.4198 - val_loss: 1.1555 - val_accuracy: 0.6044\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0533 - accuracy: 0.6478\n",
      "Epoch 00002: val_accuracy improved from 0.60435 to 0.69139, saving model to ./storage/mnist_test_2/kfold2/epoch_002_val_0.917_acc_0.691.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0534 - accuracy: 0.6478 - val_loss: 0.9172 - val_accuracy: 0.6914\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7426 - accuracy: 0.7569\n",
      "Epoch 00003: val_accuracy improved from 0.69139 to 0.80551, saving model to ./storage/mnist_test_2/kfold2/epoch_003_val_0.567_acc_0.806.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7424 - accuracy: 0.7571 - val_loss: 0.5671 - val_accuracy: 0.8055\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5675 - accuracy: 0.8161\n",
      "Epoch 00004: val_accuracy improved from 0.80551 to 0.81705, saving model to ./storage/mnist_test_2/kfold2/epoch_004_val_0.553_acc_0.817.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5675 - accuracy: 0.8160 - val_loss: 0.5531 - val_accuracy: 0.8171\n",
      "Epoch 5/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8606\n",
      "Epoch 00005: val_accuracy improved from 0.81705 to 0.84680, saving model to ./storage/mnist_test_2/kfold2/epoch_005_val_0.475_acc_0.847.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.4332 - accuracy: 0.8608 - val_loss: 0.4755 - val_accuracy: 0.8468\n",
      "Epoch 6/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3474 - accuracy: 0.8890\n",
      "Epoch 00006: val_accuracy did not improve from 0.84680\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.3473 - accuracy: 0.8890 - val_loss: 0.5350 - val_accuracy: 0.8308\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.9002\n",
      "Epoch 00007: val_accuracy improved from 0.84680 to 0.85435, saving model to ./storage/mnist_test_2/kfold2/epoch_007_val_0.480_acc_0.854.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2996 - accuracy: 0.9002 - val_loss: 0.4802 - val_accuracy: 0.8544\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.9218\n",
      "Epoch 00008: val_accuracy improved from 0.85435 to 0.87433, saving model to ./storage/mnist_test_2/kfold2/epoch_008_val_0.427_acc_0.874.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2440 - accuracy: 0.9218 - val_loss: 0.4274 - val_accuracy: 0.8743\n",
      "Epoch 9/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9267\n",
      "Epoch 00009: val_accuracy did not improve from 0.87433\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2213 - accuracy: 0.9268 - val_loss: 0.4381 - val_accuracy: 0.8703\n",
      "Epoch 10/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9458\n",
      "Epoch 00010: val_accuracy did not improve from 0.87433\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1690 - accuracy: 0.9458 - val_loss: 0.4673 - val_accuracy: 0.8734\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9478\n",
      "Epoch 00011: val_accuracy improved from 0.87433 to 0.88233, saving model to ./storage/mnist_test_2/kfold2/epoch_011_val_0.413_acc_0.882.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1618 - accuracy: 0.9476 - val_loss: 0.4127 - val_accuracy: 0.8823\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9457\n",
      "Epoch 00012: val_accuracy did not improve from 0.88233\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1671 - accuracy: 0.9458 - val_loss: 0.4643 - val_accuracy: 0.8757\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9563\n",
      "Epoch 00013: val_accuracy did not improve from 0.88233\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1326 - accuracy: 0.9563 - val_loss: 0.5100 - val_accuracy: 0.8690\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9648\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.88233\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1095 - accuracy: 0.9648 - val_loss: 0.4782 - val_accuracy: 0.8814\n",
      "Epoch 15/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9778\n",
      "Epoch 00015: val_accuracy improved from 0.88233 to 0.89210, saving model to ./storage/mnist_test_2/kfold2/epoch_015_val_0.401_acc_0.892.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0732 - accuracy: 0.9778 - val_loss: 0.4006 - val_accuracy: 0.8921\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9817\n",
      "Epoch 00016: val_accuracy did not improve from 0.89210\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0594 - accuracy: 0.9817 - val_loss: 0.5130 - val_accuracy: 0.8712\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9717\n",
      "Epoch 00017: val_accuracy improved from 0.89210 to 0.90098, saving model to ./storage/mnist_test_2/kfold2/epoch_017_val_0.387_acc_0.901.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0878 - accuracy: 0.9716 - val_loss: 0.3872 - val_accuracy: 0.9010\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0668 - accuracy: 0.9783\n",
      "Epoch 00018: val_accuracy did not improve from 0.90098\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.4892 - val_accuracy: 0.8783\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9783\n",
      "Epoch 00019: val_accuracy did not improve from 0.90098\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0685 - accuracy: 0.9783 - val_loss: 0.5166 - val_accuracy: 0.8819\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9791\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.90098\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0624 - accuracy: 0.9790 - val_loss: 0.4029 - val_accuracy: 0.8992\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9887\n",
      "Epoch 00021: val_accuracy did not improve from 0.90098\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.4128 - val_accuracy: 0.9001\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 00022: val_accuracy improved from 0.90098 to 0.90631, saving model to ./storage/mnist_test_2/kfold2/epoch_022_val_0.417_acc_0.906.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.4169 - val_accuracy: 0.9063\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9903\n",
      "Epoch 00023: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.4441 - val_accuracy: 0.8996\n",
      "Epoch 24/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9872\n",
      "Epoch 00024: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.4818 - val_accuracy: 0.8956\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9883\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0365 - accuracy: 0.9883 - val_loss: 0.4225 - val_accuracy: 0.8894\n",
      "Epoch 26/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9909\n",
      "Epoch 00026: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.4174 - val_accuracy: 0.9001\n",
      "Epoch 27/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9939\n",
      "Epoch 00027: val_accuracy improved from 0.90631 to 0.90675, saving model to ./storage/mnist_test_2/kfold2/epoch_027_val_0.403_acc_0.907.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.4033 - val_accuracy: 0.9067\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9915\n",
      "Epoch 00028: val_accuracy did not improve from 0.90675\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.4286 - val_accuracy: 0.9067\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9913\n",
      "Epoch 00029: val_accuracy improved from 0.90675 to 0.90897, saving model to ./storage/mnist_test_2/kfold2/epoch_029_val_0.419_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.4190 - val_accuracy: 0.9090\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9929\n",
      "Epoch 00030: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.4166 - val_accuracy: 0.9036\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9915\n",
      "Epoch 00031: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.4521 - val_accuracy: 0.9036\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9932\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.4532 - val_accuracy: 0.9050\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 00033: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.4491 - val_accuracy: 0.9032\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9957\n",
      "Epoch 00034: val_accuracy improved from 0.90897 to 0.91208, saving model to ./storage/mnist_test_2/kfold2/epoch_034_val_0.425_acc_0.912.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.4249 - val_accuracy: 0.9121\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 00035: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.3912 - val_accuracy: 0.9121\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9956\n",
      "Epoch 00036: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.4205 - val_accuracy: 0.9067\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9948\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.4110 - val_accuracy: 0.9112\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 00038: val_accuracy improved from 0.91208 to 0.91652, saving model to ./storage/mnist_test_2/kfold2/epoch_038_val_0.393_acc_0.917.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.3926 - val_accuracy: 0.9165\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 00039: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.3951 - val_accuracy: 0.9143\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 00040: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.4206 - val_accuracy: 0.9152\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.4042 - val_accuracy: 0.9130\n",
      "Epoch 42/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00042: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.4014 - val_accuracy: 0.9103\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00043: val_accuracy improved from 0.91652 to 0.91874, saving model to ./storage/mnist_test_2/kfold2/epoch_043_val_0.403_acc_0.919.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.4029 - val_accuracy: 0.9187\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00044: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4093 - val_accuracy: 0.9183\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9978\n",
      "Epoch 00045: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.4062 - val_accuracy: 0.9174\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9980\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.4070 - val_accuracy: 0.9143\n",
      "Epoch 47/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00047: val_accuracy improved from 0.91874 to 0.91918, saving model to ./storage/mnist_test_2/kfold2/epoch_047_val_0.408_acc_0.919.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4075 - val_accuracy: 0.9192\n",
      "Epoch 48/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00048: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.3975 - val_accuracy: 0.9174\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00049: val_accuracy improved from 0.91918 to 0.92007, saving model to ./storage/mnist_test_2/kfold2/epoch_049_val_0.401_acc_0.920.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.4008 - val_accuracy: 0.9201\n",
      "Epoch 50/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00050: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.4260 - val_accuracy: 0.9187\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 00051: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.4345 - val_accuracy: 0.9156\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4296 - val_accuracy: 0.9201\n",
      "Epoch 53/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00053: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.4573 - val_accuracy: 0.9183\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00054: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.4242 - val_accuracy: 0.9183\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 00055: val_accuracy improved from 0.92007 to 0.92274, saving model to ./storage/mnist_test_2/kfold2/epoch_055_val_0.412_acc_0.923.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.4124 - val_accuracy: 0.9227\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 00056: val_accuracy improved from 0.92274 to 0.92584, saving model to ./storage/mnist_test_2/kfold2/epoch_056_val_0.409_acc_0.926.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4088 - val_accuracy: 0.9258\n",
      "Epoch 57/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00057: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.4116 - val_accuracy: 0.9214\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00058: val_accuracy improved from 0.92584 to 0.92629, saving model to ./storage/mnist_test_2/kfold2/epoch_058_val_0.394_acc_0.926.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3940 - val_accuracy: 0.9263\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00059: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.4063 - val_accuracy: 0.9245\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00060: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.4274 - val_accuracy: 0.9241\n",
      "Epoch 61/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00061: val_accuracy improved from 0.92629 to 0.92718, saving model to ./storage/mnist_test_2/kfold2/epoch_061_val_0.425_acc_0.927.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4246 - val_accuracy: 0.9272\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00062: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4320 - val_accuracy: 0.9205\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00063: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.4498 - val_accuracy: 0.9192\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4386 - val_accuracy: 0.9218\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00065: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.4320 - val_accuracy: 0.9223\n",
      "Epoch 66/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00066: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4291 - val_accuracy: 0.9227\n",
      "Epoch 67/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4268 - val_accuracy: 0.9263\n",
      "Epoch 68/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00068: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.4160 - val_accuracy: 0.9267\n",
      "Epoch 69/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00069: val_accuracy improved from 0.92718 to 0.92940, saving model to ./storage/mnist_test_2/kfold2/epoch_069_val_0.410_acc_0.929.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4102 - val_accuracy: 0.9294\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00070: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.4265 - val_accuracy: 0.9236\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00071: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.4173 - val_accuracy: 0.9214\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.9249e-04 - accuracy: 0.9998 ETA: 0s - loss: 8.7689e-04 - accuracy: \n",
      "Epoch 00072: val_accuracy improved from 0.92940 to 0.93028, saving model to ./storage/mnist_test_2/kfold2/epoch_072_val_0.406_acc_0.930.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 8.9162e-04 - accuracy: 0.9998 - val_loss: 0.4065 - val_accuracy: 0.9303\n",
      "Epoch 73/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.0683e-04 - accuracy: 0.9998\n",
      "Epoch 00073: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.0514e-04 - accuracy: 0.9998 - val_loss: 0.4087 - val_accuracy: 0.9263\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 00074: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.4272 - val_accuracy: 0.9227\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.4209 - val_accuracy: 0.9254\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00076: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4124 - val_accuracy: 0.9250\n",
      "Epoch 77/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.4623e-04 - accuracy: 0.9997\n",
      "Epoch 00077: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.4415e-04 - accuracy: 0.9997 - val_loss: 0.4143 - val_accuracy: 0.9263\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995 ETA: 0s - los\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4267 - val_accuracy: 0.9227\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.2544e-04 - accuracy: 0.9997\n",
      "Epoch 00079: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.2457e-04 - accuracy: 0.9997 - val_loss: 0.4153 - val_accuracy: 0.9263\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00080: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4153 - val_accuracy: 0.9263\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4168 - val_accuracy: 0.9250\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00082: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4190 - val_accuracy: 0.9241\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00083: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4132 - val_accuracy: 0.9258\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.4255e-04 - accuracy: 0.9998\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.4174e-04 - accuracy: 0.9998 - val_loss: 0.4149 - val_accuracy: 0.9227\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.7517e-04 - accuracy: 0.9999\n",
      "Epoch 00085: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.7445e-04 - accuracy: 0.9999 - val_loss: 0.4074 - val_accuracy: 0.9232\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00086: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4093 - val_accuracy: 0.9250\n",
      "Epoch 87/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.4898e-04 - accuracy: 0.9998\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.4769e-04 - accuracy: 0.9998 - val_loss: 0.4057 - val_accuracy: 0.9254\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7485e-04 - accuracy: 0.9999\n",
      "Epoch 00088: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7448e-04 - accuracy: 0.9999 - val_loss: 0.4073 - val_accuracy: 0.9267\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5627e-04 - accuracy: 1.0000\n",
      "Epoch 00089: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5595e-04 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9281\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1646e-04 - accuracy: 1.0000\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5488e-04 - accuracy: 0.9999 - val_loss: 0.4037 - val_accuracy: 0.9276\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.2834e-04 - accuracy: 0.9999\n",
      "Epoch 00091: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.2788e-04 - accuracy: 0.9999 - val_loss: 0.4019 - val_accuracy: 0.9263\n",
      "Epoch 92/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.8806e-04 - accuracy: 0.9999\n",
      "Epoch 00092: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.8727e-04 - accuracy: 0.9999 - val_loss: 0.3992 - val_accuracy: 0.9276\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.1239e-04 - accuracy: 0.9997\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.1160e-04 - accuracy: 0.9997 - val_loss: 0.4055 - val_accuracy: 0.9250\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.2335e-04 - accuracy: 0.9999\n",
      "Epoch 00094: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.3793e-04 - accuracy: 0.9999 - val_loss: 0.3980 - val_accuracy: 0.9276\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9574e-04 - accuracy: 0.9999\n",
      "Epoch 00095: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9535e-04 - accuracy: 0.9999 - val_loss: 0.4008 - val_accuracy: 0.9272\n",
      "Epoch 96/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.0938e-04 - accuracy: 0.9999\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.0871e-04 - accuracy: 0.9999 - val_loss: 0.4009 - val_accuracy: 0.9272\n",
      "Epoch 97/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.8567e-04 - accuracy: 0.9998\n",
      "Epoch 00097: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.8428e-04 - accuracy: 0.9998 - val_loss: 0.3966 - val_accuracy: 0.9290\n",
      "************ Fold 3 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8129 - accuracy: 0.4086\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57948, saving model to ./storage/mnist_test_2/kfold3/epoch_001_val_1.224_acc_0.579.h5\n",
      "20276/20276 [==============================] - 29s 1ms/sample - loss: 1.8125 - accuracy: 0.4087 - val_loss: 1.2243 - val_accuracy: 0.5795\n",
      "Epoch 2/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.0599 - accuracy: 0.6463\n",
      "Epoch 00002: val_accuracy improved from 0.57948 to 0.73357, saving model to ./storage/mnist_test_2/kfold3/epoch_002_val_0.806_acc_0.734.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0601 - accuracy: 0.6462 - val_loss: 0.8057 - val_accuracy: 0.7336\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7401 - accuracy: 0.7555\n",
      "Epoch 00003: val_accuracy improved from 0.73357 to 0.78774, saving model to ./storage/mnist_test_2/kfold3/epoch_003_val_0.637_acc_0.788.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7401 - accuracy: 0.7557 - val_loss: 0.6368 - val_accuracy: 0.7877\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5631 - accuracy: 0.8163\n",
      "Epoch 00004: val_accuracy improved from 0.78774 to 0.81528, saving model to ./storage/mnist_test_2/kfold3/epoch_004_val_0.553_acc_0.815.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5629 - accuracy: 0.8163 - val_loss: 0.5527 - val_accuracy: 0.8153\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4409 - accuracy: 0.8567\n",
      "Epoch 00005: val_accuracy improved from 0.81528 to 0.83215, saving model to ./storage/mnist_test_2/kfold3/epoch_005_val_0.528_acc_0.832.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.4414 - accuracy: 0.8565 - val_loss: 0.5283 - val_accuracy: 0.8321\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8780\n",
      "Epoch 00006: val_accuracy improved from 0.83215 to 0.84991, saving model to ./storage/mnist_test_2/kfold3/epoch_006_val_0.472_acc_0.850.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3801 - accuracy: 0.8779 - val_loss: 0.4719 - val_accuracy: 0.8499\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.9009\n",
      "Epoch 00007: val_accuracy did not improve from 0.84991\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.3080 - accuracy: 0.9009 - val_loss: 0.4982 - val_accuracy: 0.8446\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9164\n",
      "Epoch 00008: val_accuracy improved from 0.84991 to 0.86590, saving model to ./storage/mnist_test_2/kfold3/epoch_008_val_0.443_acc_0.866.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2569 - accuracy: 0.9164 - val_loss: 0.4435 - val_accuracy: 0.8659\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2332 - accuracy: 0.9258\n",
      "Epoch 00009: val_accuracy did not improve from 0.86590\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2335 - accuracy: 0.9257 - val_loss: 0.4938 - val_accuracy: 0.8619\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9389\n",
      "Epoch 00010: val_accuracy improved from 0.86590 to 0.87034, saving model to ./storage/mnist_test_2/kfold3/epoch_010_val_0.466_acc_0.870.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1835 - accuracy: 0.9388 - val_loss: 0.4664 - val_accuracy: 0.8703\n",
      "Epoch 11/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1843 - accuracy: 0.9390\n",
      "Epoch 00011: val_accuracy improved from 0.87034 to 0.87211, saving model to ./storage/mnist_test_2/kfold3/epoch_011_val_0.477_acc_0.872.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1840 - accuracy: 0.9392 - val_loss: 0.4765 - val_accuracy: 0.8721\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1402 - accuracy: 0.9553\n",
      "Epoch 00012: val_accuracy did not improve from 0.87211\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1401 - accuracy: 0.9553 - val_loss: 0.4856 - val_accuracy: 0.8663\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.9581\n",
      "Epoch 00013: val_accuracy improved from 0.87211 to 0.87833, saving model to ./storage/mnist_test_2/kfold3/epoch_013_val_0.479_acc_0.878.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1313 - accuracy: 0.9581 - val_loss: 0.4792 - val_accuracy: 0.8783\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9602\n",
      "Epoch 00014: val_accuracy did not improve from 0.87833\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1203 - accuracy: 0.9601 - val_loss: 0.5935 - val_accuracy: 0.8504\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9562\n",
      "Epoch 00015: val_accuracy improved from 0.87833 to 0.88144, saving model to ./storage/mnist_test_2/kfold3/epoch_015_val_0.452_acc_0.881.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1325 - accuracy: 0.9562 - val_loss: 0.4516 - val_accuracy: 0.8814\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9646\n",
      "Epoch 00016: val_accuracy did not improve from 0.88144\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1101 - accuracy: 0.9646 - val_loss: 0.6676 - val_accuracy: 0.8370\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9688\n",
      "Epoch 00017: val_accuracy improved from 0.88144 to 0.88588, saving model to ./storage/mnist_test_2/kfold3/epoch_017_val_0.430_acc_0.886.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0975 - accuracy: 0.9689 - val_loss: 0.4303 - val_accuracy: 0.8859\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9763\n",
      "Epoch 00018: val_accuracy did not improve from 0.88588\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0744 - accuracy: 0.9762 - val_loss: 0.5010 - val_accuracy: 0.8743\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9744\n",
      "Epoch 00019: val_accuracy did not improve from 0.88588\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0833 - accuracy: 0.9745 - val_loss: 0.4533 - val_accuracy: 0.8841\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9768\n",
      "Epoch 00020: val_accuracy improved from 0.88588 to 0.88943, saving model to ./storage/mnist_test_2/kfold3/epoch_020_val_0.480_acc_0.889.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0704 - accuracy: 0.9769 - val_loss: 0.4797 - val_accuracy: 0.8894\n",
      "Epoch 21/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9769\n",
      "Epoch 00021: val_accuracy did not improve from 0.88943\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0739 - accuracy: 0.9768 - val_loss: 0.4728 - val_accuracy: 0.8877\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9754\n",
      "Epoch 00022: val_accuracy did not improve from 0.88943\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0796 - accuracy: 0.9753 - val_loss: 0.5089 - val_accuracy: 0.8788\n",
      "Epoch 23/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9778\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.88943\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0719 - accuracy: 0.9779 - val_loss: 0.5150 - val_accuracy: 0.8770\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9845\n",
      "Epoch 00024: val_accuracy improved from 0.88943 to 0.89165, saving model to ./storage/mnist_test_2/kfold3/epoch_024_val_0.479_acc_0.892.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0493 - accuracy: 0.9846 - val_loss: 0.4791 - val_accuracy: 0.8917\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9877\n",
      "Epoch 00025: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0373 - accuracy: 0.9877 - val_loss: 0.5913 - val_accuracy: 0.8677\n",
      "Epoch 26/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9833\n",
      "Epoch 00026: val_accuracy improved from 0.89165 to 0.89298, saving model to ./storage/mnist_test_2/kfold3/epoch_026_val_0.513_acc_0.893.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0513 - accuracy: 0.9834 - val_loss: 0.5131 - val_accuracy: 0.8930\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9880\n",
      "Epoch 00027: val_accuracy improved from 0.89298 to 0.90631, saving model to ./storage/mnist_test_2/kfold3/epoch_027_val_0.476_acc_0.906.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.4757 - val_accuracy: 0.9063\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9887\n",
      "Epoch 00028: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.4645 - val_accuracy: 0.9028\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9886\n",
      "Epoch 00029: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0407 - accuracy: 0.9886 - val_loss: 0.5063 - val_accuracy: 0.8881\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9871\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90631\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0368 - accuracy: 0.9871 - val_loss: 0.4820 - val_accuracy: 0.8974\n",
      "Epoch 31/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9926\n",
      "Epoch 00031: val_accuracy improved from 0.90631 to 0.90853, saving model to ./storage/mnist_test_2/kfold3/epoch_031_val_0.418_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.4179 - val_accuracy: 0.9085\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9935\n",
      "Epoch 00032: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.4510 - val_accuracy: 0.9036\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9913\n",
      "Epoch 00033: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.4698 - val_accuracy: 0.8956\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9898\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0342 - accuracy: 0.9898 - val_loss: 0.4650 - val_accuracy: 0.9014\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9932\n",
      "Epoch 00035: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.4418 - val_accuracy: 0.9023\n",
      "Epoch 36/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9940\n",
      "Epoch 00036: val_accuracy improved from 0.90853 to 0.91163, saving model to ./storage/mnist_test_2/kfold3/epoch_036_val_0.427_acc_0.912.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.4271 - val_accuracy: 0.9116\n",
      "Epoch 37/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954\n",
      "Epoch 00037: val_accuracy improved from 0.91163 to 0.91385, saving model to ./storage/mnist_test_2/kfold3/epoch_037_val_0.409_acc_0.914.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.4093 - val_accuracy: 0.9139\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9954\n",
      "Epoch 00038: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.4558 - val_accuracy: 0.9010\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9941\n",
      "Epoch 00039: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.4735 - val_accuracy: 0.9054\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.4967 - val_accuracy: 0.9028\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9959\n",
      "Epoch 00041: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4632 - val_accuracy: 0.9072\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 00042: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.4561 - val_accuracy: 0.9059\n",
      "Epoch 43/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.4673 - val_accuracy: 0.9112\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9962\n",
      "Epoch 00044: val_accuracy improved from 0.91385 to 0.91652, saving model to ./storage/mnist_test_2/kfold3/epoch_044_val_0.439_acc_0.917.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.4391 - val_accuracy: 0.9165\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 00045: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4298 - val_accuracy: 0.9161\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00046: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4335 - val_accuracy: 0.9161\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.4532 - val_accuracy: 0.9152\n",
      "Epoch 48/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 00048: val_accuracy improved from 0.91652 to 0.91918, saving model to ./storage/mnist_test_2/kfold3/epoch_048_val_0.457_acc_0.919.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.4574 - val_accuracy: 0.9192\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00049: val_accuracy improved from 0.91918 to 0.92052, saving model to ./storage/mnist_test_2/kfold3/epoch_049_val_0.456_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.4560 - val_accuracy: 0.9205\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 00050: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.4551 - val_accuracy: 0.9143\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 00051: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4680 - val_accuracy: 0.9165\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4660 - val_accuracy: 0.9130\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00053: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.4590 - val_accuracy: 0.9139\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00054: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.4604 - val_accuracy: 0.9143\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4639 - val_accuracy: 0.9201\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00056: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4451 - val_accuracy: 0.9192\n",
      "Epoch 57/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00057: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4449 - val_accuracy: 0.9161\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4362 - val_accuracy: 0.9205\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00059: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4390 - val_accuracy: 0.9205\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00060: val_accuracy improved from 0.92052 to 0.92229, saving model to ./storage/mnist_test_2/kfold3/epoch_060_val_0.448_acc_0.922.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.4485 - val_accuracy: 0.9223\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00061: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4543 - val_accuracy: 0.9210\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00062: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4541 - val_accuracy: 0.9187\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4606 - val_accuracy: 0.9214\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00064: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4548 - val_accuracy: 0.9210\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 00065: val_accuracy improved from 0.92229 to 0.92274, saving model to ./storage/mnist_test_2/kfold3/epoch_065_val_0.444_acc_0.923.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.4443 - val_accuracy: 0.9227\n",
      "Epoch 66/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00066: val_accuracy improved from 0.92274 to 0.92629, saving model to ./storage/mnist_test_2/kfold3/epoch_066_val_0.447_acc_0.926.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4473 - val_accuracy: 0.9263\n",
      "Epoch 67/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy improved from 0.92629 to 0.92762, saving model to ./storage/mnist_test_2/kfold3/epoch_067_val_0.443_acc_0.928.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4427 - val_accuracy: 0.9276\n",
      "Epoch 68/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.0794e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4419 - val_accuracy: 0.9223\n",
      "Epoch 69/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00069: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.4426 - val_accuracy: 0.9254\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4679 - val_accuracy: 0.9227\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 00071: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4491 - val_accuracy: 0.9201\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.9772e-04 - accuracy: 0.9998\n",
      "Epoch 00072: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 7.9899e-04 - accuracy: 0.9998 - val_loss: 0.4473 - val_accuracy: 0.9214\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4455 - val_accuracy: 0.9236\n",
      "Epoch 74/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.3373e-04 - accuracy: 0.9999\n",
      "Epoch 00074: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.3280e-04 - accuracy: 0.9999 - val_loss: 0.4409 - val_accuracy: 0.9218\n",
      "Epoch 75/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00075: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4385 - val_accuracy: 0.9232\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4325 - val_accuracy: 0.9210\n",
      "Epoch 77/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.4804e-04 - accuracy: 0.9997\n",
      "Epoch 00077: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.5478e-04 - accuracy: 0.9997 - val_loss: 0.4377 - val_accuracy: 0.9214\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00078: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4371 - val_accuracy: 0.9210\n",
      "Epoch 79/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.8440e-04 - accuracy: 0.9999\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.0017e-04 - accuracy: 0.9999 - val_loss: 0.4408 - val_accuracy: 0.9218\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.1569e-04 - accuracy: 0.9999\n",
      "Epoch 00080: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.1512e-04 - accuracy: 0.9999 - val_loss: 0.4446 - val_accuracy: 0.9218\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.9832e-04 - accuracy: 0.9998\n",
      "Epoch 00081: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.0023e-04 - accuracy: 0.9998 - val_loss: 0.4505 - val_accuracy: 0.9214\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.1215e-04 - accuracy: 0.9999\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.1187e-04 - accuracy: 0.9999 - val_loss: 0.4519 - val_accuracy: 0.9196\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0128e-04 - accuracy: 0.9999\n",
      "Epoch 00083: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.0086e-04 - accuracy: 0.9999 - val_loss: 0.4549 - val_accuracy: 0.9227\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.5439e-04 - accuracy: 0.9998\n",
      "Epoch 00084: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.5449e-04 - accuracy: 0.9998 - val_loss: 0.4454 - val_accuracy: 0.9254\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7869e-04 - accuracy: 1.0000\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7835e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9250\n",
      "Epoch 86/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.4529e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.4355e-04 - accuracy: 0.9999 - val_loss: 0.4468 - val_accuracy: 0.9241\n",
      "Epoch 87/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.0990e-04 - accuracy: 0.9998\n",
      "Epoch 00087: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.0869e-04 - accuracy: 0.9998 - val_loss: 0.4479 - val_accuracy: 0.9223\n",
      "Epoch 88/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.6883e-04 - accuracy: 0.9999\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7004e-04 - accuracy: 0.9999 - val_loss: 0.4484 - val_accuracy: 0.9223\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.5560e-04 - accuracy: 1.0000\n",
      "Epoch 00089: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.5535e-04 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9214\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.8590e-04 - accuracy: 0.9999\n",
      "Epoch 00090: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.8515e-04 - accuracy: 0.9999 - val_loss: 0.4490 - val_accuracy: 0.9245\n",
      "Epoch 91/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.4237e-04 - accuracy: 1.0000\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.4133e-04 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9232\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3165e-04 - accuracy: 0.9999\n",
      "Epoch 00092: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3124e-04 - accuracy: 0.9999 - val_loss: 0.4483 - val_accuracy: 0.9241\n",
      "************ Fold 4 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.8199 - accuracy: 0.4082\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59103, saving model to ./storage/mnist_test_2/kfold4/epoch_001_val_1.207_acc_0.591.h5\n",
      "20276/20276 [==============================] - 29s 1ms/sample - loss: 1.8179 - accuracy: 0.4087 - val_loss: 1.2070 - val_accuracy: 0.5910\n",
      "Epoch 2/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.0552 - accuracy: 0.6439\n",
      "Epoch 00002: val_accuracy improved from 0.59103 to 0.73135, saving model to ./storage/mnist_test_2/kfold4/epoch_002_val_0.792_acc_0.731.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0545 - accuracy: 0.6442 - val_loss: 0.7921 - val_accuracy: 0.7313\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7510 - accuracy: 0.7504\n",
      "Epoch 00003: val_accuracy improved from 0.73135 to 0.78597, saving model to ./storage/mnist_test_2/kfold4/epoch_003_val_0.634_acc_0.786.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7509 - accuracy: 0.7504 - val_loss: 0.6342 - val_accuracy: 0.7860\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.8173\n",
      "Epoch 00004: val_accuracy improved from 0.78597 to 0.81261, saving model to ./storage/mnist_test_2/kfold4/epoch_004_val_0.570_acc_0.813.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5466 - accuracy: 0.8175 - val_loss: 0.5704 - val_accuracy: 0.8126\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4133 - accuracy: 0.8658\n",
      "Epoch 00005: val_accuracy improved from 0.81261 to 0.82638, saving model to ./storage/mnist_test_2/kfold4/epoch_005_val_0.558_acc_0.826.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.4133 - accuracy: 0.8658 - val_loss: 0.5585 - val_accuracy: 0.8264\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3517 - accuracy: 0.8851\n",
      "Epoch 00006: val_accuracy improved from 0.82638 to 0.84503, saving model to ./storage/mnist_test_2/kfold4/epoch_006_val_0.510_acc_0.845.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3520 - accuracy: 0.8849 - val_loss: 0.5100 - val_accuracy: 0.8450\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8993\n",
      "Epoch 00007: val_accuracy improved from 0.84503 to 0.85258, saving model to ./storage/mnist_test_2/kfold4/epoch_007_val_0.473_acc_0.853.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3082 - accuracy: 0.8993 - val_loss: 0.4729 - val_accuracy: 0.8526\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2343 - accuracy: 0.9240\n",
      "Epoch 00008: val_accuracy improved from 0.85258 to 0.85613, saving model to ./storage/mnist_test_2/kfold4/epoch_008_val_0.477_acc_0.856.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2342 - accuracy: 0.9240 - val_loss: 0.4775 - val_accuracy: 0.8561\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.9281\n",
      "Epoch 00009: val_accuracy improved from 0.85613 to 0.87078, saving model to ./storage/mnist_test_2/kfold4/epoch_009_val_0.447_acc_0.871.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2265 - accuracy: 0.9281 - val_loss: 0.4474 - val_accuracy: 0.8708\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9402\n",
      "Epoch 00010: val_accuracy did not improve from 0.87078\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1884 - accuracy: 0.9402 - val_loss: 0.4520 - val_accuracy: 0.8686\n",
      "Epoch 11/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9523\n",
      "Epoch 00011: val_accuracy did not improve from 0.87078\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1451 - accuracy: 0.9523 - val_loss: 0.4518 - val_accuracy: 0.8677\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9501\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87078\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1544 - accuracy: 0.9501 - val_loss: 0.5152 - val_accuracy: 0.8650\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9646\n",
      "Epoch 00013: val_accuracy improved from 0.87078 to 0.89920, saving model to ./storage/mnist_test_2/kfold4/epoch_013_val_0.375_acc_0.899.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1080 - accuracy: 0.9644 - val_loss: 0.3747 - val_accuracy: 0.8992\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9759\n",
      "Epoch 00014: val_accuracy did not improve from 0.89920\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0748 - accuracy: 0.9759 - val_loss: 0.4257 - val_accuracy: 0.8845\n",
      "Epoch 15/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9714\n",
      "Epoch 00015: val_accuracy did not improve from 0.89920\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0837 - accuracy: 0.9714 - val_loss: 0.4791 - val_accuracy: 0.8832\n",
      "Epoch 16/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9710\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.89920\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0882 - accuracy: 0.9710 - val_loss: 0.4483 - val_accuracy: 0.8894\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9845\n",
      "Epoch 00017: val_accuracy improved from 0.89920 to 0.90409, saving model to ./storage/mnist_test_2/kfold4/epoch_017_val_0.404_acc_0.904.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0465 - accuracy: 0.9845 - val_loss: 0.4035 - val_accuracy: 0.9041\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9865\n",
      "Epoch 00018: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.4428 - val_accuracy: 0.8988\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9835\n",
      "Epoch 00019: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0526 - accuracy: 0.9834 - val_loss: 0.4707 - val_accuracy: 0.8943\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9805\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0591 - accuracy: 0.9806 - val_loss: 0.4473 - val_accuracy: 0.8934\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9916\n",
      "Epoch 00021: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.5170 - val_accuracy: 0.8881\n",
      "Epoch 22/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9904\n",
      "Epoch 00022: val_accuracy improved from 0.90409 to 0.90675, saving model to ./storage/mnist_test_2/kfold4/epoch_022_val_0.416_acc_0.907.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.4159 - val_accuracy: 0.9067\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9907\n",
      "Epoch 00023: val_accuracy did not improve from 0.90675\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0292 - accuracy: 0.9907 - val_loss: 0.4611 - val_accuracy: 0.8988\n",
      "Epoch 24/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9876\n",
      "Epoch 00024: val_accuracy did not improve from 0.90675\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.4439 - val_accuracy: 0.9005\n",
      "Epoch 25/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9900\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.90675\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.4415 - val_accuracy: 0.8988\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9943\n",
      "Epoch 00026: val_accuracy did not improve from 0.90675\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.4014 - val_accuracy: 0.9067\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9951\n",
      "Epoch 00027: val_accuracy improved from 0.90675 to 0.91119, saving model to ./storage/mnist_test_2/kfold4/epoch_027_val_0.369_acc_0.911.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.3692 - val_accuracy: 0.9112\n",
      "Epoch 28/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 00028: val_accuracy did not improve from 0.91119\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.4299 - val_accuracy: 0.9067\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9925\n",
      "Epoch 00029: val_accuracy did not improve from 0.91119\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.4155 - val_accuracy: 0.9094\n",
      "Epoch 30/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.91119\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.4390 - val_accuracy: 0.9067\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 00031: val_accuracy improved from 0.91119 to 0.91430, saving model to ./storage/mnist_test_2/kfold4/epoch_031_val_0.422_acc_0.914.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.4216 - val_accuracy: 0.9143\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9963\n",
      "Epoch 00032: val_accuracy did not improve from 0.91430\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.4361 - val_accuracy: 0.9054\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 00033: val_accuracy did not improve from 0.91430\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.4357 - val_accuracy: 0.9112\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9961\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.91430\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.4483 - val_accuracy: 0.9085\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9960\n",
      "Epoch 00035: val_accuracy improved from 0.91430 to 0.91563, saving model to ./storage/mnist_test_2/kfold4/epoch_035_val_0.417_acc_0.916.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.4171 - val_accuracy: 0.9156\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 00036: val_accuracy improved from 0.91563 to 0.91696, saving model to ./storage/mnist_test_2/kfold4/epoch_036_val_0.399_acc_0.917.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.3989 - val_accuracy: 0.9170\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00037: val_accuracy did not improve from 0.91696\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.4041 - val_accuracy: 0.9156\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9971\n",
      "Epoch 00038: val_accuracy did not improve from 0.91696\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.4382 - val_accuracy: 0.9072\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00039: val_accuracy improved from 0.91696 to 0.92096, saving model to ./storage/mnist_test_2/kfold4/epoch_039_val_0.433_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.4329 - val_accuracy: 0.9210\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9975\n",
      "Epoch 00040: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.4102 - val_accuracy: 0.9205\n",
      "Epoch 41/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 00041: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.4314 - val_accuracy: 0.9103\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4185 - val_accuracy: 0.9147\n",
      "Epoch 43/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 00043: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.4279 - val_accuracy: 0.9183\n",
      "Epoch 44/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 00044: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.4317 - val_accuracy: 0.9165\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.4454 - val_accuracy: 0.9183\n",
      "Epoch 46/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00046: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.4303 - val_accuracy: 0.9170\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00047: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.4357 - val_accuracy: 0.9205\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4317 - val_accuracy: 0.9210\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00049: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.4374 - val_accuracy: 0.9187\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00050: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.4334 - val_accuracy: 0.9152\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00051: val_accuracy improved from 0.92096 to 0.92496, saving model to ./storage/mnist_test_2/kfold4/epoch_051_val_0.422_acc_0.925.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4217 - val_accuracy: 0.9250\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00052: val_accuracy did not improve from 0.92496\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.4218 - val_accuracy: 0.9210\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00053: val_accuracy did not improve from 0.92496\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4233 - val_accuracy: 0.9196\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00054: val_accuracy improved from 0.92496 to 0.92584, saving model to ./storage/mnist_test_2/kfold4/epoch_054_val_0.432_acc_0.926.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.4316 - val_accuracy: 0.9258\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00055: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4263 - val_accuracy: 0.9205\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 00056: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.4199 - val_accuracy: 0.9214\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.4190 - val_accuracy: 0.9210\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00058: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4224 - val_accuracy: 0.9245\n",
      "Epoch 59/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00059: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.4274 - val_accuracy: 0.9250\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4213 - val_accuracy: 0.9245\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00061: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.4232 - val_accuracy: 0.9250\n",
      "Epoch 62/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00062: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4217 - val_accuracy: 0.9254\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4207 - val_accuracy: 0.9250\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00064: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4247 - val_accuracy: 0.9258\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.4350e-04 - accuracy: 0.9998\n",
      "Epoch 00065: val_accuracy improved from 0.92584 to 0.92718, saving model to ./storage/mnist_test_2/kfold4/epoch_065_val_0.427_acc_0.927.h5\n",
      "20276/20276 [==============================] - 33s 2ms/sample - loss: 9.4278e-04 - accuracy: 0.9998 - val_loss: 0.4267 - val_accuracy: 0.9272\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.2426e-04 - accuracy: 0.9997\n",
      "Epoch 00066: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.2338e-04 - accuracy: 0.9997 - val_loss: 0.4247 - val_accuracy: 0.9241\n",
      "Epoch 67/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.9677e-04 - accuracy: 0.9999\n",
      "Epoch 00067: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.9502e-04 - accuracy: 0.9999 - val_loss: 0.4247 - val_accuracy: 0.9267\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.8580e-04 - accuracy: 0.9998\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.8582e-04 - accuracy: 0.9998 - val_loss: 0.4305 - val_accuracy: 0.9267\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00069: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4317 - val_accuracy: 0.9267\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.7366e-04 - accuracy: 0.9998 ETA: 1s - loss: 9.0557e - ETA: 0s - loss:\n",
      "Epoch 00070: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.7486e-04 - accuracy: 0.9998 - val_loss: 0.4301 - val_accuracy: 0.9245\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.2324e-04 - accuracy: 0.9998\n",
      "Epoch 00071: val_accuracy improved from 0.92718 to 0.92806, saving model to ./storage/mnist_test_2/kfold4/epoch_071_val_0.426_acc_0.928.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 7.2253e-04 - accuracy: 0.9998 - val_loss: 0.4260 - val_accuracy: 0.9281\n",
      "Epoch 72/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.8299e-04 - accuracy: 0.9999\n",
      "Epoch 00072: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.8168e-04 - accuracy: 0.9999 - val_loss: 0.4227 - val_accuracy: 0.9281\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.6748e-04 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy improved from 0.92806 to 0.93028, saving model to ./storage/mnist_test_2/kfold4/epoch_073_val_0.432_acc_0.930.h5\n",
      "20276/20276 [==============================] - 42s 2ms/sample - loss: 7.6674e-04 - accuracy: 0.9997 - val_loss: 0.4320 - val_accuracy: 0.9303\n",
      "Epoch 74/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00074: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4293 - val_accuracy: 0.9281\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.3498e-04 - accuracy: 0.9998\n",
      "Epoch 00075: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.3441e-04 - accuracy: 0.9998 - val_loss: 0.4326 - val_accuracy: 0.9281\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.5897e-04 - accuracy: 0.9997\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.5821e-04 - accuracy: 0.9997 - val_loss: 0.4297 - val_accuracy: 0.9285\n",
      "Epoch 77/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.6919e-04 - accuracy: 0.9998\n",
      "Epoch 00077: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.6736e-04 - accuracy: 0.9998 - val_loss: 0.4356 - val_accuracy: 0.9276\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.7411e-04 - accuracy: 1.0000\n",
      "Epoch 00078: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7470e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9281\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.9504e-04 - accuracy: 0.9998\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.9452e-04 - accuracy: 0.9998 - val_loss: 0.4395 - val_accuracy: 0.9254\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.3382e-04 - accuracy: 0.9999\n",
      "Epoch 00080: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.3229e-04 - accuracy: 0.9999 - val_loss: 0.4315 - val_accuracy: 0.9281\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.5339e-04 - accuracy: 0.9998\n",
      "Epoch 00081: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.5266e-04 - accuracy: 0.9998 - val_loss: 0.4319 - val_accuracy: 0.9245\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6887e-04 - accuracy: 0.9999\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.6831e-04 - accuracy: 0.9999 - val_loss: 0.4342 - val_accuracy: 0.9250\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3474e-04 - accuracy: 0.9998\n",
      "Epoch 00083: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.3411e-04 - accuracy: 0.9998 - val_loss: 0.4329 - val_accuracy: 0.9250\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.8214e-04 - accuracy: 0.9998\n",
      "Epoch 00084: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.8519e-04 - accuracy: 0.9998 - val_loss: 0.4348 - val_accuracy: 0.9263\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7498e-04 - accuracy: 1.0000\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7464e-04 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9294\n",
      "Epoch 86/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.3202e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.3023e-04 - accuracy: 0.9999 - val_loss: 0.4357 - val_accuracy: 0.9281\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.1304e-04 - accuracy: 0.9998\n",
      "Epoch 00087: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.1266e-04 - accuracy: 0.9998 - val_loss: 0.4355 - val_accuracy: 0.9250\n",
      "Epoch 88/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.8150e-04 - accuracy: 0.9998\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.8031e-04 - accuracy: 0.9998 - val_loss: 0.4351 - val_accuracy: 0.9258\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6611e-04 - accuracy: 0.9998\n",
      "Epoch 00089: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.6567e-04 - accuracy: 0.9998 - val_loss: 0.4325 - val_accuracy: 0.9258\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.7801e-04 - accuracy: 1.0000\n",
      "Epoch 00090: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.7816e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9276\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.9296e-04 - accuracy: 0.9999\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.0507e-04 - accuracy: 0.9999 - val_loss: 0.4313 - val_accuracy: 0.9281\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1495e-04 - accuracy: 1.0000\n",
      "Epoch 00092: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.1478e-04 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9281\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0433e-04 - accuracy: 0.9999\n",
      "Epoch 00093: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.0392e-04 - accuracy: 0.9999 - val_loss: 0.4275 - val_accuracy: 0.9276\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.1164e-04 - accuracy: 0.9997\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.1099e-04 - accuracy: 0.9997 - val_loss: 0.4287 - val_accuracy: 0.9290\n",
      "Epoch 95/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.2788e-04 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.3996e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9303\n",
      "Epoch 96/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.6941e-04 - accuracy: 0.9999\n",
      "Epoch 00096: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.6914e-04 - accuracy: 0.9999 - val_loss: 0.4253 - val_accuracy: 0.9290\n",
      "Epoch 97/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8646e-04 - accuracy: 0.9999\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.8618e-04 - accuracy: 0.9999 - val_loss: 0.4296 - val_accuracy: 0.9294\n",
      "Epoch 98/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00098: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4293 - val_accuracy: 0.9290\n",
      "************ Fold 5 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7757 - accuracy: 0.4244\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58837, saving model to ./storage/mnist_test_2/kfold5/epoch_001_val_1.239_acc_0.588.h5\n",
      "20276/20276 [==============================] - 44s 2ms/sample - loss: 1.7754 - accuracy: 0.4244 - val_loss: 1.2395 - val_accuracy: 0.5884\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0507 - accuracy: 0.6449\n",
      "Epoch 00002: val_accuracy improved from 0.58837 to 0.75000, saving model to ./storage/mnist_test_2/kfold5/epoch_002_val_0.748_acc_0.750.h5\n",
      "20276/20276 [==============================] - 34s 2ms/sample - loss: 1.0502 - accuracy: 0.6451 - val_loss: 0.7479 - val_accuracy: 0.7500\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7357 - accuracy: 0.7588\n",
      "Epoch 00003: val_accuracy improved from 0.75000 to 0.78064, saving model to ./storage/mnist_test_2/kfold5/epoch_003_val_0.666_acc_0.781.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7357 - accuracy: 0.7589 - val_loss: 0.6663 - val_accuracy: 0.7806\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.8186\n",
      "Epoch 00004: val_accuracy improved from 0.78064 to 0.81350, saving model to ./storage/mnist_test_2/kfold5/epoch_004_val_0.546_acc_0.813.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5620 - accuracy: 0.8185 - val_loss: 0.5462 - val_accuracy: 0.8135\n",
      "Epoch 5/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.4353 - accuracy: 0.8572\n",
      "Epoch 00005: val_accuracy improved from 0.81350 to 0.84414, saving model to ./storage/mnist_test_2/kfold5/epoch_005_val_0.523_acc_0.844.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.4352 - accuracy: 0.8573 - val_loss: 0.5231 - val_accuracy: 0.8441\n",
      "Epoch 6/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.8859\n",
      "Epoch 00006: val_accuracy improved from 0.84414 to 0.85169, saving model to ./storage/mnist_test_2/kfold5/epoch_006_val_0.496_acc_0.852.h5\n",
      "20276/20276 [==============================] - 31s 2ms/sample - loss: 0.3501 - accuracy: 0.8855 - val_loss: 0.4961 - val_accuracy: 0.8517\n",
      "Epoch 7/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3025 - accuracy: 0.9027\n",
      "Epoch 00007: val_accuracy did not improve from 0.85169\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.3029 - accuracy: 0.9025 - val_loss: 0.4827 - val_accuracy: 0.8499\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2604 - accuracy: 0.9136\n",
      "Epoch 00008: val_accuracy improved from 0.85169 to 0.85702, saving model to ./storage/mnist_test_2/kfold5/epoch_008_val_0.478_acc_0.857.h5\n",
      "20276/20276 [==============================] - 32s 2ms/sample - loss: 0.2604 - accuracy: 0.9136 - val_loss: 0.4783 - val_accuracy: 0.8570\n",
      "Epoch 9/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9330\n",
      "Epoch 00009: val_accuracy improved from 0.85702 to 0.86501, saving model to ./storage/mnist_test_2/kfold5/epoch_009_val_0.466_acc_0.865.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2108 - accuracy: 0.9330 - val_loss: 0.4659 - val_accuracy: 0.8650\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9438\n",
      "Epoch 00010: val_accuracy improved from 0.86501 to 0.86590, saving model to ./storage/mnist_test_2/kfold5/epoch_010_val_0.517_acc_0.866.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1718 - accuracy: 0.9439 - val_loss: 0.5167 - val_accuracy: 0.8659\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9457\n",
      "Epoch 00011: val_accuracy did not improve from 0.86590\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1671 - accuracy: 0.9458 - val_loss: 0.5172 - val_accuracy: 0.8619\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9471\n",
      "Epoch 00012: val_accuracy improved from 0.86590 to 0.88410, saving model to ./storage/mnist_test_2/kfold5/epoch_012_val_0.462_acc_0.884.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1595 - accuracy: 0.9471 - val_loss: 0.4615 - val_accuracy: 0.8841\n",
      "Epoch 13/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1181 - accuracy: 0.9628\n",
      "Epoch 00013: val_accuracy did not improve from 0.88410\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1181 - accuracy: 0.9628 - val_loss: 0.4745 - val_accuracy: 0.8757\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9629\n",
      "Epoch 00014: val_accuracy did not improve from 0.88410\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1148 - accuracy: 0.9629 - val_loss: 0.5318 - val_accuracy: 0.8734\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9698\n",
      "Epoch 00015: val_accuracy improved from 0.88410 to 0.89565, saving model to ./storage/mnist_test_2/kfold5/epoch_015_val_0.447_acc_0.896.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0933 - accuracy: 0.9699 - val_loss: 0.4469 - val_accuracy: 0.8956\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9640\n",
      "Epoch 00016: val_accuracy did not improve from 0.89565\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1145 - accuracy: 0.9640 - val_loss: 0.5069 - val_accuracy: 0.8739\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9683\n",
      "Epoch 00017: val_accuracy did not improve from 0.89565\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0966 - accuracy: 0.9682 - val_loss: 0.4799 - val_accuracy: 0.8877\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9729\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89565\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0818 - accuracy: 0.9729 - val_loss: 0.4883 - val_accuracy: 0.8854\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9783\n",
      "Epoch 00019: val_accuracy did not improve from 0.89565\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0662 - accuracy: 0.9782 - val_loss: 0.4447 - val_accuracy: 0.8912\n",
      "Epoch 20/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.98 - ETA: 0s - loss: 0.0623 - accuracy: 0.9804\n",
      "Epoch 00020: val_accuracy did not improve from 0.89565\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0625 - accuracy: 0.9804 - val_loss: 0.4587 - val_accuracy: 0.8912\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9816\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.89565\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0589 - accuracy: 0.9817 - val_loss: 0.4454 - val_accuracy: 0.8934\n",
      "Epoch 22/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9896\n",
      "Epoch 00022: val_accuracy improved from 0.89565 to 0.90009, saving model to ./storage/mnist_test_2/kfold5/epoch_022_val_0.430_acc_0.900.h5\n",
      "20276/20276 [==============================] - 40s 2ms/sample - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.4299 - val_accuracy: 0.9001\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9895\n",
      "Epoch 00023: val_accuracy improved from 0.90009 to 0.90808, saving model to ./storage/mnist_test_2/kfold5/epoch_023_val_0.436_acc_0.908.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.4358 - val_accuracy: 0.9081\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9915\n",
      "Epoch 00024: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0274 - accuracy: 0.9914 - val_loss: 0.4345 - val_accuracy: 0.9081\n",
      "Epoch 25/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9876\n",
      "Epoch 00025: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0400 - accuracy: 0.9876 - val_loss: 0.4349 - val_accuracy: 0.9041\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9874\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.4818 - val_accuracy: 0.9010\n",
      "Epoch 27/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9920\n",
      "Epoch 00027: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.4378 - val_accuracy: 0.9014\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9934\n",
      "Epoch 00028: val_accuracy improved from 0.90808 to 0.90897, saving model to ./storage/mnist_test_2/kfold5/epoch_028_val_0.430_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.4295 - val_accuracy: 0.9090\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 00029: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.5011 - val_accuracy: 0.8970\n",
      "Epoch 30/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 00030: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.5000 - val_accuracy: 0.8948\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.5187 - val_accuracy: 0.8992\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9951\n",
      "Epoch 00032: val_accuracy improved from 0.90897 to 0.91075, saving model to ./storage/mnist_test_2/kfold5/epoch_032_val_0.452_acc_0.911.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.4517 - val_accuracy: 0.9107\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9956\n",
      "Epoch 00033: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.4634 - val_accuracy: 0.9090\n",
      "Epoch 34/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9963\n",
      "Epoch 00034: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4835 - val_accuracy: 0.8988\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.5020 - val_accuracy: 0.9032\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9963 ETA: 0s - loss:\n",
      "Epoch 00036: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.4731 - val_accuracy: 0.9059\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 00037: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.4862 - val_accuracy: 0.9063\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 00038: val_accuracy improved from 0.91075 to 0.91119, saving model to ./storage/mnist_test_2/kfold5/epoch_038_val_0.486_acc_0.911.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.4858 - val_accuracy: 0.9112\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 00039: val_accuracy improved from 0.91119 to 0.91252, saving model to ./storage/mnist_test_2/kfold5/epoch_039_val_0.488_acc_0.913.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.4883 - val_accuracy: 0.9125\n",
      "Epoch 40/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 00040: val_accuracy improved from 0.91252 to 0.91341, saving model to ./storage/mnist_test_2/kfold5/epoch_040_val_0.473_acc_0.913.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.4734 - val_accuracy: 0.9134\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 00041: val_accuracy improved from 0.91341 to 0.91385, saving model to ./storage/mnist_test_2/kfold5/epoch_041_val_0.477_acc_0.914.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.4774 - val_accuracy: 0.9139\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 00042: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.5224 - val_accuracy: 0.9063\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9974\n",
      "Epoch 00043: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.5528 - val_accuracy: 0.9036\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5228 - val_accuracy: 0.9041\n",
      "Epoch 45/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 00045: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.4987 - val_accuracy: 0.9063\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00046: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4936 - val_accuracy: 0.9116\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.5019 - val_accuracy: 0.9063\n",
      "Epoch 48/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 00048: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.4961 - val_accuracy: 0.9085\n",
      "Epoch 49/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992 ETA: 0s - loss: 0.0029 - accura\n",
      "Epoch 00049: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.5034 - val_accuracy: 0.9112\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.5192 - val_accuracy: 0.9085\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00051: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5046 - val_accuracy: 0.9085\n",
      "Epoch 52/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00052: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.4941 - val_accuracy: 0.9103\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.5212 - val_accuracy: 0.9063\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 00054: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.5227 - val_accuracy: 0.9094\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00055: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5283 - val_accuracy: 0.9112\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5350 - val_accuracy: 0.9116\n",
      "Epoch 57/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00057: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.5312 - val_accuracy: 0.9112\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00058: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.5192 - val_accuracy: 0.9112\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.5204 - val_accuracy: 0.9099\n",
      "Epoch 60/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00060: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.5173 - val_accuracy: 0.9125\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00061: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.5162 - val_accuracy: 0.9103\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.5088 - val_accuracy: 0.9112\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 00063: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4964 - val_accuracy: 0.9134\n",
      "Epoch 64/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00064: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4891 - val_accuracy: 0.9139\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4942 - val_accuracy: 0.9116\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00066: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.4876 - val_accuracy: 0.9139\n",
      "************ Fold 6 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7850 - accuracy: 0.4216\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60480, saving model to ./storage/mnist_test_2/kfold6/epoch_001_val_1.129_acc_0.605.h5\n",
      "20276/20276 [==============================] - 29s 1ms/sample - loss: 1.7849 - accuracy: 0.4217 - val_loss: 1.1291 - val_accuracy: 0.6048\n",
      "Epoch 2/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.0455 - accuracy: 0.6504\n",
      "Epoch 00002: val_accuracy improved from 0.60480 to 0.74112, saving model to ./storage/mnist_test_2/kfold6/epoch_002_val_0.768_acc_0.741.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0451 - accuracy: 0.6505 - val_loss: 0.7684 - val_accuracy: 0.7411\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7343 - accuracy: 0.7573\n",
      "Epoch 00003: val_accuracy improved from 0.74112 to 0.78375, saving model to ./storage/mnist_test_2/kfold6/epoch_003_val_0.662_acc_0.784.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7345 - accuracy: 0.7573 - val_loss: 0.6625 - val_accuracy: 0.7837\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5569 - accuracy: 0.8184\n",
      "Epoch 00004: val_accuracy improved from 0.78375 to 0.82993, saving model to ./storage/mnist_test_2/kfold6/epoch_004_val_0.507_acc_0.830.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5569 - accuracy: 0.8184 - val_loss: 0.5068 - val_accuracy: 0.8299\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4312 - accuracy: 0.8597\n",
      "Epoch 00005: val_accuracy did not improve from 0.82993\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.4316 - accuracy: 0.8596 - val_loss: 0.5492 - val_accuracy: 0.8237\n",
      "Epoch 6/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3544 - accuracy: 0.8848 ETA: 0s - loss: 0.3542 - \n",
      "Epoch 00006: val_accuracy improved from 0.82993 to 0.85480, saving model to ./storage/mnist_test_2/kfold6/epoch_006_val_0.456_acc_0.855.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3540 - accuracy: 0.8849 - val_loss: 0.4563 - val_accuracy: 0.8548\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.9092\n",
      "Epoch 00007: val_accuracy did not improve from 0.85480\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2781 - accuracy: 0.9091 - val_loss: 0.5025 - val_accuracy: 0.8508\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9223\n",
      "Epoch 00008: val_accuracy improved from 0.85480 to 0.88011, saving model to ./storage/mnist_test_2/kfold6/epoch_008_val_0.408_acc_0.880.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2407 - accuracy: 0.9223 - val_loss: 0.4075 - val_accuracy: 0.8801\n",
      "Epoch 9/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9260\n",
      "Epoch 00009: val_accuracy did not improve from 0.88011\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2233 - accuracy: 0.9260 - val_loss: 0.4690 - val_accuracy: 0.8637\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9384\n",
      "Epoch 00010: val_accuracy did not improve from 0.88011\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1917 - accuracy: 0.9384 - val_loss: 0.4266 - val_accuracy: 0.8690\n",
      "Epoch 11/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9504\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.88011\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1518 - accuracy: 0.9504 - val_loss: 0.4639 - val_accuracy: 0.8712\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 0.9655\n",
      "Epoch 00012: val_accuracy improved from 0.88011 to 0.90497, saving model to ./storage/mnist_test_2/kfold6/epoch_012_val_0.360_acc_0.905.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1046 - accuracy: 0.9655 - val_loss: 0.3595 - val_accuracy: 0.9050\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9681\n",
      "Epoch 00013: val_accuracy did not improve from 0.90497\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0964 - accuracy: 0.9680 - val_loss: 0.4583 - val_accuracy: 0.8788\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9647\n",
      "Epoch 00014: val_accuracy did not improve from 0.90497\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1088 - accuracy: 0.9646 - val_loss: 0.3918 - val_accuracy: 0.8903\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9732\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.90497\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0785 - accuracy: 0.9732 - val_loss: 0.4328 - val_accuracy: 0.8877\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9806\n",
      "Epoch 00016: val_accuracy improved from 0.90497 to 0.91030, saving model to ./storage/mnist_test_2/kfold6/epoch_016_val_0.338_acc_0.910.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0584 - accuracy: 0.9807 - val_loss: 0.3383 - val_accuracy: 0.9103\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9843\n",
      "Epoch 00017: val_accuracy did not improve from 0.91030\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0482 - accuracy: 0.9843 - val_loss: 0.4100 - val_accuracy: 0.8948\n",
      "Epoch 18/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9809\n",
      "Epoch 00018: val_accuracy did not improve from 0.91030\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.3778 - val_accuracy: 0.9028\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9839\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91030\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0487 - accuracy: 0.9838 - val_loss: 0.3928 - val_accuracy: 0.9054\n",
      "Epoch 20/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9889\n",
      "Epoch 00020: val_accuracy did not improve from 0.91030\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0354 - accuracy: 0.9889 - val_loss: 0.3592 - val_accuracy: 0.9094\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9896\n",
      "Epoch 00021: val_accuracy did not improve from 0.91030\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.3978 - val_accuracy: 0.9045\n",
      "Epoch 22/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9904\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91030\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.3742 - val_accuracy: 0.9099\n",
      "Epoch 23/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9904\n",
      "Epoch 00023: val_accuracy improved from 0.91030 to 0.91385, saving model to ./storage/mnist_test_2/kfold6/epoch_023_val_0.368_acc_0.914.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.3685 - val_accuracy: 0.9139\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9945\n",
      "Epoch 00024: val_accuracy improved from 0.91385 to 0.91430, saving model to ./storage/mnist_test_2/kfold6/epoch_024_val_0.358_acc_0.914.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.3583 - val_accuracy: 0.9143\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9926\n",
      "Epoch 00025: val_accuracy did not improve from 0.91430\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.3736 - val_accuracy: 0.9085\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9931\n",
      "Epoch 00026: val_accuracy did not improve from 0.91430\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.3944 - val_accuracy: 0.9063\n",
      "Epoch 27/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9931\n",
      "Epoch 00027: val_accuracy improved from 0.91430 to 0.91519, saving model to ./storage/mnist_test_2/kfold6/epoch_027_val_0.370_acc_0.915.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.3702 - val_accuracy: 0.9152\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9923\n",
      "Epoch 00028: val_accuracy did not improve from 0.91519\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.4308 - val_accuracy: 0.9059\n",
      "Epoch 29/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 00029: val_accuracy did not improve from 0.91519\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.3995 - val_accuracy: 0.9121\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.91519\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.3810 - val_accuracy: 0.9134\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9946\n",
      "Epoch 00031: val_accuracy improved from 0.91519 to 0.91741, saving model to ./storage/mnist_test_2/kfold6/epoch_031_val_0.378_acc_0.917.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.3782 - val_accuracy: 0.9174\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 00032: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.3892 - val_accuracy: 0.9170\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 00033: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.3977 - val_accuracy: 0.9125\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 00034: val_accuracy improved from 0.91741 to 0.91785, saving model to ./storage/mnist_test_2/kfold6/epoch_034_val_0.396_acc_0.918.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.3956 - val_accuracy: 0.9179\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 00035: val_accuracy improved from 0.91785 to 0.92052, saving model to ./storage/mnist_test_2/kfold6/epoch_035_val_0.399_acc_0.921.h5\n",
      "20276/20276 [==============================] - 23s 1ms/sample - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.3989 - val_accuracy: 0.9205\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9961\n",
      "Epoch 00036: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.4136 - val_accuracy: 0.9156\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 00037: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.4307 - val_accuracy: 0.9090\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9943\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.4136 - val_accuracy: 0.9103\n",
      "Epoch 39/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 00039: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.4138 - val_accuracy: 0.9143\n",
      "Epoch 40/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9972\n",
      "Epoch 00040: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.4095 - val_accuracy: 0.9152\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4059 - val_accuracy: 0.9143\n",
      "Epoch 42/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00042: val_accuracy improved from 0.92052 to 0.92096, saving model to ./storage/mnist_test_2/kfold6/epoch_042_val_0.403_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.4031 - val_accuracy: 0.9210\n",
      "Epoch 43/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 00043: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4051 - val_accuracy: 0.9161\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 00044: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.4227 - val_accuracy: 0.9156\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.4324 - val_accuracy: 0.9139\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 00046: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3912 - val_accuracy: 0.9201\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00047: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.3899 - val_accuracy: 0.9192\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.3921 - val_accuracy: 0.9210\n",
      "Epoch 49/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 00049: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4018 - val_accuracy: 0.9170\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00050: val_accuracy improved from 0.92096 to 0.92318, saving model to ./storage/mnist_test_2/kfold6/epoch_050_val_0.371_acc_0.923.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.3709 - val_accuracy: 0.9232\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00051: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.3880 - val_accuracy: 0.9214\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00052: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.3838 - val_accuracy: 0.9210\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.3949 - val_accuracy: 0.9201\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 00054: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.3903 - val_accuracy: 0.9223\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00055: val_accuracy improved from 0.92318 to 0.92540, saving model to ./storage/mnist_test_2/kfold6/epoch_055_val_0.388_acc_0.925.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3875 - val_accuracy: 0.9254\n",
      "Epoch 56/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00056: val_accuracy did not improve from 0.92540\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3949 - val_accuracy: 0.9223\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00057: val_accuracy improved from 0.92540 to 0.92895, saving model to ./storage/mnist_test_2/kfold6/epoch_057_val_0.387_acc_0.929.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.3867 - val_accuracy: 0.9290\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00058: val_accuracy did not improve from 0.92895\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.3846 - val_accuracy: 0.9258\n",
      "Epoch 59/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00059: val_accuracy did not improve from 0.92895\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3835 - val_accuracy: 0.9272\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00060: val_accuracy improved from 0.92895 to 0.92984, saving model to ./storage/mnist_test_2/kfold6/epoch_060_val_0.382_acc_0.930.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.3824 - val_accuracy: 0.9298\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00061: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.3883 - val_accuracy: 0.9258\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00062: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.3753 - val_accuracy: 0.9254\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.3711 - val_accuracy: 0.9258\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00064: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3681 - val_accuracy: 0.9254\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00065: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3614 - val_accuracy: 0.9276\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3618 - val_accuracy: 0.9272\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3679 - val_accuracy: 0.9263\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.6098e-04 - accuracy: 0.9999\n",
      "Epoch 00068: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.6040e-04 - accuracy: 0.9999 - val_loss: 0.3687 - val_accuracy: 0.9263\n",
      "Epoch 69/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995 ETA: 0s - los\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.3520 - val_accuracy: 0.9294\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00070: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3549 - val_accuracy: 0.9263\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00071: val_accuracy did not improve from 0.92984\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.3476 - val_accuracy: 0.9294\n",
      "Epoch 72/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00072: val_accuracy improved from 0.92984 to 0.93073, saving model to ./storage/mnist_test_2/kfold6/epoch_072_val_0.353_acc_0.931.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3531 - val_accuracy: 0.9307\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 00073: val_accuracy improved from 0.93073 to 0.93250, saving model to ./storage/mnist_test_2/kfold6/epoch_073_val_0.352_acc_0.933.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.3519 - val_accuracy: 0.9325\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.8392e-04 - accuracy: 0.9997\n",
      "Epoch 00074: val_accuracy improved from 0.93250 to 0.93384, saving model to ./storage/mnist_test_2/kfold6/epoch_074_val_0.348_acc_0.934.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 9.9343e-04 - accuracy: 0.9997 - val_loss: 0.3478 - val_accuracy: 0.9338\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3544 - val_accuracy: 0.9276\n",
      "Epoch 76/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.4623e-04 - accuracy: 0.9999\n",
      "Epoch 00076: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.4489e-04 - accuracy: 0.9999 - val_loss: 0.3572 - val_accuracy: 0.9316\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.0126e-04 - accuracy: 0.9998\n",
      "Epoch 00077: val_accuracy improved from 0.93384 to 0.93517, saving model to ./storage/mnist_test_2/kfold6/epoch_077_val_0.348_acc_0.935.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 9.0148e-04 - accuracy: 0.9998 - val_loss: 0.3482 - val_accuracy: 0.9352\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.1978e-04 - accuracy: 0.9998\n",
      "Epoch 00078: val_accuracy improved from 0.93517 to 0.93783, saving model to ./storage/mnist_test_2/kfold6/epoch_078_val_0.347_acc_0.938.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 8.1901e-04 - accuracy: 0.9998 - val_loss: 0.3470 - val_accuracy: 0.9378\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.7716e-04 - accuracy: 0.9997\n",
      "Epoch 00079: val_accuracy did not improve from 0.93783\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.7630e-04 - accuracy: 0.9997 - val_loss: 0.3411 - val_accuracy: 0.9338\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 00080: val_accuracy did not improve from 0.93783\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.3464 - val_accuracy: 0.9352\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.7645e-04 - accuracy: 0.9997\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.93783\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3444 - val_accuracy: 0.9374\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3637e-04 - accuracy: 1.0000\n",
      "Epoch 00082: val_accuracy did not improve from 0.93783\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3608e-04 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9369\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00083: val_accuracy did not improve from 0.93783\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3356 - val_accuracy: 0.9378\n",
      "Epoch 84/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.4898e-04 - accuracy: 0.9999\n",
      "Epoch 00084: val_accuracy improved from 0.93783 to 0.93917, saving model to ./storage/mnist_test_2/kfold6/epoch_084_val_0.337_acc_0.939.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 6.4915e-04 - accuracy: 0.9999 - val_loss: 0.3366 - val_accuracy: 0.9392\n",
      "Epoch 85/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.3184e-04 - accuracy: 0.9997\n",
      "Epoch 00085: val_accuracy did not improve from 0.93917\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.2960e-04 - accuracy: 0.9997 - val_loss: 0.3465 - val_accuracy: 0.9338\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.1463e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.93917\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.1440e-04 - accuracy: 0.9999 - val_loss: 0.3438 - val_accuracy: 0.9361\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.7746e-04 - accuracy: 0.9996\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.93917\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.7663e-04 - accuracy: 0.9996 - val_loss: 0.3446 - val_accuracy: 0.9374\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6080e-04 - accuracy: 0.9998\n",
      "Epoch 00088: val_accuracy did not improve from 0.93917\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.6029e-04 - accuracy: 0.9998 - val_loss: 0.3479 - val_accuracy: 0.9361\n",
      "Epoch 89/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.5030e-04 - accuracy: 0.9999\n",
      "Epoch 00089: val_accuracy did not improve from 0.93917\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.5058e-04 - accuracy: 0.9999 - val_loss: 0.3476 - val_accuracy: 0.9387\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6927e-04 - accuracy: 0.9998\n",
      "Epoch 00090: val_accuracy improved from 0.93917 to 0.93961, saving model to ./storage/mnist_test_2/kfold6/epoch_090_val_0.347_acc_0.940.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 5.6996e-04 - accuracy: 0.9998 - val_loss: 0.3474 - val_accuracy: 0.9396\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00091: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3539 - val_accuracy: 0.9387\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 00092: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.3494 - val_accuracy: 0.9378\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.7594e-04 - accuracy: 0.9999\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.7511e-04 - accuracy: 0.9999 - val_loss: 0.3498 - val_accuracy: 0.9374\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0911e-04 - accuracy: 1.0000\n",
      "Epoch 00094: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.0874e-04 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9365\n",
      "Epoch 95/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.3848e-04 - accuracy: 0.9999\n",
      "Epoch 00095: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.3770e-04 - accuracy: 0.9999 - val_loss: 0.3469 - val_accuracy: 0.9369\n",
      "Epoch 96/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.2505e-04 - accuracy: 0.9998\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.2444e-04 - accuracy: 0.9998 - val_loss: 0.3383 - val_accuracy: 0.9392\n",
      "Epoch 97/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1763e-04 - accuracy: 0.9999\n",
      "Epoch 00097: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.1722e-04 - accuracy: 0.9999 - val_loss: 0.3403 - val_accuracy: 0.9378\n",
      "Epoch 98/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7541e-04 - accuracy: 0.9998 ETA: 0s - loss: 6.9694e\n",
      "Epoch 00098: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.7481e-04 - accuracy: 0.9998 - val_loss: 0.3423 - val_accuracy: 0.9374\n",
      "Epoch 99/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5686e-04 - accuracy: 0.9999\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.5651e-04 - accuracy: 0.9999 - val_loss: 0.3445 - val_accuracy: 0.9361\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2848e-04 - accuracy: 0.9999\n",
      "Epoch 00100: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.3263e-04 - accuracy: 0.9999 - val_loss: 0.3428 - val_accuracy: 0.9396\n",
      "Epoch 101/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0670e-04 - accuracy: 0.9999\n",
      "Epoch 00101: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.0631e-04 - accuracy: 0.9999 - val_loss: 0.3422 - val_accuracy: 0.9396\n",
      "Epoch 102/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5330e-04 - accuracy: 0.9999\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.93961\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5286e-04 - accuracy: 0.9999 - val_loss: 0.3414 - val_accuracy: 0.9383\n",
      "Epoch 103/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5123e-04 - accuracy: 1.0000\n",
      "Epoch 00103: val_accuracy improved from 0.93961 to 0.94094, saving model to ./storage/mnist_test_2/kfold6/epoch_103_val_0.339_acc_0.941.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 3.5088e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9409\n",
      "Epoch 104/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.8821e-04 - accuracy: 1.0000\n",
      "Epoch 00104: val_accuracy did not improve from 0.94094\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.8781e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9392\n",
      "Epoch 105/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.2795e-04 - accuracy: 0.9998\n",
      "Epoch 00105: val_accuracy did not improve from 0.94094\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.2743e-04 - accuracy: 0.9998 - val_loss: 0.3385 - val_accuracy: 0.9409\n",
      "Epoch 106/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8935e-04 - accuracy: 1.0000\n",
      "Epoch 00106: val_accuracy improved from 0.94094 to 0.94139, saving model to ./storage/mnist_test_2/kfold6/epoch_106_val_0.338_acc_0.941.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 2.8908e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9414\n",
      "Epoch 107/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.7129e-04 - accuracy: 0.9999\n",
      "Epoch 00107: val_accuracy did not improve from 0.94139\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7038e-04 - accuracy: 0.9999 - val_loss: 0.3380 - val_accuracy: 0.9414\n",
      "Epoch 108/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.2755e-04 - accuracy: 0.9999\n",
      "Epoch 00108: val_accuracy did not improve from 0.94139\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.2747e-04 - accuracy: 0.9999 - val_loss: 0.3387 - val_accuracy: 0.9414\n",
      "Epoch 109/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5113e-04 - accuracy: 1.0000\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.94139\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.5082e-04 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9409\n",
      "Epoch 110/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0367e-04 - accuracy: 1.0000\n",
      "Epoch 00110: val_accuracy did not improve from 0.94139\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.0337e-04 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9414\n",
      "Epoch 111/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.7066e-04 - accuracy: 0.9998\n",
      "Epoch 00111: val_accuracy did not improve from 0.94139\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.6908e-04 - accuracy: 0.9998 - val_loss: 0.3373 - val_accuracy: 0.9409\n",
      "Epoch 112/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4268e-04 - accuracy: 0.9999\n",
      "Epoch 00112: val_accuracy improved from 0.94139 to 0.94183, saving model to ./storage/mnist_test_2/kfold6/epoch_112_val_0.336_acc_0.942.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 3.4235e-04 - accuracy: 0.9999 - val_loss: 0.3355 - val_accuracy: 0.9418\n",
      "Epoch 113/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.5763e-04 - accuracy: 0.9998\n",
      "Epoch 00113: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.5703e-04 - accuracy: 0.9998 - val_loss: 0.3369 - val_accuracy: 0.9401\n",
      "Epoch 114/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.7374e-04 - accuracy: 0.9999\n",
      "Epoch 00114: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7340e-04 - accuracy: 0.9999 - val_loss: 0.3388 - val_accuracy: 0.9409\n",
      "Epoch 115/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.5934e-04 - accuracy: 0.9998\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.5870e-04 - accuracy: 0.9998 - val_loss: 0.3397 - val_accuracy: 0.9409\n",
      "Epoch 116/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.0851e-04 - accuracy: 1.0000\n",
      "Epoch 00116: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.0824e-04 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9418\n",
      "Epoch 117/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6700e-04 - accuracy: 0.9999\n",
      "Epoch 00117: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.6826e-04 - accuracy: 0.9999 - val_loss: 0.3381 - val_accuracy: 0.9405\n",
      "Epoch 118/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1344e-04 - accuracy: 0.9999\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.1304e-04 - accuracy: 0.9999 - val_loss: 0.3449 - val_accuracy: 0.9401\n",
      "Epoch 119/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.2830e-04 - accuracy: 0.9999\n",
      "Epoch 00119: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.2698e-04 - accuracy: 0.9999 - val_loss: 0.3416 - val_accuracy: 0.9396\n",
      "Epoch 120/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2336e-04 - accuracy: 1.0000\n",
      "Epoch 00120: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.2321e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9405\n",
      "Epoch 121/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.8745e-04 - accuracy: 0.9999\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.9947e-04 - accuracy: 0.9999 - val_loss: 0.3414 - val_accuracy: 0.9401\n",
      "Epoch 122/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.6375e-04 - accuracy: 1.0000\n",
      "Epoch 00122: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.6359e-04 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9392\n",
      "Epoch 123/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7288e-04 - accuracy: 0.9999\n",
      "Epoch 00123: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7352e-04 - accuracy: 0.9999 - val_loss: 0.3386 - val_accuracy: 0.9401\n",
      "Epoch 124/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8906e-04 - accuracy: 1.0000\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.8890e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9392\n",
      "Epoch 125/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7085e-04 - accuracy: 1.0000\n",
      "Epoch 00125: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.7071e-04 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9405\n",
      "Epoch 126/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2699e-04 - accuracy: 1.0000\n",
      "Epoch 00126: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.2973e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9387\n",
      "Epoch 127/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3247e-04 - accuracy: 0.9999\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.3295e-04 - accuracy: 0.9999 - val_loss: 0.3414 - val_accuracy: 0.9401\n",
      "Epoch 128/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.4898e-04 - accuracy: 1.0000\n",
      "Epoch 00128: val_accuracy did not improve from 0.94183\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.4946e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9387\n",
      "Epoch 129/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.4033e-04 - accuracy: 1.0000\n",
      "Epoch 00129: val_accuracy improved from 0.94183 to 0.94227, saving model to ./storage/mnist_test_2/kfold6/epoch_129_val_0.343_acc_0.942.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 3.2013e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9423\n",
      "Epoch 130/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.9037e-04 - accuracy: 0.9999\n",
      "Epoch 00130: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.8964e-04 - accuracy: 0.9999 - val_loss: 0.3390 - val_accuracy: 0.9423\n",
      "Epoch 131/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.3355e-04 - accuracy: 0.9999\n",
      "Epoch 00131: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.4200e-04 - accuracy: 0.9999 - val_loss: 0.3392 - val_accuracy: 0.9401\n",
      "Epoch 132/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.3071e-04 - accuracy: 1.0000\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 3.0223149224184457e-06.\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.3669e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9396\n",
      "Epoch 133/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1799e-04 - accuracy: 1.0000\n",
      "Epoch 00133: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.1778e-04 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9418\n",
      "Epoch 134/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6015e-04 - accuracy: 0.9999\n",
      "Epoch 00134: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.6191e-04 - accuracy: 0.9999 - val_loss: 0.3419 - val_accuracy: 0.9405\n",
      "Epoch 135/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2515e-04 - accuracy: 1.0000 ETA: 0s - loss: 2.3053e-0\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 2.4178520106943328e-06.\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.2493e-04 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9401\n",
      "Epoch 136/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.1599e-04 - accuracy: 1.0000\n",
      "Epoch 00136: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.1565e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9405\n",
      "Epoch 137/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3857e-04 - accuracy: 0.9998\n",
      "Epoch 00137: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3820e-04 - accuracy: 0.9998 - val_loss: 0.3468 - val_accuracy: 0.9387\n",
      "Epoch 138/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.6741e-04 - accuracy: 0.9999\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 1.9342816813150422e-06.\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.6648e-04 - accuracy: 0.9999 - val_loss: 0.3425 - val_accuracy: 0.9409\n",
      "Epoch 139/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2379e-04 - accuracy: 0.9999\n",
      "Epoch 00139: val_accuracy did not improve from 0.94227\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.2347e-04 - accuracy: 0.9999 - val_loss: 0.3432 - val_accuracy: 0.9405\n",
      "Epoch 140/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3898e-04 - accuracy: 0.9999\n",
      "Epoch 00140: val_accuracy improved from 0.94227 to 0.94272, saving model to ./storage/mnist_test_2/kfold6/epoch_140_val_0.342_acc_0.943.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 3.3880e-04 - accuracy: 0.9999 - val_loss: 0.3424 - val_accuracy: 0.9427\n",
      "Epoch 141/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2502e-04 - accuracy: 0.9999\n",
      "Epoch 00141: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.2483e-04 - accuracy: 0.9999 - val_loss: 0.3440 - val_accuracy: 0.9418\n",
      "Epoch 142/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.1475e-04 - accuracy: 0.9999\n",
      "Epoch 00142: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.1429e-04 - accuracy: 0.9999 - val_loss: 0.3379 - val_accuracy: 0.9409\n",
      "Epoch 143/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2752e-04 - accuracy: 0.9999\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1.547425381431822e-06.\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.2723e-04 - accuracy: 0.9999 - val_loss: 0.3427 - val_accuracy: 0.9387\n",
      "Epoch 144/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1354e-04 - accuracy: 1.0000\n",
      "Epoch 00144: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.1338e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9414\n",
      "Epoch 145/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5358e-04 - accuracy: 0.9999\n",
      "Epoch 00145: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.5485e-04 - accuracy: 0.9999 - val_loss: 0.3435 - val_accuracy: 0.9409\n",
      "Epoch 146/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.3039e-04 - accuracy: 1.0000\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.2379403415252455e-06.\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.3021e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9392\n",
      "Epoch 147/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.2137e-04 - accuracy: 0.9998\n",
      "Epoch 00147: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.2076e-04 - accuracy: 0.9998 - val_loss: 0.3434 - val_accuracy: 0.9414\n",
      "Epoch 148/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.6344e-04 - accuracy: 1.0000\n",
      "Epoch 00148: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9387\n",
      "Epoch 149/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7766e-04 - accuracy: 1.0000\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 9.903522368404083e-07.\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.7754e-04 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9405\n",
      "Epoch 150/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.4726e-04 - accuracy: 0.9997\n",
      "Epoch 00150: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.4643e-04 - accuracy: 0.9997 - val_loss: 0.3394 - val_accuracy: 0.9392\n",
      "Epoch 151/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.1564e-04 - accuracy: 1.0000\n",
      "Epoch 00151: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.1521e-04 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9396\n",
      "Epoch 152/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.2841e-04 - accuracy: 1.0000\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 7.922817530925386e-07.\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 1.2821e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9401\n",
      "Epoch 153/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2039e-04 - accuracy: 0.9998\n",
      "Epoch 00153: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.2005e-04 - accuracy: 0.9998 - val_loss: 0.3438 - val_accuracy: 0.9396\n",
      "Epoch 154/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2631e-04 - accuracy: 0.9998\n",
      "Epoch 00154: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.2597e-04 - accuracy: 0.9998 - val_loss: 0.3426 - val_accuracy: 0.9392\n",
      "Epoch 155/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.6774e-04 - accuracy: 1.0000\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 6.338254024740309e-07.\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.6749e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9396\n",
      "Epoch 156/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8293e-04 - accuracy: 0.9999\n",
      "Epoch 00156: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.8256e-04 - accuracy: 0.9999 - val_loss: 0.3421 - val_accuracy: 0.9418\n",
      "Epoch 157/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7449e-04 - accuracy: 0.9998\n",
      "Epoch 00157: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7414e-04 - accuracy: 0.9998 - val_loss: 0.3420 - val_accuracy: 0.9405\n",
      "Epoch 158/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.0272e-04 - accuracy: 0.9999\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 5.070603037893307e-07.\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.0253e-04 - accuracy: 0.9999 - val_loss: 0.3439 - val_accuracy: 0.9414\n",
      "Epoch 159/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.0495e-04 - accuracy: 1.0000\n",
      "Epoch 00159: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.0475e-04 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9401\n",
      "Epoch 160/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3839e-04 - accuracy: 0.9999\n",
      "Epoch 00160: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.4108e-04 - accuracy: 0.9999 - val_loss: 0.3432 - val_accuracy: 0.9427\n",
      "Epoch 161/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.3517e-04 - accuracy: 0.9999\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 4.056482339365175e-07.\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3407e-04 - accuracy: 0.9999 - val_loss: 0.3423 - val_accuracy: 0.9405\n",
      "Epoch 162/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9630e-04 - accuracy: 0.9999\n",
      "Epoch 00162: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9591e-04 - accuracy: 0.9999 - val_loss: 0.3434 - val_accuracy: 0.9401\n",
      "Epoch 163/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.4009e-04 - accuracy: 1.0000\n",
      "Epoch 00163: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.4002e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9423\n",
      "Epoch 164/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.3710e-04 - accuracy: 1.0000\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 3.24518578054267e-07.\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.3690e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9405\n",
      "Epoch 165/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1158e-04 - accuracy: 1.0000\n",
      "Epoch 00165: val_accuracy did not improve from 0.94272\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.1137e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9405\n",
      "************ Fold 7 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8077 - accuracy: 0.4130\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62256, saving model to ./storage/mnist_test_2/kfold7/epoch_001_val_1.142_acc_0.623.h5\n",
      "20276/20276 [==============================] - 28s 1ms/sample - loss: 1.8072 - accuracy: 0.4131 - val_loss: 1.1418 - val_accuracy: 0.6226\n",
      "Epoch 2/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.0373 - accuracy: 0.6538\n",
      "Epoch 00002: val_accuracy improved from 0.62256 to 0.69005, saving model to ./storage/mnist_test_2/kfold7/epoch_002_val_0.929_acc_0.690.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0368 - accuracy: 0.6540 - val_loss: 0.9290 - val_accuracy: 0.6901\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7343 - accuracy: 0.7566\n",
      "Epoch 00003: val_accuracy improved from 0.69005 to 0.78908, saving model to ./storage/mnist_test_2/kfold7/epoch_003_val_0.658_acc_0.789.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7342 - accuracy: 0.7567 - val_loss: 0.6584 - val_accuracy: 0.7891\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.8161\n",
      "Epoch 00004: val_accuracy improved from 0.78908 to 0.83393, saving model to ./storage/mnist_test_2/kfold7/epoch_004_val_0.541_acc_0.834.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5545 - accuracy: 0.8162 - val_loss: 0.5412 - val_accuracy: 0.8339\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4339 - accuracy: 0.8617\n",
      "Epoch 00005: val_accuracy improved from 0.83393 to 0.83881, saving model to ./storage/mnist_test_2/kfold7/epoch_005_val_0.509_acc_0.839.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.4337 - accuracy: 0.8618 - val_loss: 0.5094 - val_accuracy: 0.8388\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3446 - accuracy: 0.8863\n",
      "Epoch 00006: val_accuracy did not improve from 0.83881\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.3444 - accuracy: 0.8863 - val_loss: 0.5417 - val_accuracy: 0.8242\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.9031\n",
      "Epoch 00007: val_accuracy improved from 0.83881 to 0.86679, saving model to ./storage/mnist_test_2/kfold7/epoch_007_val_0.444_acc_0.867.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2964 - accuracy: 0.9031 - val_loss: 0.4442 - val_accuracy: 0.8668\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9231\n",
      "Epoch 00008: val_accuracy did not improve from 0.86679\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2380 - accuracy: 0.9230 - val_loss: 0.4654 - val_accuracy: 0.8650\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1998 - accuracy: 0.9349\n",
      "Epoch 00009: val_accuracy improved from 0.86679 to 0.87078, saving model to ./storage/mnist_test_2/kfold7/epoch_009_val_0.458_acc_0.871.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2001 - accuracy: 0.9348 - val_loss: 0.4580 - val_accuracy: 0.8708\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9413\n",
      "Epoch 00010: val_accuracy did not improve from 0.87078\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1790 - accuracy: 0.9413 - val_loss: 0.4789 - val_accuracy: 0.8681\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9463\n",
      "Epoch 00011: val_accuracy did not improve from 0.87078\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1647 - accuracy: 0.9463 - val_loss: 0.4846 - val_accuracy: 0.8655\n",
      "Epoch 12/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1493 - accuracy: 0.9502\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87078\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1493 - accuracy: 0.9501 - val_loss: 0.4791 - val_accuracy: 0.8708\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9744\n",
      "Epoch 00013: val_accuracy improved from 0.87078 to 0.87611, saving model to ./storage/mnist_test_2/kfold7/epoch_013_val_0.474_acc_0.876.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0806 - accuracy: 0.9744 - val_loss: 0.4737 - val_accuracy: 0.8761\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9755\n",
      "Epoch 00014: val_accuracy did not improve from 0.87611\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0730 - accuracy: 0.9755 - val_loss: 0.4998 - val_accuracy: 0.8739\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9706\n",
      "Epoch 00015: val_accuracy improved from 0.87611 to 0.88499, saving model to ./storage/mnist_test_2/kfold7/epoch_015_val_0.480_acc_0.885.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0904 - accuracy: 0.9706 - val_loss: 0.4802 - val_accuracy: 0.8850\n",
      "Epoch 16/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9747\n",
      "Epoch 00016: val_accuracy improved from 0.88499 to 0.89298, saving model to ./storage/mnist_test_2/kfold7/epoch_016_val_0.466_acc_0.893.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0770 - accuracy: 0.9747 - val_loss: 0.4658 - val_accuracy: 0.8930\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9810\n",
      "Epoch 00017: val_accuracy did not improve from 0.89298\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.4854 - val_accuracy: 0.8823\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9690\n",
      "Epoch 00018: val_accuracy did not improve from 0.89298\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0996 - accuracy: 0.9690 - val_loss: 0.5655 - val_accuracy: 0.8712\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9752\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89298\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0764 - accuracy: 0.9751 - val_loss: 0.4942 - val_accuracy: 0.8837\n",
      "Epoch 20/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9871\n",
      "Epoch 00020: val_accuracy improved from 0.89298 to 0.90142, saving model to ./storage/mnist_test_2/kfold7/epoch_020_val_0.422_acc_0.901.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.4224 - val_accuracy: 0.9014\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9909\n",
      "Epoch 00021: val_accuracy did not improve from 0.90142\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.4950 - val_accuracy: 0.8965\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9898\n",
      "Epoch 00022: val_accuracy did not improve from 0.90142\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0323 - accuracy: 0.9898 - val_loss: 0.4909 - val_accuracy: 0.8956\n",
      "Epoch 23/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9885\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90142\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.5093 - val_accuracy: 0.8925\n",
      "Epoch 24/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9897\n",
      "Epoch 00024: val_accuracy improved from 0.90142 to 0.90853, saving model to ./storage/mnist_test_2/kfold7/epoch_024_val_0.431_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.4308 - val_accuracy: 0.9085\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9927\n",
      "Epoch 00025: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.4339 - val_accuracy: 0.9076\n",
      "Epoch 26/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9919\n",
      "Epoch 00026: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.4448 - val_accuracy: 0.9045\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9923\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.4589 - val_accuracy: 0.9045\n",
      "Epoch 28/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 00028: val_accuracy improved from 0.90853 to 0.91252, saving model to ./storage/mnist_test_2/kfold7/epoch_028_val_0.423_acc_0.913.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.4232 - val_accuracy: 0.9125\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9949\n",
      "Epoch 00029: val_accuracy did not improve from 0.91252\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.4646 - val_accuracy: 0.9041\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9953\n",
      "Epoch 00030: val_accuracy did not improve from 0.91252\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.4491 - val_accuracy: 0.9028\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9941\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.91252\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.4838 - val_accuracy: 0.9014\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9949\n",
      "Epoch 00032: val_accuracy did not improve from 0.91252\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.4634 - val_accuracy: 0.9059\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00033: val_accuracy did not improve from 0.91252\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.4474 - val_accuracy: 0.9063\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.91252\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4592 - val_accuracy: 0.9081\n",
      "Epoch 35/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 00035: val_accuracy improved from 0.91252 to 0.91563, saving model to ./storage/mnist_test_2/kfold7/epoch_035_val_0.446_acc_0.916.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.4458 - val_accuracy: 0.9156\n",
      "Epoch 36/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00036: val_accuracy did not improve from 0.91563\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.4348 - val_accuracy: 0.9116\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9972\n",
      "Epoch 00037: val_accuracy did not improve from 0.91563\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.4585 - val_accuracy: 0.9094\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 00038: val_accuracy improved from 0.91563 to 0.91607, saving model to ./storage/mnist_test_2/kfold7/epoch_038_val_0.464_acc_0.916.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.4642 - val_accuracy: 0.9161\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00039: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.4487 - val_accuracy: 0.9099\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 00040: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.4634 - val_accuracy: 0.9134\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 00041: val_accuracy improved from 0.91607 to 0.91874, saving model to ./storage/mnist_test_2/kfold7/epoch_041_val_0.463_acc_0.919.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.4630 - val_accuracy: 0.9187\n",
      "Epoch 42/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 00042: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.5004 - val_accuracy: 0.9072\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 00043: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4932 - val_accuracy: 0.9094\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.4922 - val_accuracy: 0.9161\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 00045: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.4756 - val_accuracy: 0.9174\n",
      "Epoch 46/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 00046: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.4955 - val_accuracy: 0.9165\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4999 - val_accuracy: 0.9125\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00048: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4795 - val_accuracy: 0.9152\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 00049: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.4846 - val_accuracy: 0.9165\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.4831 - val_accuracy: 0.9130\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00051: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4702 - val_accuracy: 0.9174\n",
      "Epoch 52/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00052: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4826 - val_accuracy: 0.9187\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4793 - val_accuracy: 0.9165\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00054: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.4801 - val_accuracy: 0.9183\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00055: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4610 - val_accuracy: 0.9183\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00056: val_accuracy improved from 0.91874 to 0.91963, saving model to ./storage/mnist_test_2/kfold7/epoch_056_val_0.470_acc_0.920.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.4699 - val_accuracy: 0.9196\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995 ETA: \n",
      "Epoch 00057: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4647 - val_accuracy: 0.9192\n",
      "Epoch 58/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00058: val_accuracy improved from 0.91963 to 0.92229, saving model to ./storage/mnist_test_2/kfold7/epoch_058_val_0.456_acc_0.922.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4563 - val_accuracy: 0.9223\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00059: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4591 - val_accuracy: 0.9205\n",
      "Epoch 60/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00060: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4743 - val_accuracy: 0.9214\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4655 - val_accuracy: 0.9201\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00062: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.4727 - val_accuracy: 0.9218\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 00063: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4678 - val_accuracy: 0.9223\n",
      "Epoch 64/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4772 - val_accuracy: 0.9218\n",
      "Epoch 65/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.8703e-04 - accuracy: 0.9998\n",
      "Epoch 00065: val_accuracy improved from 0.92229 to 0.92407, saving model to ./storage/mnist_test_2/kfold7/epoch_065_val_0.473_acc_0.924.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 8.8538e-04 - accuracy: 0.9998 - val_loss: 0.4733 - val_accuracy: 0.9241\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00066: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4729 - val_accuracy: 0.9214\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.2489e-04 - accuracy: 0.9998\n",
      "Epoch 00067: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.2408e-04 - accuracy: 0.9998 - val_loss: 0.4685 - val_accuracy: 0.9214\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4786 - val_accuracy: 0.9210\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996 ETA: 0s - loss: 0.0012 - accura\n",
      "Epoch 00069: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4826 - val_accuracy: 0.9187\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.3106e-04 - accuracy: 0.9999\n",
      "Epoch 00070: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.3048e-04 - accuracy: 0.9999 - val_loss: 0.4727 - val_accuracy: 0.9214\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4714 - val_accuracy: 0.9227\n",
      "Epoch 72/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.6991e-04 - accuracy: 0.9998\n",
      "Epoch 00072: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.6784e-04 - accuracy: 0.9998 - val_loss: 0.4737 - val_accuracy: 0.9223\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.4748 - val_accuracy: 0.9187\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.0267e-04 - accuracy: 0.9998\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.0197e-04 - accuracy: 0.9998 - val_loss: 0.4776 - val_accuracy: 0.9192\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.5931e-04 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.5863e-04 - accuracy: 0.9997 - val_loss: 0.4768 - val_accuracy: 0.9183\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.4922e-04 - accuracy: 0.9999\n",
      "Epoch 00076: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.4987e-04 - accuracy: 0.9999 - val_loss: 0.4778 - val_accuracy: 0.9192\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7991e-04 - accuracy: 0.9999\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.7925e-04 - accuracy: 0.9999 - val_loss: 0.4850 - val_accuracy: 0.9192\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.3034e-04 - accuracy: 0.9998\n",
      "Epoch 00078: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.2877e-04 - accuracy: 0.9998 - val_loss: 0.4800 - val_accuracy: 0.9196\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.8079e-04 - accuracy: 0.9998\n",
      "Epoch 00079: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.8009e-04 - accuracy: 0.9998 - val_loss: 0.4805 - val_accuracy: 0.9210\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.4146e-04 - accuracy: 0.9999\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.4097e-04 - accuracy: 0.9999 - val_loss: 0.4814 - val_accuracy: 0.9196\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.7663e-04 - accuracy: 0.9999\n",
      "Epoch 00081: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.7921e-04 - accuracy: 0.9999 - val_loss: 0.4877 - val_accuracy: 0.9192\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5099e-04 - accuracy: 0.9999\n",
      "Epoch 00082: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5056e-04 - accuracy: 0.9999 - val_loss: 0.4840 - val_accuracy: 0.9201\n",
      "Epoch 83/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.7838e-04 - accuracy: 0.9998\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.7835e-04 - accuracy: 0.9998 - val_loss: 0.4859 - val_accuracy: 0.9210\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8648e-04 - accuracy: 1.0000\n",
      "Epoch 00084: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9049e-04 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9214\n",
      "Epoch 85/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.5796e-04 - accuracy: 0.9999\n",
      "Epoch 00085: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5679e-04 - accuracy: 0.9999 - val_loss: 0.4788 - val_accuracy: 0.9223\n",
      "Epoch 86/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.1177e-04 - accuracy: 0.9998\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.1064e-04 - accuracy: 0.9998 - val_loss: 0.4866 - val_accuracy: 0.9214\n",
      "Epoch 87/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.3455e-04 - accuracy: 0.9999\n",
      "Epoch 00087: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3344e-04 - accuracy: 0.9999 - val_loss: 0.4818 - val_accuracy: 0.9192\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.9504e-04 - accuracy: 0.9997\n",
      "Epoch 00088: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.9436e-04 - accuracy: 0.9997 - val_loss: 0.4790 - val_accuracy: 0.9210\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.7074e-04 - accuracy: 0.9998\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.7015e-04 - accuracy: 0.9998 - val_loss: 0.4774 - val_accuracy: 0.9232\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7878e-04 - accuracy: 0.9997\n",
      "Epoch 00090: val_accuracy did not improve from 0.92407\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 6.7811e-04 - accuracy: 0.9997 - val_loss: 0.4767 - val_accuracy: 0.9214\n",
      "************ Fold 8 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.8046 - accuracy: 0.4155\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58837, saving model to ./storage/mnist_test_2/kfold8/epoch_001_val_1.235_acc_0.588.h5\n",
      "20276/20276 [==============================] - 29s 1ms/sample - loss: 1.8034 - accuracy: 0.4157 - val_loss: 1.2352 - val_accuracy: 0.5884\n",
      "Epoch 2/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.0300 - accuracy: 0.6550\n",
      "Epoch 00002: val_accuracy improved from 0.58837 to 0.71714, saving model to ./storage/mnist_test_2/kfold8/epoch_002_val_0.834_acc_0.717.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0301 - accuracy: 0.6551 - val_loss: 0.8336 - val_accuracy: 0.7171\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7230 - accuracy: 0.7605\n",
      "Epoch 00003: val_accuracy improved from 0.71714 to 0.76776, saving model to ./storage/mnist_test_2/kfold8/epoch_003_val_0.744_acc_0.768.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7230 - accuracy: 0.7605 - val_loss: 0.7444 - val_accuracy: 0.7678\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.8182\n",
      "Epoch 00004: val_accuracy improved from 0.76776 to 0.79130, saving model to ./storage/mnist_test_2/kfold8/epoch_004_val_0.638_acc_0.791.h5\n",
      "20276/20276 [==============================] - 23s 1ms/sample - loss: 0.5495 - accuracy: 0.8182 - val_loss: 0.6384 - val_accuracy: 0.7913\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8628\n",
      "Epoch 00005: val_accuracy improved from 0.79130 to 0.84147, saving model to ./storage/mnist_test_2/kfold8/epoch_005_val_0.494_acc_0.841.h5\n",
      "20276/20276 [==============================] - 23s 1ms/sample - loss: 0.4243 - accuracy: 0.8628 - val_loss: 0.4942 - val_accuracy: 0.8415\n",
      "Epoch 6/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3486 - accuracy: 0.8875\n",
      "Epoch 00006: val_accuracy did not improve from 0.84147\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.3486 - accuracy: 0.8875 - val_loss: 0.5317 - val_accuracy: 0.8410\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2915 - accuracy: 0.9052\n",
      "Epoch 00007: val_accuracy improved from 0.84147 to 0.84858, saving model to ./storage/mnist_test_2/kfold8/epoch_007_val_0.525_acc_0.849.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2916 - accuracy: 0.9052 - val_loss: 0.5255 - val_accuracy: 0.8486\n",
      "Epoch 8/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.9174\n",
      "Epoch 00008: val_accuracy improved from 0.84858 to 0.86146, saving model to ./storage/mnist_test_2/kfold8/epoch_008_val_0.505_acc_0.861.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.2559 - accuracy: 0.9174 - val_loss: 0.5052 - val_accuracy: 0.8615\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9274\n",
      "Epoch 00009: val_accuracy did not improve from 0.86146\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2224 - accuracy: 0.9275 - val_loss: 0.5421 - val_accuracy: 0.8424\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9361\n",
      "Epoch 00010: val_accuracy did not improve from 0.86146\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1982 - accuracy: 0.9360 - val_loss: 0.5537 - val_accuracy: 0.8508\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9439\n",
      "Epoch 00011: val_accuracy improved from 0.86146 to 0.86856, saving model to ./storage/mnist_test_2/kfold8/epoch_011_val_0.480_acc_0.869.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1700 - accuracy: 0.9440 - val_loss: 0.4799 - val_accuracy: 0.8686\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9537\n",
      "Epoch 00012: val_accuracy did not improve from 0.86856\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1408 - accuracy: 0.9537 - val_loss: 0.5622 - val_accuracy: 0.8619\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9548\n",
      "Epoch 00013: val_accuracy did not improve from 0.86856\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1393 - accuracy: 0.9548 - val_loss: 0.5096 - val_accuracy: 0.8677\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9575\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.86856\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1309 - accuracy: 0.9576 - val_loss: 0.5144 - val_accuracy: 0.8628\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 0.9735 ETA: 0s - loss: 0\n",
      "Epoch 00015: val_accuracy improved from 0.86856 to 0.88677, saving model to ./storage/mnist_test_2/kfold8/epoch_015_val_0.450_acc_0.887.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0832 - accuracy: 0.9735 - val_loss: 0.4499 - val_accuracy: 0.8868\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9810\n",
      "Epoch 00016: val_accuracy improved from 0.88677 to 0.89076, saving model to ./storage/mnist_test_2/kfold8/epoch_016_val_0.463_acc_0.891.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.4627 - val_accuracy: 0.8908\n",
      "Epoch 17/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9771\n",
      "Epoch 00017: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0698 - accuracy: 0.9771 - val_loss: 0.4819 - val_accuracy: 0.8712\n",
      "Epoch 18/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9756\n",
      "Epoch 00018: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0749 - accuracy: 0.9755 - val_loss: 0.5405 - val_accuracy: 0.8694\n",
      "Epoch 19/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9816\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0586 - accuracy: 0.9816 - val_loss: 0.5085 - val_accuracy: 0.8814\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9873\n",
      "Epoch 00020: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0386 - accuracy: 0.9873 - val_loss: 0.4748 - val_accuracy: 0.8845\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 0.9844\n",
      "Epoch 00021: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0486 - accuracy: 0.9844 - val_loss: 0.5259 - val_accuracy: 0.8854\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0381 - accuracy: 0.9878\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.5208 - val_accuracy: 0.8850\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 00023: val_accuracy improved from 0.89076 to 0.89609, saving model to ./storage/mnist_test_2/kfold8/epoch_023_val_0.481_acc_0.896.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.4811 - val_accuracy: 0.8961\n",
      "Epoch 24/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9922\n",
      "Epoch 00024: val_accuracy did not improve from 0.89609\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.4693 - val_accuracy: 0.8934\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9917\n",
      "Epoch 00025: val_accuracy improved from 0.89609 to 0.89698, saving model to ./storage/mnist_test_2/kfold8/epoch_025_val_0.462_acc_0.897.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.4620 - val_accuracy: 0.8970\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9921\n",
      "Epoch 00026: val_accuracy improved from 0.89698 to 0.90453, saving model to ./storage/mnist_test_2/kfold8/epoch_026_val_0.442_acc_0.905.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.4415 - val_accuracy: 0.9045\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 00027: val_accuracy did not improve from 0.90453\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.4955 - val_accuracy: 0.8908\n",
      "Epoch 28/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9889\n",
      "Epoch 00028: val_accuracy did not improve from 0.90453\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.5534 - val_accuracy: 0.8854\n",
      "Epoch 29/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9899\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90453\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.4884 - val_accuracy: 0.8988\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9934\n",
      "Epoch 00030: val_accuracy did not improve from 0.90453\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.4353 - val_accuracy: 0.9023\n",
      "Epoch 31/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 00031: val_accuracy improved from 0.90453 to 0.90719, saving model to ./storage/mnist_test_2/kfold8/epoch_031_val_0.465_acc_0.907.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.4650 - val_accuracy: 0.9072\n",
      "Epoch 32/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 00032: val_accuracy did not improve from 0.90719\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.5009 - val_accuracy: 0.9005\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9947\n",
      "Epoch 00033: val_accuracy did not improve from 0.90719\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.4873 - val_accuracy: 0.9041\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90719\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.4944 - val_accuracy: 0.8992\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 00035: val_accuracy did not improve from 0.90719\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.4651 - val_accuracy: 0.9023\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 00036: val_accuracy did not improve from 0.90719\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.4903 - val_accuracy: 0.9072\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9964\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90719\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.4987 - val_accuracy: 0.9050\n",
      "Epoch 38/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9964\n",
      "Epoch 00038: val_accuracy improved from 0.90719 to 0.90808, saving model to ./storage/mnist_test_2/kfold8/epoch_038_val_0.492_acc_0.908.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4916 - val_accuracy: 0.9081\n",
      "Epoch 39/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 00039: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.5063 - val_accuracy: 0.9081\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00040: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.4976 - val_accuracy: 0.9045\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9988\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.5113 - val_accuracy: 0.9036\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00042: val_accuracy improved from 0.90808 to 0.91075, saving model to ./storage/mnist_test_2/kfold8/epoch_042_val_0.475_acc_0.911.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.4749 - val_accuracy: 0.9107\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9981\n",
      "Epoch 00043: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.4773 - val_accuracy: 0.9076\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 00044: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.4653 - val_accuracy: 0.9081\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4948 - val_accuracy: 0.9050\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 00046: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.4806 - val_accuracy: 0.9067\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00047: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.4602 - val_accuracy: 0.9072\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.91075\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4652 - val_accuracy: 0.9063\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 00049: val_accuracy improved from 0.91075 to 0.91208, saving model to ./storage/mnist_test_2/kfold8/epoch_049_val_0.463_acc_0.912.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.4634 - val_accuracy: 0.9121\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 00050: val_accuracy improved from 0.91208 to 0.91519, saving model to ./storage/mnist_test_2/kfold8/epoch_050_val_0.454_acc_0.915.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.4537 - val_accuracy: 0.9152\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 00051: val_accuracy improved from 0.91519 to 0.91918, saving model to ./storage/mnist_test_2/kfold8/epoch_051_val_0.454_acc_0.919.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4543 - val_accuracy: 0.9192\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00052: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.4548 - val_accuracy: 0.9143\n",
      "Epoch 53/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00053: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4631 - val_accuracy: 0.9099\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.4615 - val_accuracy: 0.9156\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00055: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4656 - val_accuracy: 0.9170\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00056: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4482 - val_accuracy: 0.9179\n",
      "Epoch 57/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.4597 - val_accuracy: 0.9183\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00058: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4643 - val_accuracy: 0.9192\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00059: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.4787 - val_accuracy: 0.9139\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4787 - val_accuracy: 0.9179\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00061: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4765 - val_accuracy: 0.9152\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00062: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4786 - val_accuracy: 0.9165\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 00063: val_accuracy improved from 0.91918 to 0.92052, saving model to ./storage/mnist_test_2/kfold8/epoch_063_val_0.469_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.4692 - val_accuracy: 0.9205\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00064: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4692 - val_accuracy: 0.9196\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00065: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4803 - val_accuracy: 0.9170\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00066: val_accuracy improved from 0.92052 to 0.92140, saving model to ./storage/mnist_test_2/kfold8/epoch_066_val_0.472_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4717 - val_accuracy: 0.9214\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.3407e-04 - accuracy: 0.9998\n",
      "Epoch 00067: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.3473e-04 - accuracy: 0.9998 - val_loss: 0.4713 - val_accuracy: 0.9214\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.8721e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.8638e-04 - accuracy: 0.9998 - val_loss: 0.4732 - val_accuracy: 0.9210\n",
      "Epoch 69/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.2323e-04 - accuracy: 0.9998\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.2161e-04 - accuracy: 0.9998 - val_loss: 0.4731 - val_accuracy: 0.9196\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.9333e-04 - accuracy: 0.9997\n",
      "Epoch 00070: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.9556e-04 - accuracy: 0.9997 - val_loss: 0.4746 - val_accuracy: 0.9196\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.0074e-04 - accuracy: 0.9998\n",
      "Epoch 00071: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.0522e-04 - accuracy: 0.9998 - val_loss: 0.4823 - val_accuracy: 0.9179\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.7864e-04 - accuracy: 0.9997\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.7828e-04 - accuracy: 0.9997 - val_loss: 0.4944 - val_accuracy: 0.9134\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00073: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4937 - val_accuracy: 0.9152\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7979e-04 - accuracy: 0.9999\n",
      "Epoch 00074: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.8117e-04 - accuracy: 0.9999 - val_loss: 0.4933 - val_accuracy: 0.9156\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.5704e-04 - accuracy: 0.9998\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.5645e-04 - accuracy: 0.9998 - val_loss: 0.4944 - val_accuracy: 0.9143\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.3723e-04 - accuracy: 0.9999\n",
      "Epoch 00076: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.3654e-04 - accuracy: 0.9999 - val_loss: 0.4881 - val_accuracy: 0.9147\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.8907e-04 - accuracy: 0.9999\n",
      "Epoch 00077: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.8820e-04 - accuracy: 0.9999 - val_loss: 0.4862 - val_accuracy: 0.9174\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.8623e-04 - accuracy: 0.9999\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.8465e-04 - accuracy: 0.9999 - val_loss: 0.4839 - val_accuracy: 0.9143\n",
      "Epoch 79/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00079: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4840 - val_accuracy: 0.9179\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.2213e-04 - accuracy: 0.9997\n",
      "Epoch 00080: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.2219e-04 - accuracy: 0.9997 - val_loss: 0.4851 - val_accuracy: 0.9156\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3598e-04 - accuracy: 0.9998\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.3537e-04 - accuracy: 0.9998 - val_loss: 0.4814 - val_accuracy: 0.9139\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.7764e-04 - accuracy: 0.9998\n",
      "Epoch 00082: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.7688e-04 - accuracy: 0.9998 - val_loss: 0.4749 - val_accuracy: 0.9183\n",
      "Epoch 83/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.5162e-04 - accuracy: 0.9999\n",
      "Epoch 00083: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5048e-04 - accuracy: 0.9999 - val_loss: 0.4822 - val_accuracy: 0.9161\n",
      "Epoch 84/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.3794e-04 - accuracy: 1.0000\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.3714e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9156\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.6994e-04 - accuracy: 0.9999\n",
      "Epoch 00085: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.6929e-04 - accuracy: 0.9999 - val_loss: 0.4800 - val_accuracy: 0.9165\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.2567e-04 - accuracy: 0.9998\n",
      "Epoch 00086: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.2501e-04 - accuracy: 0.9998 - val_loss: 0.4793 - val_accuracy: 0.9156\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.2455e-04 - accuracy: 0.9999\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.2414e-04 - accuracy: 0.9999 - val_loss: 0.4728 - val_accuracy: 0.9179\n",
      "Epoch 88/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.2176e-04 - accuracy: 0.9999\n",
      "Epoch 00088: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.2046e-04 - accuracy: 0.9999 - val_loss: 0.4785 - val_accuracy: 0.9165\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2082e-04 - accuracy: 0.9999\n",
      "Epoch 00089: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.2042e-04 - accuracy: 0.9999 - val_loss: 0.4759 - val_accuracy: 0.9179\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8767e-04 - accuracy: 1.0000\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.8730e-04 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9179\n",
      "Epoch 91/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.7215e-04 - accuracy: 0.9999\n",
      "Epoch 00091: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.7135e-04 - accuracy: 0.9999 - val_loss: 0.4707 - val_accuracy: 0.9192\n",
      "************ Fold 9 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7899 - accuracy: 0.4137\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59369, saving model to ./storage/mnist_test_2/kfold9/epoch_001_val_1.235_acc_0.594.h5\n",
      "20276/20276 [==============================] - 28s 1ms/sample - loss: 1.7898 - accuracy: 0.4137 - val_loss: 1.2347 - val_accuracy: 0.5937\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0588 - accuracy: 0.6482\n",
      "Epoch 00002: val_accuracy improved from 0.59369 to 0.71758, saving model to ./storage/mnist_test_2/kfold9/epoch_002_val_0.849_acc_0.718.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 1.0592 - accuracy: 0.6481 - val_loss: 0.8491 - val_accuracy: 0.7176\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7383 - accuracy: 0.7585\n",
      "Epoch 00003: val_accuracy improved from 0.71758 to 0.78197, saving model to ./storage/mnist_test_2/kfold9/epoch_003_val_0.655_acc_0.782.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.7381 - accuracy: 0.7586 - val_loss: 0.6545 - val_accuracy: 0.7820\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5552 - accuracy: 0.8190\n",
      "Epoch 00004: val_accuracy improved from 0.78197 to 0.80107, saving model to ./storage/mnist_test_2/kfold9/epoch_004_val_0.629_acc_0.801.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.5561 - accuracy: 0.8187 - val_loss: 0.6293 - val_accuracy: 0.8011\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4439 - accuracy: 0.8561\n",
      "Epoch 00005: val_accuracy improved from 0.80107 to 0.83259, saving model to ./storage/mnist_test_2/kfold9/epoch_005_val_0.533_acc_0.833.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.4443 - accuracy: 0.8560 - val_loss: 0.5332 - val_accuracy: 0.8326\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.8903\n",
      "Epoch 00006: val_accuracy improved from 0.83259 to 0.84725, saving model to ./storage/mnist_test_2/kfold9/epoch_006_val_0.492_acc_0.847.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3405 - accuracy: 0.8903 - val_loss: 0.4923 - val_accuracy: 0.8472\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3066 - accuracy: 0.9010\n",
      "Epoch 00007: val_accuracy improved from 0.84725 to 0.85835, saving model to ./storage/mnist_test_2/kfold9/epoch_007_val_0.437_acc_0.858.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.3064 - accuracy: 0.9010 - val_loss: 0.4371 - val_accuracy: 0.8583\n",
      "Epoch 8/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.9303\n",
      "Epoch 00008: val_accuracy did not improve from 0.85835\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.2165 - accuracy: 0.9301 - val_loss: 0.5131 - val_accuracy: 0.8468\n",
      "Epoch 9/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9355\n",
      "Epoch 00009: val_accuracy did not improve from 0.85835\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1923 - accuracy: 0.9355 - val_loss: 0.4935 - val_accuracy: 0.8521\n",
      "Epoch 10/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9411\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.85835\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1770 - accuracy: 0.9411 - val_loss: 0.5114 - val_accuracy: 0.8495\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9645\n",
      "Epoch 00011: val_accuracy improved from 0.85835 to 0.87256, saving model to ./storage/mnist_test_2/kfold9/epoch_011_val_0.499_acc_0.873.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.1084 - accuracy: 0.9645 - val_loss: 0.4990 - val_accuracy: 0.8726\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.9686\n",
      "Epoch 00012: val_accuracy improved from 0.87256 to 0.87567, saving model to ./storage/mnist_test_2/kfold9/epoch_012_val_0.461_acc_0.876.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0970 - accuracy: 0.9685 - val_loss: 0.4611 - val_accuracy: 0.8757\n",
      "Epoch 13/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9627\n",
      "Epoch 00013: val_accuracy did not improve from 0.87567\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.1137 - accuracy: 0.9625 - val_loss: 0.4834 - val_accuracy: 0.8708\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9701\n",
      "Epoch 00014: val_accuracy did not improve from 0.87567\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0912 - accuracy: 0.9701 - val_loss: 0.4612 - val_accuracy: 0.8752\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9698\n",
      "Epoch 00015: val_accuracy improved from 0.87567 to 0.89076, saving model to ./storage/mnist_test_2/kfold9/epoch_015_val_0.427_acc_0.891.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0935 - accuracy: 0.9698 - val_loss: 0.4267 - val_accuracy: 0.8908\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9761\n",
      "Epoch 00016: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.4441 - val_accuracy: 0.8894\n",
      "Epoch 17/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9780\n",
      "Epoch 00017: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0684 - accuracy: 0.9780 - val_loss: 0.5164 - val_accuracy: 0.8717\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0812 - accuracy: 0.9740\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0812 - accuracy: 0.9740 - val_loss: 0.4827 - val_accuracy: 0.8841\n",
      "Epoch 19/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9850\n",
      "Epoch 00019: val_accuracy did not improve from 0.89076\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0465 - accuracy: 0.9850 - val_loss: 0.4426 - val_accuracy: 0.8877\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9864\n",
      "Epoch 00020: val_accuracy improved from 0.89076 to 0.90231, saving model to ./storage/mnist_test_2/kfold9/epoch_020_val_0.413_acc_0.902.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.4132 - val_accuracy: 0.9023\n",
      "Epoch 21/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9878\n",
      "Epoch 00021: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.4834 - val_accuracy: 0.8850\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9750\n",
      "Epoch 00022: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.4852 - val_accuracy: 0.8823\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9844\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0491 - accuracy: 0.9844 - val_loss: 0.4908 - val_accuracy: 0.8943\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9919\n",
      "Epoch 00024: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.4623 - val_accuracy: 0.8925\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9930\n",
      "Epoch 00025: val_accuracy improved from 0.90231 to 0.90542, saving model to ./storage/mnist_test_2/kfold9/epoch_025_val_0.433_acc_0.905.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.4329 - val_accuracy: 0.9054\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9936\n",
      "Epoch 00026: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.4665 - val_accuracy: 0.8965\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 00027: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.4475 - val_accuracy: 0.9032\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9910\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.4328 - val_accuracy: 0.9054\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9950\n",
      "Epoch 00029: val_accuracy improved from 0.90542 to 0.90853, saving model to ./storage/mnist_test_2/kfold9/epoch_029_val_0.413_acc_0.909.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.4130 - val_accuracy: 0.9085\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9956\n",
      "Epoch 00030: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.4237 - val_accuracy: 0.9085\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9942\n",
      "Epoch 00031: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.4271 - val_accuracy: 0.9054\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9952 ETA: 0s - loss: 0.0167 - accuracy: 0.\n",
      "Epoch 00032: val_accuracy improved from 0.90853 to 0.91030, saving model to ./storage/mnist_test_2/kfold9/epoch_032_val_0.407_acc_0.910.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.4073 - val_accuracy: 0.9103\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9959\n",
      "Epoch 00033: val_accuracy improved from 0.91030 to 0.91163, saving model to ./storage/mnist_test_2/kfold9/epoch_033_val_0.462_acc_0.912.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.4619 - val_accuracy: 0.9116\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 00034: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.4287 - val_accuracy: 0.9103\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 00035: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.4700 - val_accuracy: 0.9054\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.4537 - val_accuracy: 0.9054\n",
      "Epoch 37/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9955\n",
      "Epoch 00037: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.4205 - val_accuracy: 0.9112\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 00038: val_accuracy improved from 0.91163 to 0.91607, saving model to ./storage/mnist_test_2/kfold9/epoch_038_val_0.398_acc_0.916.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.3977 - val_accuracy: 0.9161\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 00039: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.4455 - val_accuracy: 0.9147\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9976\n",
      "Epoch 00040: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4316 - val_accuracy: 0.9125\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.4568 - val_accuracy: 0.9094\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 00042: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.4527 - val_accuracy: 0.9107\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00043: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.4433 - val_accuracy: 0.9161\n",
      "Epoch 44/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9971\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.4208 - val_accuracy: 0.9152\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 00045: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.4206 - val_accuracy: 0.9143\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00046: val_accuracy did not improve from 0.91607\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.4354 - val_accuracy: 0.9161\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00047: val_accuracy improved from 0.91607 to 0.91874, saving model to ./storage/mnist_test_2/kfold9/epoch_047_val_0.423_acc_0.919.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.4233 - val_accuracy: 0.9187\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 00048: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.4308 - val_accuracy: 0.9116\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 00049: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.4450 - val_accuracy: 0.9147\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.4454 - val_accuracy: 0.9125\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00051: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4078 - val_accuracy: 0.9134\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 00052: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.4233 - val_accuracy: 0.9085\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991 ETA: 1s - loss: 0.0034 - accura - ETA: 0s - loss: 0.0\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.4381 - val_accuracy: 0.9112\n",
      "Epoch 54/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 00054: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.4162 - val_accuracy: 0.9183\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 00055: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.4183 - val_accuracy: 0.9183\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00056: val_accuracy improved from 0.91874 to 0.92140, saving model to ./storage/mnist_test_2/kfold9/epoch_056_val_0.422_acc_0.921.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.4218 - val_accuracy: 0.9214\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 00057: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.4244 - val_accuracy: 0.9210\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00058: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.4265 - val_accuracy: 0.9210\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995 ETA: 0s - loss: 0.002\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4381 - val_accuracy: 0.9187\n",
      "Epoch 60/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00060: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4314 - val_accuracy: 0.9201\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 00061: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.4327 - val_accuracy: 0.9179\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4365 - val_accuracy: 0.9165\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 00063: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.4420 - val_accuracy: 0.9187\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.6910e-04 - accuracy: 0.9999\n",
      "Epoch 00064: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.6835e-04 - accuracy: 0.9999 - val_loss: 0.4221 - val_accuracy: 0.9201\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.4309 - val_accuracy: 0.9196\n",
      "Epoch 66/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00066: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4314 - val_accuracy: 0.9187\n",
      "Epoch 67/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.0020e-04 - accuracy: 0.9998\n",
      "Epoch 00067: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.9793e-04 - accuracy: 0.9998 - val_loss: 0.4283 - val_accuracy: 0.9205\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997 ETA: 0s - loss: 0.0012 - accu\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4319 - val_accuracy: 0.9210\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00069: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4225 - val_accuracy: 0.9201\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00070: val_accuracy did not improve from 0.92140\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4142 - val_accuracy: 0.9214\n",
      "Epoch 71/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.9573e-04 - accuracy: 0.9997\n",
      "Epoch 00071: val_accuracy improved from 0.92140 to 0.92496, saving model to ./storage/mnist_test_2/kfold9/epoch_071_val_0.417_acc_0.925.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 9.0083e-04 - accuracy: 0.9997 - val_loss: 0.4174 - val_accuracy: 0.9250\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00072: val_accuracy did not improve from 0.92496\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4239 - val_accuracy: 0.9245\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3901e-04 - accuracy: 0.9999\n",
      "Epoch 00073: val_accuracy did not improve from 0.92496\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.3839e-04 - accuracy: 0.9999 - val_loss: 0.4250 - val_accuracy: 0.9245\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.4935e-04 - accuracy: 0.9998\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.92496\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.4867e-04 - accuracy: 0.9998 - val_loss: 0.4191 - val_accuracy: 0.9241\n",
      "Epoch 75/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998     ETA: \n",
      "Epoch 00075: val_accuracy improved from 0.92496 to 0.92629, saving model to ./storage/mnist_test_2/kfold9/epoch_075_val_0.424_acc_0.926.h5\n",
      "20276/20276 [==============================] - 22s 1ms/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4242 - val_accuracy: 0.9263\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.2927e-04 - accuracy: 0.9998\n",
      "Epoch 00076: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.2842e-04 - accuracy: 0.9998 - val_loss: 0.4270 - val_accuracy: 0.9236\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9021e-04 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 3.9019e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9227\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.4709e-04 - accuracy: 0.9998 ETA: 0s - loss: 7.4565e-04 - accura\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.4681e-04 - accuracy: 0.9998 - val_loss: 0.4255 - val_accuracy: 0.9232\n",
      "Epoch 79/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.6445e-04 - accuracy: 0.9999\n",
      "Epoch 00079: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.6691e-04 - accuracy: 0.9999 - val_loss: 0.4241 - val_accuracy: 0.9232\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.8137e-04 - accuracy: 0.9998\n",
      "Epoch 00080: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.7891e-04 - accuracy: 0.9998 - val_loss: 0.4236 - val_accuracy: 0.9218\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.5325e-04 - accuracy: 0.9998\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.5304e-04 - accuracy: 0.9998 - val_loss: 0.4208 - val_accuracy: 0.9245\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7135e-04 - accuracy: 0.9998\n",
      "Epoch 00082: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.7069e-04 - accuracy: 0.9998 - val_loss: 0.4244 - val_accuracy: 0.9223\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7014e-04 - accuracy: 0.9998\n",
      "Epoch 00083: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.7588e-04 - accuracy: 0.9998 - val_loss: 0.4260 - val_accuracy: 0.9223\n",
      "Epoch 84/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.3004e-04 - accuracy: 0.9997\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 8.2806e-04 - accuracy: 0.9997 - val_loss: 0.4234 - val_accuracy: 0.9218\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7561e-04 - accuracy: 0.9998\n",
      "Epoch 00085: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.7505e-04 - accuracy: 0.9998 - val_loss: 0.4172 - val_accuracy: 0.9241\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.0968e-04 - accuracy: 0.9997\n",
      "Epoch 00086: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.2228e-04 - accuracy: 0.9997 - val_loss: 0.4125 - val_accuracy: 0.9254\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5569e-04 - accuracy: 1.0000\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5530e-04 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9236\n",
      "Epoch 88/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.5929e-04 - accuracy: 0.9999\n",
      "Epoch 00088: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.5838e-04 - accuracy: 0.9999 - val_loss: 0.4150 - val_accuracy: 0.9236\n",
      "Epoch 89/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.5288e-04 - accuracy: 0.9998\n",
      "Epoch 00089: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.5173e-04 - accuracy: 0.9998 - val_loss: 0.4157 - val_accuracy: 0.9250\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.4825e-04 - accuracy: 1.0000\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.4821e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9245\n",
      "Epoch 91/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.5615e-04 - accuracy: 0.9999 ETA: 0s - loss: 4.5352e-04 - accuracy\n",
      "Epoch 00091: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.5510e-04 - accuracy: 0.9999 - val_loss: 0.4156 - val_accuracy: 0.9245\n",
      "Epoch 92/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.0489e-04 - accuracy: 0.9998\n",
      "Epoch 00092: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 7.0309e-04 - accuracy: 0.9998 - val_loss: 0.4161 - val_accuracy: 0.9245\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7472e-04 - accuracy: 0.9999\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 6.7442e-04 - accuracy: 0.9999 - val_loss: 0.4200 - val_accuracy: 0.9245\n",
      "Epoch 94/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.6169e-04 - accuracy: 1.0000\n",
      "Epoch 00094: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 2.6142e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9250\n",
      "Epoch 95/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.6497e-04 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.6380e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9263\n",
      "Epoch 96/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.5568e-04 - accuracy: 0.9999\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 5.5444e-04 - accuracy: 0.9999 - val_loss: 0.4214 - val_accuracy: 0.9245\n",
      "Epoch 97/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.6797e-04 - accuracy: 0.9997\n",
      "Epoch 00097: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 9.6551e-04 - accuracy: 0.9997 - val_loss: 0.4183 - val_accuracy: 0.9241\n",
      "Epoch 98/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6145e-04 - accuracy: 1.0000\n",
      "Epoch 00098: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.3444e-04 - accuracy: 0.9999 - val_loss: 0.4209 - val_accuracy: 0.9232\n",
      "Epoch 99/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2125e-04 - accuracy: 0.9999\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.2088e-04 - accuracy: 0.9999 - val_loss: 0.4207 - val_accuracy: 0.9250\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1877e-04 - accuracy: 0.9999 ETA: 0s - loss: 4.2330e-04 - accuracy\n",
      "Epoch 00100: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 21s 1ms/sample - loss: 4.1843e-04 - accuracy: 0.9999 - val_loss: 0.4211 - val_accuracy: 0.9245\n",
      "************ Fold 10 training ************\n",
      "Train on 20268 samples, validate on 2260 samples\n",
      "Epoch 1/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 1.8000 - accuracy: 0.4211\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60133, saving model to ./storage/mnist_test_2/kfold10/epoch_001_val_1.184_acc_0.601.h5\n",
      "20268/20268 [==============================] - 28s 1ms/sample - loss: 1.7999 - accuracy: 0.4210 - val_loss: 1.1844 - val_accuracy: 0.6013\n",
      "Epoch 2/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 1.0420 - accuracy: 0.6533\n",
      "Epoch 00002: val_accuracy improved from 0.60133 to 0.70575, saving model to ./storage/mnist_test_2/kfold10/epoch_002_val_0.886_acc_0.706.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 1.0420 - accuracy: 0.6532 - val_loss: 0.8862 - val_accuracy: 0.7058\n",
      "Epoch 3/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.7299 - accuracy: 0.7615\n",
      "Epoch 00003: val_accuracy improved from 0.70575 to 0.78717, saving model to ./storage/mnist_test_2/kfold10/epoch_003_val_0.634_acc_0.787.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.7305 - accuracy: 0.7613 - val_loss: 0.6343 - val_accuracy: 0.7872\n",
      "Epoch 4/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.8216\n",
      "Epoch 00004: val_accuracy improved from 0.78717 to 0.80310, saving model to ./storage/mnist_test_2/kfold10/epoch_004_val_0.630_acc_0.803.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.5495 - accuracy: 0.8219 - val_loss: 0.6297 - val_accuracy: 0.8031\n",
      "Epoch 5/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.4332 - accuracy: 0.8604\n",
      "Epoch 00005: val_accuracy improved from 0.80310 to 0.82434, saving model to ./storage/mnist_test_2/kfold10/epoch_005_val_0.564_acc_0.824.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.4330 - accuracy: 0.8605 - val_loss: 0.5636 - val_accuracy: 0.8243\n",
      "Epoch 6/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.8895\n",
      "Epoch 00006: val_accuracy improved from 0.82434 to 0.82655, saving model to ./storage/mnist_test_2/kfold10/epoch_006_val_0.554_acc_0.827.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.3442 - accuracy: 0.8895 - val_loss: 0.5545 - val_accuracy: 0.8265\n",
      "Epoch 7/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.2850 - accuracy: 0.9066\n",
      "Epoch 00007: val_accuracy improved from 0.82655 to 0.84381, saving model to ./storage/mnist_test_2/kfold10/epoch_007_val_0.508_acc_0.844.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.2851 - accuracy: 0.9066 - val_loss: 0.5079 - val_accuracy: 0.8438\n",
      "Epoch 8/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9236\n",
      "Epoch 00008: val_accuracy did not improve from 0.84381\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.2385 - accuracy: 0.9236 - val_loss: 0.5472 - val_accuracy: 0.8434\n",
      "Epoch 9/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9256\n",
      "Epoch 00009: val_accuracy did not improve from 0.84381\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.2308 - accuracy: 0.9256 - val_loss: 0.5237 - val_accuracy: 0.8429\n",
      "Epoch 10/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9369\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.84381\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.1897 - accuracy: 0.9369 - val_loss: 0.5565 - val_accuracy: 0.8376\n",
      "Epoch 11/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1395 - accuracy: 0.9538\n",
      "Epoch 00011: val_accuracy improved from 0.84381 to 0.86327, saving model to ./storage/mnist_test_2/kfold10/epoch_011_val_0.505_acc_0.863.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.1394 - accuracy: 0.9539 - val_loss: 0.5047 - val_accuracy: 0.8633\n",
      "Epoch 12/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9667\n",
      "Epoch 00012: val_accuracy did not improve from 0.86327\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.1083 - accuracy: 0.9667 - val_loss: 0.5058 - val_accuracy: 0.8558\n",
      "Epoch 13/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9662\n",
      "Epoch 00013: val_accuracy improved from 0.86327 to 0.86416, saving model to ./storage/mnist_test_2/kfold10/epoch_013_val_0.543_acc_0.864.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.1018 - accuracy: 0.9661 - val_loss: 0.5426 - val_accuracy: 0.8642\n",
      "Epoch 14/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9642\n",
      "Epoch 00014: val_accuracy did not improve from 0.86416\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.1089 - accuracy: 0.9642 - val_loss: 0.5678 - val_accuracy: 0.8575\n",
      "Epoch 15/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9692\n",
      "Epoch 00015: val_accuracy improved from 0.86416 to 0.86549, saving model to ./storage/mnist_test_2/kfold10/epoch_015_val_0.531_acc_0.865.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0934 - accuracy: 0.9692 - val_loss: 0.5308 - val_accuracy: 0.8655\n",
      "Epoch 16/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9780\n",
      "Epoch 00016: val_accuracy improved from 0.86549 to 0.87301, saving model to ./storage/mnist_test_2/kfold10/epoch_016_val_0.525_acc_0.873.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0699 - accuracy: 0.9780 - val_loss: 0.5245 - val_accuracy: 0.8730\n",
      "Epoch 17/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9759\n",
      "Epoch 00017: val_accuracy did not improve from 0.87301\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0773 - accuracy: 0.9758 - val_loss: 0.6013 - val_accuracy: 0.8531\n",
      "Epoch 18/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9734\n",
      "Epoch 00018: val_accuracy improved from 0.87301 to 0.88673, saving model to ./storage/mnist_test_2/kfold10/epoch_018_val_0.463_acc_0.887.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0842 - accuracy: 0.9734 - val_loss: 0.4627 - val_accuracy: 0.8867\n",
      "Epoch 19/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9780\n",
      "Epoch 00019: val_accuracy did not improve from 0.88673\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0670 - accuracy: 0.9780 - val_loss: 0.5329 - val_accuracy: 0.8717\n",
      "Epoch 20/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9799\n",
      "Epoch 00020: val_accuracy did not improve from 0.88673\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0625 - accuracy: 0.9798 - val_loss: 0.5146 - val_accuracy: 0.8717\n",
      "Epoch 21/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9799\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.88673\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0637 - accuracy: 0.9798 - val_loss: 0.6252 - val_accuracy: 0.8597\n",
      "Epoch 22/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9865\n",
      "Epoch 00022: val_accuracy improved from 0.88673 to 0.89292, saving model to ./storage/mnist_test_2/kfold10/epoch_022_val_0.468_acc_0.893.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0429 - accuracy: 0.9864 - val_loss: 0.4675 - val_accuracy: 0.8929\n",
      "Epoch 23/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9874\n",
      "Epoch 00023: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.4810 - val_accuracy: 0.8916\n",
      "Epoch 24/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9890\n",
      "Epoch 00024: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0312 - accuracy: 0.9889 - val_loss: 0.5463 - val_accuracy: 0.8774\n",
      "Epoch 25/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9831\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0508 - accuracy: 0.9831 - val_loss: 0.5265 - val_accuracy: 0.8792\n",
      "Epoch 26/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9911\n",
      "Epoch 00026: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.5095 - val_accuracy: 0.8832\n",
      "Epoch 27/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9920\n",
      "Epoch 00027: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.5185 - val_accuracy: 0.8925\n",
      "Epoch 28/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9946\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.5275 - val_accuracy: 0.8889\n",
      "Epoch 29/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 00029: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.5073 - val_accuracy: 0.8925\n",
      "Epoch 30/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 00030: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.5721 - val_accuracy: 0.8836\n",
      "Epoch 31/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9954\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.5070 - val_accuracy: 0.8916\n",
      "Epoch 32/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 00032: val_accuracy improved from 0.89292 to 0.89425, saving model to ./storage/mnist_test_2/kfold10/epoch_032_val_0.519_acc_0.894.h5\n",
      "20268/20268 [==============================] - 23s 1ms/sample - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.5191 - val_accuracy: 0.8942\n",
      "Epoch 33/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 00033: val_accuracy did not improve from 0.89425\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.5379 - val_accuracy: 0.8934\n",
      "Epoch 34/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 00034: val_accuracy improved from 0.89425 to 0.90088, saving model to ./storage/mnist_test_2/kfold10/epoch_034_val_0.500_acc_0.901.h5\n",
      "20268/20268 [==============================] - 23s 1ms/sample - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.5004 - val_accuracy: 0.9009\n",
      "Epoch 35/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9967 ETA: 2s - loss:\n",
      "Epoch 00035: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.5409 - val_accuracy: 0.8934\n",
      "Epoch 36/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 00036: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.5222 - val_accuracy: 0.8987\n",
      "Epoch 37/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9969\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.5446 - val_accuracy: 0.8929\n",
      "Epoch 38/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 00038: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.5327 - val_accuracy: 0.8965\n",
      "Epoch 39/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00039: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.5295 - val_accuracy: 0.8996\n",
      "Epoch 40/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9971\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.5198 - val_accuracy: 0.8934\n",
      "Epoch 41/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 00041: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.5300 - val_accuracy: 0.8960\n",
      "Epoch 42/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 00042: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.5317 - val_accuracy: 0.8982\n",
      "Epoch 43/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5330 - val_accuracy: 0.8987\n",
      "Epoch 44/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00044: val_accuracy did not improve from 0.90088\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.5530 - val_accuracy: 0.8951\n",
      "Epoch 45/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 00045: val_accuracy improved from 0.90088 to 0.90354, saving model to ./storage/mnist_test_2/kfold10/epoch_045_val_0.548_acc_0.904.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.5478 - val_accuracy: 0.9035\n",
      "Epoch 46/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 00046: val_accuracy did not improve from 0.90354\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.5185 - val_accuracy: 0.9022\n",
      "Epoch 47/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 00047: val_accuracy did not improve from 0.90354\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5316 - val_accuracy: 0.9000\n",
      "Epoch 48/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 00048: val_accuracy improved from 0.90354 to 0.90575, saving model to ./storage/mnist_test_2/kfold10/epoch_048_val_0.518_acc_0.906.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.5175 - val_accuracy: 0.9058\n",
      "Epoch 49/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00049: val_accuracy did not improve from 0.90575\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5150 - val_accuracy: 0.8996\n",
      "Epoch 50/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00050: val_accuracy did not improve from 0.90575\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.5199 - val_accuracy: 0.9053\n",
      "Epoch 51/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90575\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4979 - val_accuracy: 0.9031\n",
      "Epoch 52/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00052: val_accuracy improved from 0.90575 to 0.90929, saving model to ./storage/mnist_test_2/kfold10/epoch_052_val_0.496_acc_0.909.h5\n",
      "20268/20268 [==============================] - 22s 1ms/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.4960 - val_accuracy: 0.9093\n",
      "Epoch 53/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 00053: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5309 - val_accuracy: 0.9004\n",
      "Epoch 54/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 00054: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.5182 - val_accuracy: 0.9004\n",
      "Epoch 55/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.5143 - val_accuracy: 0.9013\n",
      "Epoch 56/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00056: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.5263 - val_accuracy: 0.9049\n",
      "Epoch 57/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 00057: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.5326 - val_accuracy: 0.9058\n",
      "Epoch 58/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.5198 - val_accuracy: 0.9066\n",
      "Epoch 59/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 00059: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.5088 - val_accuracy: 0.9049\n",
      "Epoch 60/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00060: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.5211 - val_accuracy: 0.9049\n",
      "Epoch 61/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.5309 - val_accuracy: 0.9040\n",
      "Epoch 62/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00062: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5280 - val_accuracy: 0.9049\n",
      "Epoch 63/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 00063: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.5199 - val_accuracy: 0.9035\n",
      "Epoch 64/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.5326 - val_accuracy: 0.9040\n",
      "Epoch 65/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 9.0469e-04 - accuracy: 0.9997\n",
      "Epoch 00065: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 9.0416e-04 - accuracy: 0.9997 - val_loss: 0.5403 - val_accuracy: 0.9040\n",
      "Epoch 66/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 9.3703e-04 - accuracy: 0.9998\n",
      "Epoch 00066: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 9.3529e-04 - accuracy: 0.9998 - val_loss: 0.5358 - val_accuracy: 0.9049\n",
      "Epoch 67/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 8.7561e-04 - accuracy: 0.9998\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 8.7629e-04 - accuracy: 0.9998 - val_loss: 0.5389 - val_accuracy: 0.9035\n",
      "Epoch 68/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 8.0397e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 8.0416e-04 - accuracy: 0.9998 - val_loss: 0.5337 - val_accuracy: 0.9044\n",
      "Epoch 69/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 9.5526e-04 - accuracy: 0.9999\n",
      "Epoch 00069: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 9.5475e-04 - accuracy: 0.9999 - val_loss: 0.5296 - val_accuracy: 0.9066\n",
      "Epoch 70/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9995\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.5247 - val_accuracy: 0.9049\n",
      "Epoch 71/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 8.5431e-04 - accuracy: 0.9998\n",
      "Epoch 00071: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 8.5678e-04 - accuracy: 0.9998 - val_loss: 0.5313 - val_accuracy: 0.9044\n",
      "Epoch 72/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 6.7929e-04 - accuracy: 0.9998\n",
      "Epoch 00072: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 8.3420e-04 - accuracy: 0.9998 - val_loss: 0.5319 - val_accuracy: 0.9027\n",
      "Epoch 73/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 5.8536e-04 - accuracy: 1.0000\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 5.8548e-04 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.9049\n",
      "Epoch 74/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00074: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.5352 - val_accuracy: 0.9018\n",
      "Epoch 75/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 7.0611e-04 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 7.0577e-04 - accuracy: 0.9997 - val_loss: 0.5353 - val_accuracy: 0.9035\n",
      "Epoch 76/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.5251 - val_accuracy: 0.9035\n",
      "Epoch 77/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 3.9412e-04 - accuracy: 0.9999\n",
      "Epoch 00077: val_accuracy did not improve from 0.90929\n",
      "20268/20268 [==============================] - 21s 1ms/sample - loss: 3.9596e-04 - accuracy: 0.9999 - val_loss: 0.5210 - val_accuracy: 0.9049\n"
     ]
    }
   ],
   "source": [
    "# implement k-fold cv \n",
    "def k_fold(k,files):  \n",
    "    folds = [] \n",
    "    fold_size = len(files) // k \n",
    "    for i in range(k): \n",
    "        if i == k-1:  \n",
    "            l = files[i*fold_size:] \n",
    "        else: \n",
    "            l = files[i*fold_size:(i+1)*fold_size]  \n",
    "        folds.append(l)   \n",
    "    return folds  \n",
    "\n",
    "# uncomment below to shuffle before splitting data into folds \n",
    "x_train, y_train, train_letters_numeric = shuffle(x_train, y_train, train_letters_numeric)\n",
    "# split data into 10 folds \n",
    "k = 10\n",
    "x_train_folds = k_fold(k, x_train)\n",
    "y_train_folds = k_fold(k, y_train) \n",
    "letter_train_folds = k_fold(k,train_letters_numeric)\n",
    "\n",
    "for t in range(k):  \n",
    "    print(\"************ Fold {} training ************\".format(t+1)) \n",
    "    cur_val_x = x_train_folds[t] \n",
    "    cur_val_y = y_train_folds[t] \n",
    "    cur_val_letter = letter_train_folds[t]\n",
    "    train_folds_x = x_train_folds[0:t] + x_train_folds[t+1:] \n",
    "    train_folds_y = y_train_folds[0:t] + y_train_folds[t+1:]\n",
    "    train_fold_letter = letter_train_folds[0:t] + letter_train_folds[t+1:]\n",
    "    cur_train_x = [] \n",
    "    cur_train_y = [] \n",
    "    cur_letter = [] \n",
    "    for j in train_folds_x:  \n",
    "        for q in j:  \n",
    "            cur_train_x.append(q) \n",
    "    for j in train_folds_y:  \n",
    "        for q in j:  \n",
    "            cur_train_y.append(q)  \n",
    "    for j in train_fold_letter: \n",
    "        for q in j: \n",
    "            cur_letter.append(q) \n",
    "    cur_train_x = np.asarray(cur_train_x)\n",
    "    cur_train_y = np.asarray(cur_train_y)\n",
    "    cur_letter = np.asarray(cur_letter) \n",
    "    model_path = './storage/mnist_test_2/' + 'kfold' + str(t+1) + '/epoch_{epoch:03d}_val_{val_loss:.3f}_acc_{val_accuracy:.3f}.h5' \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.8)\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_accuracy',verbose=1,save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',patience=25)\n",
    "    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) # possible alternative to ReduceLROnPlateau\n",
    "    model = base_cnn_grade_6() \n",
    "    \n",
    "    history = model.fit([cur_train_x,cur_letter],\n",
    "                        cur_train_y,\n",
    "                       batch_size = 32,\n",
    "                       shuffle = True, \n",
    "                       validation_data = ([cur_val_x,cur_val_letter],cur_val_y),\n",
    "                       verbose = 1, \n",
    "                       epochs = 300,\n",
    "                       callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
