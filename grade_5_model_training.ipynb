{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment: Paperspace Quadro P6000 GPU  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras # run pip install keras==2.3 beforehand for compatability \n",
    "from tensorflow.keras import Input, Model \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import random \n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import shuffle # shuffle dataset before splitting into folds \n",
    "from scipy.ndimage.filters import gaussian_filter # for elastic distortion \n",
    "from scipy.ndimage.interpolation import map_coordinates # for elastic distortion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './storage/modified_mnist_dataset/train.csv'  \n",
    "test_path = './storage/modified_mnist_dataset/test.csv' \n",
    "submission_path = './storage/modified_mnist_dataset/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path) \n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types of digit and letter columns to categorical \n",
    "train.iloc[:,1] = pd.Categorical(train.iloc[:,1])\n",
    "train.iloc[:,2] = pd.Categorical(train.iloc[:,2]) \n",
    "test.iloc[:,1] = pd.Categorical(test.iloc[:,1])\n",
    "\n",
    "# define and re-format train and test data \n",
    "x_train = train.iloc[:,3:].values.reshape(-1,28,28,1).astype(np.float32) \n",
    "y_train = train.iloc[:,1].values\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "train_letters = train.iloc[:,2].values\n",
    "\n",
    "x_test = test.iloc[:,2:].values.reshape(-1,28,28,1).astype(np.float32)  \n",
    "test_letters = test.iloc[:,1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 28, 28, 1), (2048, 10), (20480, 28, 28, 1), (2048, 26), (20480, 26))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letters_numeric = [] \n",
    "test_letters_numeric = [] \n",
    "for letter in train_letters: \n",
    "    train_letters_numeric.append(ord(letter) - ord(\"A\"))\n",
    "for letter in test_letters: \n",
    "    test_letters_numeric.append(ord(letter) - ord(\"A\")) \n",
    "    \n",
    "train_letters_numeric = np.asarray(train_letters_numeric) \n",
    "test_letters_numeric = np.asarray(test_letters_numeric) \n",
    "\n",
    "train_letters_numeric = to_categorical(train_letters_numeric, num_classes = 26) \n",
    "test_letters_numeric = to_categorical(test_letters_numeric, num_classes = 26)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, train_letters_numeric.shape, test_letters_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max scaling \n",
    "x_train /= 255.0 \n",
    "x_test /= 255.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data\n",
    "\n",
    "For now, we will try augmenting the data using the following methods \n",
    "- rotation \n",
    "- adding noise  \n",
    "- adding gaussian blur \n",
    "- shifting image \n",
    "\n",
    "Please refer to [this notebook](https://github.com/iljimae0418/overlapping-digit-and-letter-mnist/blob/master/Examples%20of%20data%20augmentations.ipynb) for examples.  \n",
    "\n",
    "Some more augmentations were decided to be added. They are \n",
    "- modifying brightness \n",
    "- ZCA Whitening \n",
    "- random crops\n",
    "- elastic distortions\n",
    "\n",
    "some more augmentations that are being planned are \n",
    "- Autoencoder generated images \n",
    "- GAN generated images\n",
    "\n",
    "Please refer to [this notebook](https://github.com/iljimae0418/overlapping-digit-and-letter-mnist/blob/master/Examples%20of%20augmentation%202%20(further%20augmentation).ipynb) for examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rotations \n",
    "x_train_rotated = [] \n",
    "for x_data in x_train:\n",
    "    rotated_img = rotate(x_data, angle = random.randint(10,40))\n",
    "    x_train_rotated.append(rotated_img) \n",
    "x_train_rotated = np.asarray(x_train_rotated) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply clockwise rotations \n",
    "x_train_rotated_2 = [] \n",
    "for x_data in x_train: \n",
    "    rotated_img = rotate(x_data, angle = -random.randint(10,40)) \n",
    "    x_train_rotated_2.append(rotated_img)\n",
    "x_train_rotated_2 = np.asarray(x_train_rotated_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise \n",
    "x_noised = [] \n",
    "for x_data in x_train: \n",
    "    noised_img = random_noise(x_data) \n",
    "    x_noised.append(noised_img)\n",
    "x_noised = np.asarray(x_noised) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gaussian blur \n",
    "x_blurred = [] \n",
    "for x_data in x_train:\n",
    "    kernel_size = random.choice([3,5,9]) \n",
    "    blurred = cv2.GaussianBlur(x_data, (kernel_size, kernel_size), 0) \n",
    "    x_blurred.append(blurred)\n",
    "x_blurred = np.asarray(x_blurred)\n",
    "x_blurred = x_blurred.reshape(-1,28,28,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift image \n",
    "x_shifted = [] \n",
    "for x_data in x_train: \n",
    "    dx = random.choice([-2,-1,1,2])\n",
    "    dy = random.choice([-2,-1,1,2])\n",
    "    transform = AffineTransform(translation = (dx,dy))\n",
    "    warp_img = warp(x_data, transform, mode = \"wrap\")\n",
    "    x_shifted.append(warp_img) \n",
    "x_shifted = np.asarray(x_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply brightness modifications \n",
    "x_brightness = [] \n",
    "for x_data in x_train: \n",
    "    brightness = 0.5\n",
    "    alpha = 1.0 + random.uniform(-brightness, brightness) \n",
    "    brightness_modified = x_data * alpha \n",
    "    x_brightness.append(brightness_modified) \n",
    "\n",
    "x_brightness = np.asarray(x_brightness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply zca whitening \n",
    "def zca_whitening(sample): \n",
    "    sample = sample - sample.mean(axis=0)\n",
    "    cov = np.cov(sample, rowvar = False)\n",
    "    U,S,V = np.linalg.svd(cov) \n",
    "    epsilon = 0.1\n",
    "    X_ZCA = U.dot(np.diag(1.0/np.sqrt(S + epsilon))).dot(U.T).dot(sample.T).T\n",
    "    X_ZCA_rescaled = (X_ZCA - X_ZCA.min()) / (X_ZCA.max() - X_ZCA.min())\n",
    "    X_ZCA_rescaled = X_ZCA_rescaled.reshape((28,28,1)) \n",
    "    return X_ZCA_rescaled \n",
    "\n",
    "x_zca_whitened = [] \n",
    "for x_data in x_train: \n",
    "    zca_whitened = zca_whitening(x_data.reshape((28,28))) \n",
    "    x_zca_whitened.append(zca_whitened) \n",
    "    \n",
    "x_zca_whitened = np.asarray(x_zca_whitened) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random cropping (zooming effect)\n",
    "def random_crop(img): \n",
    "    img = img.copy() \n",
    "    size = random.randint(22,24) # this seems to be a good balance, since our image size is 28 by 28\n",
    "    crop_size = (size,size)\n",
    "    w,h = img.shape[:2]\n",
    "    x,y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
    "    img = img[y:y+crop_size[0], x:x+crop_size[1]] \n",
    "    return img \n",
    "\n",
    "x_random_crop = []\n",
    "for x_data in x_train: \n",
    "    cropped = random_crop(x_data) \n",
    "    cropped = resize(cropped, (28,28,1))\n",
    "    x_random_crop.append(cropped)\n",
    "\n",
    "x_random_crop = np.asarray(x_random_crop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elastic distortions \n",
    "# from https://www.kaggle.com/babbler/mnist-data-augmentation-with-elastic-distortion\n",
    "def elastic_transform(image, alpha_range, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "       \n",
    "   # Arguments\n",
    "       image: Numpy array with shape (height, width, channels). \n",
    "       alpha_range: Float for fixed value or [lower, upper] for random value from uniform distribution.\n",
    "           Controls intensity of deformation.\n",
    "       sigma: Float, sigma of gaussian filter that smooths the displacement fields.\n",
    "       random_state: `numpy.random.RandomState` object for generating displacement fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "        \n",
    "    if np.isscalar(alpha_range):\n",
    "        alpha = alpha_range\n",
    "    else:\n",
    "        alpha = np.random.uniform(low=alpha_range[0], high=alpha_range[1])\n",
    "    \n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "    indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
    "\n",
    "x_elastic_distort = [] \n",
    "for x_data in x_train: \n",
    "    distorted = elastic_transform(x_data, [8,10], 3) \n",
    "    x_elastic_distort.append(distorted) \n",
    "    \n",
    "x_elastic_distort = np.asarray(x_elastic_distort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ae = np.load('./storage/ae_gen_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22528, 28, 28, 1), (22528, 10), (22528, 26))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating augmented data to the original \n",
    "x_train = np.concatenate((x_train, x_train_rotated, x_train_rotated_2, x_noised, x_blurred, x_shifted, x_brightness, x_zca_whitened, x_random_crop, x_elastic_distort, x_ae), axis = 0) \n",
    "y_train = np.concatenate((y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train), axis = 0) \n",
    "train_letters_numeric = np.concatenate((train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric), axis = 0)\n",
    "\n",
    "x_train.shape, y_train.shape, train_letters_numeric.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses skip connections and also adds information from both MaxPooling2D and AveragePooling2D \n",
    "def conv2d_block(input_layer, n_filters, kernel):\n",
    "    conv1 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = Add()([conv1, conv2])   \n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    maxpool = MaxPooling2D((2,2))(conv1) \n",
    "    avgpool = AveragePooling2D((2,2))(conv1)\n",
    "    ret = Add()([maxpool,avgpool])\n",
    "    return ret \n",
    "\n",
    "# obtains around 82% validation accuracy on a 9:1 train/validation split\n",
    "# the most promising model so far, until we come up with a potentially more powerful grade 5 model \n",
    "# obtains 90.6% on the public leaderboard \n",
    "def base_cnn_grade_4(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))    \n",
    "    conv1 = conv2d_block(inputs, 64, 7) \n",
    "    conv2 = conv2d_block(inputs, 64, 5) \n",
    "    conv3 = conv2d_block(inputs, 64, 3) \n",
    "    conv = Concatenate()([conv1,conv2,conv3])   \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv = Concatenate()([conv1,conv2,conv3]) \n",
    "    outputs = Flatten()(conv) \n",
    "    outputs = Concatenate()([outputs,letter_input])\n",
    "    for unit in [512, 256, 128]: \n",
    "        outputs = Dense(unit, activation = 'relu')(outputs)  \n",
    "        outputs = BatchNormalization()(outputs) \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "# obtains 91.2% accuracy on public leaderboard. \n",
    "# increased to three convolutional blocks \n",
    "# batchnorm input layer to normalize the input layer  \n",
    "def base_cnn_grade_5(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))  \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv1 = conv2d_block(bn, 64, 7) \n",
    "    conv2 = conv2d_block(bn, 64, 5) \n",
    "    conv3 = conv2d_block(bn, 64, 3) \n",
    "    conv4 = conv2d_block(bn, 64, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv4 = conv2d_block(conv, 32, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    conv1 = conv2d_block(conv, 16, 7)\n",
    "    conv2 = conv2d_block(conv, 16, 5)\n",
    "    conv3 = conv2d_block(conv, 16, 3)   \n",
    "    conv4 = conv2d_block(conv, 16, 1)       \n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4]) \n",
    "    conv = BatchNormalization()(conv) \n",
    "    outputs = Flatten()(conv) \n",
    "    outputs = Concatenate()([outputs, letter_input]) \n",
    "    for units in [512, 256, 128]: \n",
    "        outputs = Dense(units, activation = 'relu', kernel_initializer = 'he_normal')(outputs) \n",
    "        outputs = BatchNormalization()(outputs)  \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "\n",
    "# reduced to two convolutional blocks \n",
    "# more dense layers at the end \n",
    "# batchnorm input layer to normalize the input layer \n",
    "def base_cnn_grade_6(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))  \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv1 = conv2d_block(bn, 64, 7) \n",
    "    conv2 = conv2d_block(bn, 64, 5) \n",
    "    conv3 = conv2d_block(bn, 64, 4)\n",
    "    conv4 = conv2d_block(bn, 64, 3) \n",
    "    conv5 = conv2d_block(bn, 64, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4,conv5])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 4) \n",
    "    conv4 = conv2d_block(conv, 32, 3) \n",
    "    conv5 = conv2d_block(conv, 32, 1)\n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4,conv5])   \n",
    "    conv = BatchNormalization()(conv) \n",
    "    outputs = Flatten()(conv)  \n",
    "    outputs = Concatenate()([outputs, letter_input])\n",
    "    for units in [1024, 512, 256, 128]: \n",
    "        outputs = Dense(units, activation = 'relu', kernel_initializer = 'he_normal')(outputs) \n",
    "        outputs = BatchNormalization()(outputs)  \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Fold 1 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.8649 - accuracy: 0.3891\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57726, saving model to ./storage/mnist_test/kfold1/epoch_001_val_1.217_acc_0.577.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8649 - accuracy: 0.3893 - val_loss: 1.2172 - val_accuracy: 0.5773\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0849 - accuracy: 0.6351\n",
      "Epoch 00002: val_accuracy improved from 0.57726 to 0.67673, saving model to ./storage/mnist_test/kfold1/epoch_002_val_0.934_acc_0.677.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 1.0847 - accuracy: 0.6351 - val_loss: 0.9341 - val_accuracy: 0.6767\n",
      "Epoch 3/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.7716 - accuracy: 0.7395\n",
      "Epoch 00003: val_accuracy improved from 0.67673 to 0.76288, saving model to ./storage/mnist_test/kfold1/epoch_003_val_0.684_acc_0.763.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.7715 - accuracy: 0.7395 - val_loss: 0.6844 - val_accuracy: 0.7629\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5769 - accuracy: 0.8094\n",
      "Epoch 00004: val_accuracy improved from 0.76288 to 0.80195, saving model to ./storage/mnist_test/kfold1/epoch_004_val_0.568_acc_0.802.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.5772 - accuracy: 0.8093 - val_loss: 0.5683 - val_accuracy: 0.8020\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.8455\n",
      "Epoch 00005: val_accuracy improved from 0.80195 to 0.83881, saving model to ./storage/mnist_test/kfold1/epoch_005_val_0.510_acc_0.839.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.4730 - accuracy: 0.8455 - val_loss: 0.5103 - val_accuracy: 0.8388\n",
      "Epoch 6/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8738\n",
      "Epoch 00006: val_accuracy improved from 0.83881 to 0.83925, saving model to ./storage/mnist_test/kfold1/epoch_006_val_0.513_acc_0.839.h5\n",
      "20276/20276 [==============================] - 18s 899us/sample - loss: 0.3806 - accuracy: 0.8737 - val_loss: 0.5131 - val_accuracy: 0.8393\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.9001\n",
      "Epoch 00007: val_accuracy improved from 0.83925 to 0.86279, saving model to ./storage/mnist_test/kfold1/epoch_007_val_0.448_acc_0.863.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.3054 - accuracy: 0.9002 - val_loss: 0.4482 - val_accuracy: 0.8628\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9155\n",
      "Epoch 00008: val_accuracy improved from 0.86279 to 0.87389, saving model to ./storage/mnist_test/kfold1/epoch_008_val_0.419_acc_0.874.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.2579 - accuracy: 0.9155 - val_loss: 0.4194 - val_accuracy: 0.8739\n",
      "Epoch 9/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9283\n",
      "Epoch 00009: val_accuracy did not improve from 0.87389\n",
      "20276/20276 [==============================] - 18s 872us/sample - loss: 0.2208 - accuracy: 0.9281 - val_loss: 0.4656 - val_accuracy: 0.8641\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1941 - accuracy: 0.9368\n",
      "Epoch 00010: val_accuracy did not improve from 0.87389\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.1940 - accuracy: 0.9368 - val_loss: 0.4282 - val_accuracy: 0.8699\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9461\n",
      "Epoch 00011: val_accuracy improved from 0.87389 to 0.87522, saving model to ./storage/mnist_test/kfold1/epoch_011_val_0.445_acc_0.875.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.1636 - accuracy: 0.9461 - val_loss: 0.4455 - val_accuracy: 0.8752\n",
      "Epoch 12/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9494\n",
      "Epoch 00012: val_accuracy did not improve from 0.87522\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.1516 - accuracy: 0.9493 - val_loss: 0.4977 - val_accuracy: 0.8601\n",
      "Epoch 13/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9578\n",
      "Epoch 00013: val_accuracy improved from 0.87522 to 0.88055, saving model to ./storage/mnist_test/kfold1/epoch_013_val_0.460_acc_0.881.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.1264 - accuracy: 0.9579 - val_loss: 0.4602 - val_accuracy: 0.8806\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9590\n",
      "Epoch 00014: val_accuracy did not improve from 0.88055\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.1263 - accuracy: 0.9590 - val_loss: 0.4901 - val_accuracy: 0.8690\n",
      "Epoch 15/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9671\n",
      "Epoch 00015: val_accuracy improved from 0.88055 to 0.88455, saving model to ./storage/mnist_test/kfold1/epoch_015_val_0.426_acc_0.885.h5\n",
      "20276/20276 [==============================] - 18s 898us/sample - loss: 0.0995 - accuracy: 0.9671 - val_loss: 0.4264 - val_accuracy: 0.8845\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9675\n",
      "Epoch 00016: val_accuracy did not improve from 0.88455\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0993 - accuracy: 0.9675 - val_loss: 0.4463 - val_accuracy: 0.8810\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9683\n",
      "Epoch 00017: val_accuracy did not improve from 0.88455\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0980 - accuracy: 0.9683 - val_loss: 0.4597 - val_accuracy: 0.8726\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9652\n",
      "Epoch 00018: val_accuracy improved from 0.88455 to 0.89165, saving model to ./storage/mnist_test/kfold1/epoch_018_val_0.414_acc_0.892.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.1015 - accuracy: 0.9651 - val_loss: 0.4137 - val_accuracy: 0.8917\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9770\n",
      "Epoch 00019: val_accuracy improved from 0.89165 to 0.89343, saving model to ./storage/mnist_test/kfold1/epoch_019_val_0.424_acc_0.893.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0718 - accuracy: 0.9771 - val_loss: 0.4245 - val_accuracy: 0.8934\n",
      "Epoch 20/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9751\n",
      "Epoch 00020: val_accuracy did not improve from 0.89343\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0744 - accuracy: 0.9750 - val_loss: 0.4346 - val_accuracy: 0.8868\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9748\n",
      "Epoch 00021: val_accuracy did not improve from 0.89343\n",
      "20276/20276 [==============================] - 18s 871us/sample - loss: 0.0776 - accuracy: 0.9747 - val_loss: 0.4975 - val_accuracy: 0.8774\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9775\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.89343\n",
      "20276/20276 [==============================] - 18s 870us/sample - loss: 0.0695 - accuracy: 0.9774 - val_loss: 0.4441 - val_accuracy: 0.8832\n",
      "Epoch 23/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9833\n",
      "Epoch 00023: val_accuracy improved from 0.89343 to 0.90764, saving model to ./storage/mnist_test/kfold1/epoch_023_val_0.382_acc_0.908.h5\n",
      "20276/20276 [==============================] - 18s 899us/sample - loss: 0.0503 - accuracy: 0.9833 - val_loss: 0.3815 - val_accuracy: 0.9076\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9866\n",
      "Epoch 00024: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.4220 - val_accuracy: 0.8996\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9887\n",
      "Epoch 00025: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0335 - accuracy: 0.9887 - val_loss: 0.4188 - val_accuracy: 0.8992\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9868\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0405 - accuracy: 0.9868 - val_loss: 0.4621 - val_accuracy: 0.8943\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9880\n",
      "Epoch 00027: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0367 - accuracy: 0.9880 - val_loss: 0.4133 - val_accuracy: 0.9010\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9929\n",
      "Epoch 00028: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.4274 - val_accuracy: 0.9041\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9922\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.4552 - val_accuracy: 0.9005\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9927\n",
      "Epoch 00030: val_accuracy did not improve from 0.90764\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.4562 - val_accuracy: 0.9041\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9939\n",
      "Epoch 00031: val_accuracy improved from 0.90764 to 0.91208, saving model to ./storage/mnist_test/kfold1/epoch_031_val_0.412_acc_0.912.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.4116 - val_accuracy: 0.9121\n",
      "Epoch 32/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9948\n",
      "Epoch 00032: val_accuracy improved from 0.91208 to 0.91741, saving model to ./storage/mnist_test/kfold1/epoch_032_val_0.416_acc_0.917.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.4160 - val_accuracy: 0.9174\n",
      "Epoch 33/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964\n",
      "Epoch 00033: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.4882 - val_accuracy: 0.9072\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9935\n",
      "Epoch 00034: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.4423 - val_accuracy: 0.9107\n",
      "Epoch 35/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9939\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.4343 - val_accuracy: 0.9099\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 00036: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.4160 - val_accuracy: 0.9174\n",
      "Epoch 37/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00037: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 872us/sample - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.4597 - val_accuracy: 0.9072\n",
      "Epoch 38/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.4295 - val_accuracy: 0.9143\n",
      "Epoch 39/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 00039: val_accuracy improved from 0.91741 to 0.92229, saving model to ./storage/mnist_test/kfold1/epoch_039_val_0.396_acc_0.922.h5\n",
      "20276/20276 [==============================] - 18s 898us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.3958 - val_accuracy: 0.9223\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 00040: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.4217 - val_accuracy: 0.9161\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00041: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4197 - val_accuracy: 0.9147\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92229\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4032 - val_accuracy: 0.9214\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00043: val_accuracy improved from 0.92229 to 0.92762, saving model to ./storage/mnist_test/kfold1/epoch_043_val_0.387_acc_0.928.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.3865 - val_accuracy: 0.9276\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00044: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4184 - val_accuracy: 0.9183\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9976\n",
      "Epoch 00045: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.3893 - val_accuracy: 0.9232\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.3880 - val_accuracy: 0.9241\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 00047: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.4071 - val_accuracy: 0.9227\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 00048: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4043 - val_accuracy: 0.9218\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.4110 - val_accuracy: 0.9210\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00050: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.4102 - val_accuracy: 0.9218\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00051: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4420 - val_accuracy: 0.9205\n",
      "Epoch 52/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.4052 - val_accuracy: 0.9214\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00053: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4111 - val_accuracy: 0.9232\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00054: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4056 - val_accuracy: 0.9205\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4319 - val_accuracy: 0.9192\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00056: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.4189 - val_accuracy: 0.9201\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00057: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4194 - val_accuracy: 0.9223\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4111 - val_accuracy: 0.9205\n",
      "Epoch 59/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00059: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.4106 - val_accuracy: 0.9214\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00060: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3994 - val_accuracy: 0.9241\n",
      "Epoch 61/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4011 - val_accuracy: 0.9205\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00062: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4020 - val_accuracy: 0.9196\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00063: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4038 - val_accuracy: 0.9223\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.4159e-04 - accuracy: 0.9999\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 5.4108e-04 - accuracy: 0.9999 - val_loss: 0.4011 - val_accuracy: 0.9214\n",
      "Epoch 65/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.7386e-04 - accuracy: 0.9999\n",
      "Epoch 00065: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 5.7327e-04 - accuracy: 0.9999 - val_loss: 0.3983 - val_accuracy: 0.9218\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.9248e-04 - accuracy: 0.9997\n",
      "Epoch 00066: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 9.9176e-04 - accuracy: 0.9997 - val_loss: 0.4050 - val_accuracy: 0.9227\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.5251e-04 - accuracy: 0.9997\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 8.5176e-04 - accuracy: 0.9997 - val_loss: 0.3939 - val_accuracy: 0.9245\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5609e-04 - accuracy: 1.0000\n",
      "Epoch 00068: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 4.5636e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9227\n",
      "************ Fold 2 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8432 - accuracy: 0.4002\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56439, saving model to ./storage/mnist_test/kfold2/epoch_001_val_1.254_acc_0.564.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8430 - accuracy: 0.4004 - val_loss: 1.2541 - val_accuracy: 0.5644\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0683 - accuracy: 0.6366\n",
      "Epoch 00002: val_accuracy improved from 0.56439 to 0.72647, saving model to ./storage/mnist_test/kfold2/epoch_002_val_0.791_acc_0.726.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 1.0682 - accuracy: 0.6366 - val_loss: 0.7912 - val_accuracy: 0.7265\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7693 - accuracy: 0.7415\n",
      "Epoch 00003: val_accuracy improved from 0.72647 to 0.76687, saving model to ./storage/mnist_test/kfold2/epoch_003_val_0.652_acc_0.767.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 0.7692 - accuracy: 0.7415 - val_loss: 0.6516 - val_accuracy: 0.7669\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5882 - accuracy: 0.8057\n",
      "Epoch 00004: val_accuracy improved from 0.76687 to 0.80062, saving model to ./storage/mnist_test/kfold2/epoch_004_val_0.570_acc_0.801.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.5881 - accuracy: 0.8058 - val_loss: 0.5702 - val_accuracy: 0.8006\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4794 - accuracy: 0.8439\n",
      "Epoch 00005: val_accuracy improved from 0.80062 to 0.82771, saving model to ./storage/mnist_test/kfold2/epoch_005_val_0.510_acc_0.828.h5\n",
      "20276/20276 [==============================] - 18s 900us/sample - loss: 0.4794 - accuracy: 0.8439 - val_loss: 0.5097 - val_accuracy: 0.8277\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8723\n",
      "Epoch 00006: val_accuracy improved from 0.82771 to 0.84547, saving model to ./storage/mnist_test/kfold2/epoch_006_val_0.465_acc_0.845.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.3866 - accuracy: 0.8724 - val_loss: 0.4652 - val_accuracy: 0.8455\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8961\n",
      "Epoch 00007: val_accuracy did not improve from 0.84547\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.3188 - accuracy: 0.8961 - val_loss: 0.4778 - val_accuracy: 0.8428\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.9141\n",
      "Epoch 00008: val_accuracy did not improve from 0.84547\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.2664 - accuracy: 0.9142 - val_loss: 0.4922 - val_accuracy: 0.8415\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9235\n",
      "Epoch 00009: val_accuracy improved from 0.84547 to 0.86901, saving model to ./storage/mnist_test/kfold2/epoch_009_val_0.427_acc_0.869.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.2307 - accuracy: 0.9235 - val_loss: 0.4266 - val_accuracy: 0.8690\n",
      "Epoch 10/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9373\n",
      "Epoch 00010: val_accuracy did not improve from 0.86901\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.1860 - accuracy: 0.9372 - val_loss: 0.4577 - val_accuracy: 0.8677\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9412\n",
      "Epoch 00011: val_accuracy improved from 0.86901 to 0.87389, saving model to ./storage/mnist_test/kfold2/epoch_011_val_0.428_acc_0.874.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.1782 - accuracy: 0.9412 - val_loss: 0.4283 - val_accuracy: 0.8739\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9468\n",
      "Epoch 00012: val_accuracy did not improve from 0.87389\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.1600 - accuracy: 0.9469 - val_loss: 0.4447 - val_accuracy: 0.8699\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9601\n",
      "Epoch 00013: val_accuracy did not improve from 0.87389\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.1214 - accuracy: 0.9600 - val_loss: 0.4459 - val_accuracy: 0.8699\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9619\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.87389\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.1214 - accuracy: 0.9619 - val_loss: 0.4854 - val_accuracy: 0.8655\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9745\n",
      "Epoch 00015: val_accuracy improved from 0.87389 to 0.89387, saving model to ./storage/mnist_test/kfold2/epoch_015_val_0.418_acc_0.894.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0776 - accuracy: 0.9745 - val_loss: 0.4177 - val_accuracy: 0.8939\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 0.9774\n",
      "Epoch 00016: val_accuracy did not improve from 0.89387\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.4427 - val_accuracy: 0.8850\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9747\n",
      "Epoch 00017: val_accuracy did not improve from 0.89387\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.4885 - val_accuracy: 0.8757\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.9755\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89387\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0734 - accuracy: 0.9754 - val_loss: 0.4568 - val_accuracy: 0.8832\n",
      "Epoch 19/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9822\n",
      "Epoch 00019: val_accuracy improved from 0.89387 to 0.90586, saving model to ./storage/mnist_test/kfold2/epoch_019_val_0.377_acc_0.906.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.0521 - accuracy: 0.9822 - val_loss: 0.3775 - val_accuracy: 0.9059\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9869\n",
      "Epoch 00020: val_accuracy improved from 0.90586 to 0.90897, saving model to ./storage/mnist_test/kfold2/epoch_020_val_0.376_acc_0.909.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0401 - accuracy: 0.9869 - val_loss: 0.3761 - val_accuracy: 0.9090\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9871\n",
      "Epoch 00021: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0383 - accuracy: 0.9871 - val_loss: 0.3930 - val_accuracy: 0.9036\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9865\n",
      "Epoch 00022: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.4147 - val_accuracy: 0.8956\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9859\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.5153 - val_accuracy: 0.8854\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9890\n",
      "Epoch 00024: val_accuracy improved from 0.90897 to 0.90941, saving model to ./storage/mnist_test/kfold2/epoch_024_val_0.371_acc_0.909.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.3705 - val_accuracy: 0.9094\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9924\n",
      "Epoch 00025: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.4073 - val_accuracy: 0.9032\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9935\n",
      "Epoch 00026: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.3961 - val_accuracy: 0.9050\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9900\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.4727 - val_accuracy: 0.9001\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 00028: val_accuracy improved from 0.90941 to 0.91341, saving model to ./storage/mnist_test/kfold2/epoch_028_val_0.401_acc_0.913.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.4014 - val_accuracy: 0.9134\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9966\n",
      "Epoch 00029: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.4086 - val_accuracy: 0.9130\n",
      "Epoch 30/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9958\n",
      "Epoch 00030: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.4290 - val_accuracy: 0.9050\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9937\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.3851 - val_accuracy: 0.9103\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9959\n",
      "Epoch 00032: val_accuracy improved from 0.91341 to 0.91519, saving model to ./storage/mnist_test/kfold2/epoch_032_val_0.376_acc_0.915.h5\n",
      "20276/20276 [==============================] - 19s 912us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.3758 - val_accuracy: 0.9152\n",
      "Epoch 33/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 00033: val_accuracy improved from 0.91519 to 0.91785, saving model to ./storage/mnist_test/kfold2/epoch_033_val_0.387_acc_0.918.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.3872 - val_accuracy: 0.9179\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 00034: val_accuracy did not improve from 0.91785\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.4135 - val_accuracy: 0.9143\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9962\n",
      "Epoch 00035: val_accuracy did not improve from 0.91785\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.4109 - val_accuracy: 0.9125\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9958\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.91785\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.4233 - val_accuracy: 0.9094\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 00037: val_accuracy improved from 0.91785 to 0.92007, saving model to ./storage/mnist_test/kfold2/epoch_037_val_0.395_acc_0.920.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.3954 - val_accuracy: 0.9201\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9972\n",
      "Epoch 00038: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.3848 - val_accuracy: 0.9201\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 00039: val_accuracy improved from 0.92007 to 0.92096, saving model to ./storage/mnist_test/kfold2/epoch_039_val_0.401_acc_0.921.h5\n",
      "20276/20276 [==============================] - 18s 899us/sample - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.4007 - val_accuracy: 0.9210\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 00040: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.3780 - val_accuracy: 0.9205\n",
      "Epoch 41/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 00041: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.3900 - val_accuracy: 0.9134\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.3820 - val_accuracy: 0.9179\n",
      "Epoch 43/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 00043: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.3877 - val_accuracy: 0.9165\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 00044: val_accuracy improved from 0.92096 to 0.92229, saving model to ./storage/mnist_test/kfold2/epoch_044_val_0.390_acc_0.922.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.3904 - val_accuracy: 0.9223\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 00045: val_accuracy improved from 0.92229 to 0.92274, saving model to ./storage/mnist_test/kfold2/epoch_045_val_0.406_acc_0.923.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.4055 - val_accuracy: 0.9227\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 00046: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.4115 - val_accuracy: 0.9214\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00047: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.4179 - val_accuracy: 0.9147\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.4241 - val_accuracy: 0.9210\n",
      "Epoch 49/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 00049: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.4224 - val_accuracy: 0.9125\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 00050: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4172 - val_accuracy: 0.9210\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 00051: val_accuracy improved from 0.92274 to 0.92673, saving model to ./storage/mnist_test/kfold2/epoch_051_val_0.381_acc_0.927.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.3810 - val_accuracy: 0.9267\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00052: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.4017 - val_accuracy: 0.9254\n",
      "Epoch 53/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00053: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.4450 - val_accuracy: 0.9183\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.4441 - val_accuracy: 0.9165\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00055: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.4137 - val_accuracy: 0.9223\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00056: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.4202 - val_accuracy: 0.9165\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.4123 - val_accuracy: 0.9205\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00058: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.4077 - val_accuracy: 0.9183\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00059: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4115 - val_accuracy: 0.9218\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.3993 - val_accuracy: 0.9201\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00061: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3933 - val_accuracy: 0.9245\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00062: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3955 - val_accuracy: 0.9241\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4039 - val_accuracy: 0.9227\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00064: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3969 - val_accuracy: 0.9232\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 00065: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4072 - val_accuracy: 0.9205\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4023 - val_accuracy: 0.9183\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.6928e-04 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 9.8164e-04 - accuracy: 0.9997 - val_loss: 0.3937 - val_accuracy: 0.9187\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.5609e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 6.5627e-04 - accuracy: 0.9998 - val_loss: 0.4038 - val_accuracy: 0.9223\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.8677e-04 - accuracy: 0.9999\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 6.8614e-04 - accuracy: 0.9999 - val_loss: 0.3982 - val_accuracy: 0.9250\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.9467e-04 - accuracy: 0.9997\n",
      "Epoch 00070: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 8.9384e-04 - accuracy: 0.9997 - val_loss: 0.4024 - val_accuracy: 0.9258\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00071: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.4010 - val_accuracy: 0.9210\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.3924 - val_accuracy: 0.9236\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00073: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3964 - val_accuracy: 0.9236\n",
      "Epoch 74/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.7718e-04 - accuracy: 0.9999\n",
      "Epoch 00074: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 4.7648e-04 - accuracy: 0.9999 - val_loss: 0.3938 - val_accuracy: 0.9241\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.4331e-04 - accuracy: 0.9999\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 8.4249e-04 - accuracy: 0.9999 - val_loss: 0.3947 - val_accuracy: 0.9245\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7325e-04 - accuracy: 0.9999\n",
      "Epoch 00076: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 5.7272e-04 - accuracy: 0.9999 - val_loss: 0.3909 - val_accuracy: 0.9232\n",
      "************ Fold 3 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8088 - accuracy: 0.4040\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58748, saving model to ./storage/mnist_test/kfold3/epoch_001_val_1.181_acc_0.587.h5\n",
      "20276/20276 [==============================] - 26s 1ms/sample - loss: 1.8077 - accuracy: 0.4043 - val_loss: 1.1810 - val_accuracy: 0.5875\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0460 - accuracy: 0.6437\n",
      "Epoch 00002: val_accuracy improved from 0.58748 to 0.72780, saving model to ./storage/mnist_test/kfold3/epoch_002_val_0.800_acc_0.728.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 1.0460 - accuracy: 0.6436 - val_loss: 0.7996 - val_accuracy: 0.7278\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7630 - accuracy: 0.7437\n",
      "Epoch 00003: val_accuracy improved from 0.72780 to 0.77709, saving model to ./storage/mnist_test/kfold3/epoch_003_val_0.661_acc_0.777.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.7626 - accuracy: 0.7439 - val_loss: 0.6610 - val_accuracy: 0.7771\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5864 - accuracy: 0.8068\n",
      "Epoch 00004: val_accuracy improved from 0.77709 to 0.81794, saving model to ./storage/mnist_test/kfold3/epoch_004_val_0.538_acc_0.818.h5\n",
      "20276/20276 [==============================] - 18s 899us/sample - loss: 0.5866 - accuracy: 0.8067 - val_loss: 0.5377 - val_accuracy: 0.8179\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.8465\n",
      "Epoch 00005: val_accuracy improved from 0.81794 to 0.83792, saving model to ./storage/mnist_test/kfold3/epoch_005_val_0.497_acc_0.838.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.4721 - accuracy: 0.8465 - val_loss: 0.4968 - val_accuracy: 0.8379\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8747\n",
      "Epoch 00006: val_accuracy improved from 0.83792 to 0.84192, saving model to ./storage/mnist_test/kfold3/epoch_006_val_0.471_acc_0.842.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.3797 - accuracy: 0.8746 - val_loss: 0.4706 - val_accuracy: 0.8419\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8955\n",
      "Epoch 00007: val_accuracy did not improve from 0.84192\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.3181 - accuracy: 0.8956 - val_loss: 0.4868 - val_accuracy: 0.8397\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.9088\n",
      "Epoch 00008: val_accuracy improved from 0.84192 to 0.85702, saving model to ./storage/mnist_test/kfold3/epoch_008_val_0.462_acc_0.857.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.2787 - accuracy: 0.9087 - val_loss: 0.4618 - val_accuracy: 0.8570\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9297\n",
      "Epoch 00009: val_accuracy improved from 0.85702 to 0.86989, saving model to ./storage/mnist_test/kfold3/epoch_009_val_0.438_acc_0.870.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.2159 - accuracy: 0.9296 - val_loss: 0.4375 - val_accuracy: 0.8699\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9346\n",
      "Epoch 00010: val_accuracy improved from 0.86989 to 0.89121, saving model to ./storage/mnist_test/kfold3/epoch_010_val_0.393_acc_0.891.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 0.1954 - accuracy: 0.9347 - val_loss: 0.3927 - val_accuracy: 0.8912\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9442\n",
      "Epoch 00011: val_accuracy did not improve from 0.89121\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.1704 - accuracy: 0.9441 - val_loss: 0.3964 - val_accuracy: 0.8894\n",
      "Epoch 12/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9514\n",
      "Epoch 00012: val_accuracy improved from 0.89121 to 0.89165, saving model to ./storage/mnist_test/kfold3/epoch_012_val_0.375_acc_0.892.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.1457 - accuracy: 0.9513 - val_loss: 0.3755 - val_accuracy: 0.8917\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9541\n",
      "Epoch 00013: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.1391 - accuracy: 0.9541 - val_loss: 0.4454 - val_accuracy: 0.8788\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9613\n",
      "Epoch 00014: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.1159 - accuracy: 0.9613 - val_loss: 0.3909 - val_accuracy: 0.8890\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9611\n",
      "Epoch 00015: val_accuracy improved from 0.89165 to 0.89698, saving model to ./storage/mnist_test/kfold3/epoch_015_val_0.373_acc_0.897.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.1194 - accuracy: 0.9612 - val_loss: 0.3728 - val_accuracy: 0.8970\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9665\n",
      "Epoch 00016: val_accuracy did not improve from 0.89698\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0995 - accuracy: 0.9665 - val_loss: 0.4229 - val_accuracy: 0.8841\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9680\n",
      "Epoch 00017: val_accuracy did not improve from 0.89698\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0952 - accuracy: 0.9679 - val_loss: 0.4132 - val_accuracy: 0.8939\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9720\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89698\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0856 - accuracy: 0.9720 - val_loss: 0.4002 - val_accuracy: 0.8970\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 0.9786\n",
      "Epoch 00019: val_accuracy improved from 0.89698 to 0.90808, saving model to ./storage/mnist_test/kfold3/epoch_019_val_0.380_acc_0.908.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.0645 - accuracy: 0.9785 - val_loss: 0.3797 - val_accuracy: 0.9081\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9854\n",
      "Epoch 00020: val_accuracy did not improve from 0.90808\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0480 - accuracy: 0.9854 - val_loss: 0.3775 - val_accuracy: 0.9041\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9809\n",
      "Epoch 00021: val_accuracy improved from 0.90808 to 0.91163, saving model to ./storage/mnist_test/kfold3/epoch_021_val_0.358_acc_0.912.h5\n",
      "20276/20276 [==============================] - 18s 900us/sample - loss: 0.0581 - accuracy: 0.9808 - val_loss: 0.3579 - val_accuracy: 0.9116\n",
      "Epoch 22/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9832\n",
      "Epoch 00022: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.4129 - val_accuracy: 0.9059\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9829\n",
      "Epoch 00023: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0516 - accuracy: 0.9829 - val_loss: 0.4235 - val_accuracy: 0.9059\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9840\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.91163\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.4308 - val_accuracy: 0.8988\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9876\n",
      "Epoch 00025: val_accuracy improved from 0.91163 to 0.91385, saving model to ./storage/mnist_test/kfold3/epoch_025_val_0.402_acc_0.914.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.4019 - val_accuracy: 0.9139\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9896\n",
      "Epoch 00026: val_accuracy improved from 0.91385 to 0.91741, saving model to ./storage/mnist_test/kfold3/epoch_026_val_0.350_acc_0.917.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.3497 - val_accuracy: 0.9174\n",
      "Epoch 27/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9901\n",
      "Epoch 00027: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.3730 - val_accuracy: 0.9147\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9909\n",
      "Epoch 00028: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.4400 - val_accuracy: 0.8979\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9885\n",
      "Epoch 00029: val_accuracy improved from 0.91741 to 0.92007, saving model to ./storage/mnist_test/kfold3/epoch_029_val_0.352_acc_0.920.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.3525 - val_accuracy: 0.9201\n",
      "Epoch 30/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9910\n",
      "Epoch 00030: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.3698 - val_accuracy: 0.9170\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9918\n",
      "Epoch 00031: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.4030 - val_accuracy: 0.9107\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9898\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.3833 - val_accuracy: 0.9192\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 00033: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.3734 - val_accuracy: 0.9161\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.3983 - val_accuracy: 0.9116\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9949\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92007\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.3553 - val_accuracy: 0.9187\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9960\n",
      "Epoch 00036: val_accuracy improved from 0.92007 to 0.92673, saving model to ./storage/mnist_test/kfold3/epoch_036_val_0.336_acc_0.927.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.3359 - val_accuracy: 0.9267\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 00037: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.3853 - val_accuracy: 0.9192\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9958\n",
      "Epoch 00038: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.3637 - val_accuracy: 0.9196\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.3453 - val_accuracy: 0.9232\n",
      "Epoch 40/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 00040: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.3622 - val_accuracy: 0.9223\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9976\n",
      "Epoch 00041: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.3559 - val_accuracy: 0.9263\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.3369 - val_accuracy: 0.9258\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00043: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.3334 - val_accuracy: 0.9254\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 00044: val_accuracy improved from 0.92673 to 0.92851, saving model to ./storage/mnist_test/kfold3/epoch_044_val_0.342_acc_0.929.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.3415 - val_accuracy: 0.9285\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 00045: val_accuracy improved from 0.92851 to 0.93028, saving model to ./storage/mnist_test/kfold3/epoch_045_val_0.339_acc_0.930.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.3393 - val_accuracy: 0.9303\n",
      "Epoch 46/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00046: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.3477 - val_accuracy: 0.9281\n",
      "Epoch 47/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00047: val_accuracy improved from 0.93028 to 0.93384, saving model to ./storage/mnist_test/kfold3/epoch_047_val_0.347_acc_0.934.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.3468 - val_accuracy: 0.9338\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 00048: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.3614 - val_accuracy: 0.9258\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00049: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3453 - val_accuracy: 0.9316\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.3368 - val_accuracy: 0.9329\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00051: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.3540 - val_accuracy: 0.9329\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 00052: val_accuracy did not improve from 0.93384\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.3409 - val_accuracy: 0.9307\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00053: val_accuracy improved from 0.93384 to 0.93428, saving model to ./storage/mnist_test/kfold3/epoch_053_val_0.335_acc_0.934.h5\n",
      "20276/20276 [==============================] - 19s 917us/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.3348 - val_accuracy: 0.9343\n",
      "Epoch 54/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00054: val_accuracy did not improve from 0.93428\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3477 - val_accuracy: 0.9325\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 00055: val_accuracy did not improve from 0.93428\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.3591 - val_accuracy: 0.9325\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.93428\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.3704 - val_accuracy: 0.9307\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00057: val_accuracy improved from 0.93428 to 0.94050, saving model to ./storage/mnist_test/kfold3/epoch_057_val_0.353_acc_0.940.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3532 - val_accuracy: 0.9405\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00058: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.3727 - val_accuracy: 0.9343\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00059: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.3652 - val_accuracy: 0.9343\n",
      "Epoch 60/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.3411 - val_accuracy: 0.9352\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00061: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3756 - val_accuracy: 0.9321\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00062: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3642 - val_accuracy: 0.9387\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3731 - val_accuracy: 0.9361\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00064: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.3441 - val_accuracy: 0.9378\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 00065: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.3491 - val_accuracy: 0.9383\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3375 - val_accuracy: 0.9378\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.3476 - val_accuracy: 0.9361\n",
      "Epoch 68/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00068: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3438 - val_accuracy: 0.9365\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3506 - val_accuracy: 0.9356\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00070: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.3481 - val_accuracy: 0.9361\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 00071: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.3422 - val_accuracy: 0.9383\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3602 - val_accuracy: 0.9347\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.2800e-04 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 9.3405e-04 - accuracy: 0.9997 - val_loss: 0.3569 - val_accuracy: 0.9338\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00074: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3542 - val_accuracy: 0.9374\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.3249e-04 - accuracy: 0.9999\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.3238e-04 - accuracy: 0.9999 - val_loss: 0.3506 - val_accuracy: 0.9369\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.3949e-04 - accuracy: 0.9997\n",
      "Epoch 00076: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 8.3882e-04 - accuracy: 0.9997 - val_loss: 0.3434 - val_accuracy: 0.9374\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.7291e-04 - accuracy: 0.9999\n",
      "Epoch 00077: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 4.8136e-04 - accuracy: 0.9999 - val_loss: 0.3428 - val_accuracy: 0.9369\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.3866e-04 - accuracy: 0.9998\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 6.3705e-04 - accuracy: 0.9998 - val_loss: 0.3392 - val_accuracy: 0.9356\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.5825e-04 - accuracy: 0.9998\n",
      "Epoch 00079: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 9.6418e-04 - accuracy: 0.9997 - val_loss: 0.3418 - val_accuracy: 0.9365\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.6671e-04 - accuracy: 0.9999\n",
      "Epoch 00080: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 6.6514e-04 - accuracy: 0.9999 - val_loss: 0.3394 - val_accuracy: 0.9369\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.1662e-04 - accuracy: 0.9997\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 7.1614e-04 - accuracy: 0.9997 - val_loss: 0.3368 - val_accuracy: 0.9361\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4980e-04 - accuracy: 0.9999\n",
      "Epoch 00082: val_accuracy did not improve from 0.94050\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 4.5187e-04 - accuracy: 0.9999 - val_loss: 0.3357 - val_accuracy: 0.9365\n",
      "************ Fold 4 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8580 - accuracy: 0.3954\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54396, saving model to ./storage/mnist_test/kfold4/epoch_001_val_1.354_acc_0.544.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8572 - accuracy: 0.3956 - val_loss: 1.3536 - val_accuracy: 0.5440\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0700 - accuracy: 0.6373\n",
      "Epoch 00002: val_accuracy improved from 0.54396 to 0.73623, saving model to ./storage/mnist_test/kfold4/epoch_002_val_0.800_acc_0.736.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 1.0700 - accuracy: 0.6373 - val_loss: 0.7999 - val_accuracy: 0.7362\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7661 - accuracy: 0.7424\n",
      "Epoch 00003: val_accuracy improved from 0.73623 to 0.78286, saving model to ./storage/mnist_test/kfold4/epoch_003_val_0.666_acc_0.783.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.7662 - accuracy: 0.7424 - val_loss: 0.6664 - val_accuracy: 0.7829\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5968 - accuracy: 0.8013\n",
      "Epoch 00004: val_accuracy improved from 0.78286 to 0.81350, saving model to ./storage/mnist_test/kfold4/epoch_004_val_0.565_acc_0.813.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.5968 - accuracy: 0.8013 - val_loss: 0.5647 - val_accuracy: 0.8135\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8498\n",
      "Epoch 00005: val_accuracy improved from 0.81350 to 0.82815, saving model to ./storage/mnist_test/kfold4/epoch_005_val_0.539_acc_0.828.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.4613 - accuracy: 0.8498 - val_loss: 0.5390 - val_accuracy: 0.8282\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8784\n",
      "Epoch 00006: val_accuracy improved from 0.82815 to 0.84680, saving model to ./storage/mnist_test/kfold4/epoch_006_val_0.490_acc_0.847.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.3742 - accuracy: 0.8784 - val_loss: 0.4897 - val_accuracy: 0.8468\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.8975\n",
      "Epoch 00007: val_accuracy improved from 0.84680 to 0.85435, saving model to ./storage/mnist_test/kfold4/epoch_007_val_0.487_acc_0.854.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.3134 - accuracy: 0.8975 - val_loss: 0.4868 - val_accuracy: 0.8544\n",
      "Epoch 8/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9117\n",
      "Epoch 00008: val_accuracy improved from 0.85435 to 0.85790, saving model to ./storage/mnist_test/kfold4/epoch_008_val_0.474_acc_0.858.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.2652 - accuracy: 0.9117 - val_loss: 0.4737 - val_accuracy: 0.8579\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2254 - accuracy: 0.9238\n",
      "Epoch 00009: val_accuracy improved from 0.85790 to 0.87522, saving model to ./storage/mnist_test/kfold4/epoch_009_val_0.416_acc_0.875.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.2253 - accuracy: 0.9239 - val_loss: 0.4155 - val_accuracy: 0.8752\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9365\n",
      "Epoch 00010: val_accuracy did not improve from 0.87522\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.1869 - accuracy: 0.9364 - val_loss: 0.4417 - val_accuracy: 0.8632\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9474\n",
      "Epoch 00011: val_accuracy did not improve from 0.87522\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.1562 - accuracy: 0.9474 - val_loss: 0.4752 - val_accuracy: 0.8743\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1542 - accuracy: 0.9481\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87522\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.1543 - accuracy: 0.9480 - val_loss: 0.4919 - val_accuracy: 0.8712\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9684\n",
      "Epoch 00013: val_accuracy improved from 0.87522 to 0.88410, saving model to ./storage/mnist_test/kfold4/epoch_013_val_0.427_acc_0.884.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 0.0954 - accuracy: 0.9684 - val_loss: 0.4270 - val_accuracy: 0.8841\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9750\n",
      "Epoch 00014: val_accuracy improved from 0.88410 to 0.88499, saving model to ./storage/mnist_test/kfold4/epoch_014_val_0.471_acc_0.885.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.4709 - val_accuracy: 0.8850\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9690\n",
      "Epoch 00015: val_accuracy did not improve from 0.88499\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0925 - accuracy: 0.9690 - val_loss: 0.4748 - val_accuracy: 0.8748\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9711\n",
      "Epoch 00016: val_accuracy improved from 0.88499 to 0.88544, saving model to ./storage/mnist_test/kfold4/epoch_016_val_0.452_acc_0.885.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0877 - accuracy: 0.9710 - val_loss: 0.4521 - val_accuracy: 0.8854\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9790\n",
      "Epoch 00017: val_accuracy did not improve from 0.88544\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.4764 - val_accuracy: 0.8837\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9749\n",
      "Epoch 00018: val_accuracy improved from 0.88544 to 0.89165, saving model to ./storage/mnist_test/kfold4/epoch_018_val_0.452_acc_0.892.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 0.0756 - accuracy: 0.9748 - val_loss: 0.4518 - val_accuracy: 0.8917\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9764\n",
      "Epoch 00019: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0693 - accuracy: 0.9764 - val_loss: 0.4497 - val_accuracy: 0.8872\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9816\n",
      "Epoch 00020: val_accuracy improved from 0.89165 to 0.90231, saving model to ./storage/mnist_test/kfold4/epoch_020_val_0.419_acc_0.902.h5\n",
      "20276/20276 [==============================] - 19s 915us/sample - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.4190 - val_accuracy: 0.9023\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9796\n",
      "Epoch 00021: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0603 - accuracy: 0.9796 - val_loss: 0.4796 - val_accuracy: 0.8899\n",
      "Epoch 22/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9776\n",
      "Epoch 00022: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0721 - accuracy: 0.9775 - val_loss: 0.5126 - val_accuracy: 0.8863\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9810\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90231\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.4682 - val_accuracy: 0.8894\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9888\n",
      "Epoch 00024: val_accuracy improved from 0.90231 to 0.90853, saving model to ./storage/mnist_test/kfold4/epoch_024_val_0.385_acc_0.909.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.3855 - val_accuracy: 0.9085\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9886\n",
      "Epoch 00025: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.4807 - val_accuracy: 0.8934\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9897\n",
      "Epoch 00026: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.4866 - val_accuracy: 0.8974\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9884\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90853\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.4503 - val_accuracy: 0.9067\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9918\n",
      "Epoch 00028: val_accuracy improved from 0.90853 to 0.90941, saving model to ./storage/mnist_test/kfold4/epoch_028_val_0.436_acc_0.909.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.4363 - val_accuracy: 0.9094\n",
      "Epoch 29/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 00029: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.4167 - val_accuracy: 0.9094\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9930\n",
      "Epoch 00030: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.4595 - val_accuracy: 0.9019\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.4468 - val_accuracy: 0.9050\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9953\n",
      "Epoch 00032: val_accuracy did not improve from 0.90941\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.4375 - val_accuracy: 0.9076\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9948\n",
      "Epoch 00033: val_accuracy improved from 0.90941 to 0.91208, saving model to ./storage/mnist_test/kfold4/epoch_033_val_0.425_acc_0.912.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.4249 - val_accuracy: 0.9121\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9954\n",
      "Epoch 00034: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.4609 - val_accuracy: 0.9107\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 00035: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.4548 - val_accuracy: 0.9063\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.4681 - val_accuracy: 0.9023\n",
      "Epoch 37/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 00037: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.4766 - val_accuracy: 0.9010\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9967\n",
      "Epoch 00038: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.5091 - val_accuracy: 0.9019\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.91208\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.4694 - val_accuracy: 0.9072\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 00040: val_accuracy improved from 0.91208 to 0.91519, saving model to ./storage/mnist_test/kfold4/epoch_040_val_0.433_acc_0.915.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.4331 - val_accuracy: 0.9152\n",
      "Epoch 41/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 00041: val_accuracy improved from 0.91519 to 0.91652, saving model to ./storage/mnist_test/kfold4/epoch_041_val_0.430_acc_0.917.h5\n",
      "20276/20276 [==============================] - 19s 916us/sample - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.4295 - val_accuracy: 0.9165\n",
      "Epoch 42/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00042: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.4432 - val_accuracy: 0.9165\n",
      "Epoch 43/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 00043: val_accuracy improved from 0.91652 to 0.91741, saving model to ./storage/mnist_test/kfold4/epoch_043_val_0.437_acc_0.917.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4368 - val_accuracy: 0.9174\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00044: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.4255 - val_accuracy: 0.9152\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 00045: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.4553 - val_accuracy: 0.9174\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 00046: val_accuracy improved from 0.91741 to 0.91918, saving model to ./storage/mnist_test/kfold4/epoch_046_val_0.455_acc_0.919.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.4548 - val_accuracy: 0.9192\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 00047: val_accuracy improved from 0.91918 to 0.92451, saving model to ./storage/mnist_test/kfold4/epoch_047_val_0.423_acc_0.925.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.4233 - val_accuracy: 0.9245\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 00048: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.4684 - val_accuracy: 0.9187\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00049: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.4973 - val_accuracy: 0.9134\n",
      "Epoch 50/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9975\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.4322 - val_accuracy: 0.9179\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 00051: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.4532 - val_accuracy: 0.9179\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 00052: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.4342 - val_accuracy: 0.9210\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.4474 - val_accuracy: 0.9143\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 00054: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.4399 - val_accuracy: 0.9210\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 00055: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.4192 - val_accuracy: 0.9227\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.4149 - val_accuracy: 0.9205\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00057: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.4177 - val_accuracy: 0.9210\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00058: val_accuracy improved from 0.92451 to 0.92584, saving model to ./storage/mnist_test/kfold4/epoch_058_val_0.424_acc_0.926.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.4245 - val_accuracy: 0.9258\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00059: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4473 - val_accuracy: 0.9201\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 00060: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.4332 - val_accuracy: 0.9218\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.4602 - val_accuracy: 0.9236\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00062: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.4560 - val_accuracy: 0.9223\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00063: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4424 - val_accuracy: 0.9245\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.92584\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.4492 - val_accuracy: 0.9254\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00065: val_accuracy improved from 0.92584 to 0.92673, saving model to ./storage/mnist_test/kfold4/epoch_065_val_0.431_acc_0.927.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4311 - val_accuracy: 0.9267\n",
      "Epoch 66/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00066: val_accuracy improved from 0.92673 to 0.92762, saving model to ./storage/mnist_test/kfold4/epoch_066_val_0.430_acc_0.928.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4296 - val_accuracy: 0.9276\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00067: val_accuracy improved from 0.92762 to 0.92806, saving model to ./storage/mnist_test/kfold4/epoch_067_val_0.437_acc_0.928.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4369 - val_accuracy: 0.9281\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6504e-04 - accuracy: 0.9999\n",
      "Epoch 00068: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 5.6452e-04 - accuracy: 0.9999 - val_loss: 0.4367 - val_accuracy: 0.9281\n",
      "Epoch 69/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00069: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4365 - val_accuracy: 0.9258\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.4325 - val_accuracy: 0.9281\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00071: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4265 - val_accuracy: 0.9281\n",
      "Epoch 72/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00072: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4426 - val_accuracy: 0.9250\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.8929e-04 - accuracy: 0.9998\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 9.8835e-04 - accuracy: 0.9998 - val_loss: 0.4181 - val_accuracy: 0.9263\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.8192e-04 - accuracy: 0.9998\n",
      "Epoch 00074: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 9.8097e-04 - accuracy: 0.9998 - val_loss: 0.4280 - val_accuracy: 0.9267\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch 00075: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.4257 - val_accuracy: 0.9272\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.4038e-04 - accuracy: 0.9998\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 7.4002e-04 - accuracy: 0.9998 - val_loss: 0.4348 - val_accuracy: 0.9241\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7736e-04 - accuracy: 0.9999\n",
      "Epoch 00077: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 6.7670e-04 - accuracy: 0.9999 - val_loss: 0.4344 - val_accuracy: 0.9227\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00078: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4365 - val_accuracy: 0.9227\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9995\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.92806\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.4374 - val_accuracy: 0.9272\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch 00080: val_accuracy improved from 0.92806 to 0.92940, saving model to ./storage/mnist_test/kfold4/epoch_080_val_0.433_acc_0.929.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.4332 - val_accuracy: 0.9294\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4222e-04 - accuracy: 1.0000\n",
      "Epoch 00081: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 4.4230e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9285\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7367e-04 - accuracy: 0.9999\n",
      "Epoch 00082: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 6.7301e-04 - accuracy: 0.9999 - val_loss: 0.4315 - val_accuracy: 0.9281\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5340e-04 - accuracy: 0.9999\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.6181e-04 - accuracy: 0.9999 - val_loss: 0.4280 - val_accuracy: 0.9272\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.9205e-04 - accuracy: 0.9999\n",
      "Epoch 00084: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 4.9193e-04 - accuracy: 0.9999 - val_loss: 0.4309 - val_accuracy: 0.9267\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0698e-04 - accuracy: 0.9999\n",
      "Epoch 00085: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 5.0652e-04 - accuracy: 0.9999 - val_loss: 0.4270 - val_accuracy: 0.9290\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.0381e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy improved from 0.92940 to 0.93028, saving model to ./storage/mnist_test/kfold4/epoch_086_val_0.423_acc_0.930.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 6.0322e-04 - accuracy: 0.9999 - val_loss: 0.4229 - val_accuracy: 0.9303\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.6558e-04 - accuracy: 0.9998\n",
      "Epoch 00087: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 6.6493e-04 - accuracy: 0.9998 - val_loss: 0.4239 - val_accuracy: 0.9298\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.9846e-04 - accuracy: 0.9998\n",
      "Epoch 00088: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 5.9787e-04 - accuracy: 0.9998 - val_loss: 0.4284 - val_accuracy: 0.9290\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.6366e-04 - accuracy: 0.9999\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 4.6322e-04 - accuracy: 0.9999 - val_loss: 0.4293 - val_accuracy: 0.9294\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0250e-04 - accuracy: 0.9998\n",
      "Epoch 00090: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 5.0201e-04 - accuracy: 0.9998 - val_loss: 0.4332 - val_accuracy: 0.9272\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8548e-04 - accuracy: 1.0000\n",
      "Epoch 00091: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 2.8520e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9294\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.5363e-04 - accuracy: 0.9997\n",
      "Epoch 00092: val_accuracy improved from 0.93028 to 0.93073, saving model to ./storage/mnist_test/kfold4/epoch_092_val_0.424_acc_0.931.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 7.5491e-04 - accuracy: 0.9997 - val_loss: 0.4244 - val_accuracy: 0.9307\n",
      "Epoch 93/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.7186e-04 - accuracy: 0.9999\n",
      "Epoch 00093: val_accuracy did not improve from 0.93073\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 5.7044e-04 - accuracy: 0.9999 - val_loss: 0.4252 - val_accuracy: 0.9294\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0640e-04 - accuracy: 0.9999\n",
      "Epoch 00094: val_accuracy did not improve from 0.93073\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 3.0617e-04 - accuracy: 0.9999 - val_loss: 0.4243 - val_accuracy: 0.9298\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2450e-04 - accuracy: 0.9999\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.93073\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.2409e-04 - accuracy: 0.9999 - val_loss: 0.4232 - val_accuracy: 0.9294\n",
      "Epoch 96/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2066e-04 - accuracy: 0.9999\n",
      "Epoch 00096: val_accuracy did not improve from 0.93073\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 4.2025e-04 - accuracy: 0.9999 - val_loss: 0.4221 - val_accuracy: 0.9290\n",
      "Epoch 97/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7061e-04 - accuracy: 0.9998\n",
      "Epoch 00097: val_accuracy did not improve from 0.93073\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 6.7030e-04 - accuracy: 0.9998 - val_loss: 0.4196 - val_accuracy: 0.9307\n",
      "Epoch 98/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.1529e-04 - accuracy: 1.0000\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.93073\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 3.1472e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9303\n",
      "Epoch 99/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.9487e-04 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy improved from 0.93073 to 0.93162, saving model to ./storage/mnist_test/kfold4/epoch_099_val_0.424_acc_0.932.h5\n",
      "20276/20276 [==============================] - 19s 917us/sample - loss: 1.9442e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9316\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5083e-04 - accuracy: 0.9998\n",
      "Epoch 00100: val_accuracy improved from 0.93162 to 0.93206, saving model to ./storage/mnist_test/kfold4/epoch_100_val_0.420_acc_0.932.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 4.5044e-04 - accuracy: 0.9998 - val_loss: 0.4195 - val_accuracy: 0.9321\n",
      "Epoch 101/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.6247e-04 - accuracy: 0.9999\n",
      "Epoch 00101: val_accuracy improved from 0.93206 to 0.93250, saving model to ./storage/mnist_test/kfold4/epoch_101_val_0.418_acc_0.933.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 4.6215e-04 - accuracy: 0.9999 - val_loss: 0.4185 - val_accuracy: 0.9325\n",
      "Epoch 102/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1790e-04 - accuracy: 1.0000\n",
      "Epoch 00102: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 2.2728e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9316\n",
      "Epoch 103/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7583e-04 - accuracy: 0.9999\n",
      "Epoch 00103: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.7546e-04 - accuracy: 0.9999 - val_loss: 0.4163 - val_accuracy: 0.9298\n",
      "Epoch 104/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0307e-04 - accuracy: 1.0000\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.0349e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9294\n",
      "Epoch 105/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.9824e-04 - accuracy: 1.0000\n",
      "Epoch 00105: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 1.9807e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9307\n",
      "Epoch 106/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0286e-04 - accuracy: 0.9999\n",
      "Epoch 00106: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 3.0261e-04 - accuracy: 0.9999 - val_loss: 0.4191 - val_accuracy: 0.9307\n",
      "Epoch 107/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.5820e-04 - accuracy: 0.9999\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.5779e-04 - accuracy: 0.9999 - val_loss: 0.4189 - val_accuracy: 0.9321\n",
      "Epoch 108/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8742e-04 - accuracy: 1.0000\n",
      "Epoch 00108: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 3.8705e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9325\n",
      "Epoch 109/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2990e-04 - accuracy: 1.0000\n",
      "Epoch 00109: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 3.2983e-04 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9312\n",
      "Epoch 110/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.1364e-04 - accuracy: 1.0000\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 3.1335e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9307\n",
      "Epoch 111/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.5617e-04 - accuracy: 1.0000\n",
      "Epoch 00111: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 2.5597e-04 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9321\n",
      "Epoch 112/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.5889e-04 - accuracy: 0.9999\n",
      "Epoch 00112: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 3.0968e-04 - accuracy: 0.9999 - val_loss: 0.4208 - val_accuracy: 0.9312\n",
      "Epoch 113/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7009e-04 - accuracy: 1.0000\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 1.6994e-04 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9298\n",
      "Epoch 114/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.9085e-04 - accuracy: 1.0000\n",
      "Epoch 00114: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 3.0091e-04 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9316\n",
      "Epoch 115/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6975e-04 - accuracy: 0.9999\n",
      "Epoch 00115: val_accuracy improved from 0.93250 to 0.93295, saving model to ./storage/mnist_test/kfold4/epoch_115_val_0.424_acc_0.933.h5\n",
      "20276/20276 [==============================] - 19s 917us/sample - loss: 3.6939e-04 - accuracy: 0.9999 - val_loss: 0.4243 - val_accuracy: 0.9329\n",
      "Epoch 116/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.6688e-04 - accuracy: 1.0000\n",
      "Epoch 00116: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 1.6784e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9307\n",
      "Epoch 117/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.9917e-04 - accuracy: 1.0000\n",
      "Epoch 00117: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 3.6064e-04 - accuracy: 0.9999 - val_loss: 0.4222 - val_accuracy: 0.9325\n",
      "Epoch 118/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.7326e-04 - accuracy: 0.9999\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 2.7299e-04 - accuracy: 0.9999 - val_loss: 0.4217 - val_accuracy: 0.9325\n",
      "Epoch 119/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.3771e-04 - accuracy: 1.0000\n",
      "Epoch 00119: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 2.3748e-04 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9329\n",
      "Epoch 120/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.4036e-04 - accuracy: 1.0000\n",
      "Epoch 00120: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 2.4014e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9321\n",
      "Epoch 121/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.7351e-04 - accuracy: 0.9999\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 2.7354e-04 - accuracy: 0.9999 - val_loss: 0.4242 - val_accuracy: 0.9329\n",
      "Epoch 122/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2080e-04 - accuracy: 0.9999\n",
      "Epoch 00122: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.2056e-04 - accuracy: 0.9999 - val_loss: 0.4219 - val_accuracy: 0.9316\n",
      "Epoch 123/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.2331e-04 - accuracy: 0.9999\n",
      "Epoch 00123: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 5.2203e-04 - accuracy: 0.9999 - val_loss: 0.4237 - val_accuracy: 0.9312\n",
      "Epoch 124/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2812e-04 - accuracy: 1.0000\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 3.0223149224184457e-06.\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 4.2772e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9294\n",
      "Epoch 125/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8724e-04 - accuracy: 1.0000\n",
      "Epoch 00125: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 1.8709e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9321\n",
      "Epoch 126/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1959e-04 - accuracy: 1.0000\n",
      "Epoch 00126: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 2.1940e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9316\n",
      "Epoch 127/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.1757e-04 - accuracy: 1.0000\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 2.4178520106943328e-06.\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 3.1738e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9307\n",
      "Epoch 128/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.7901e-04 - accuracy: 1.0000\n",
      "Epoch 00128: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 1.7860e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9325\n",
      "Epoch 129/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.7054e-04 - accuracy: 1.0000\n",
      "Epoch 00129: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 2.7040e-04 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9316\n",
      "Epoch 130/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.8366e-04 - accuracy: 1.0000\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.9342816813150422e-06.\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 2.9257e-04 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9316\n",
      "Epoch 131/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.3683e-04 - accuracy: 1.0000\n",
      "Epoch 00131: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 1.3673e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9329\n",
      "Epoch 132/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5231e-04 - accuracy: 0.9999\n",
      "Epoch 00132: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 3.5198e-04 - accuracy: 0.9999 - val_loss: 0.4244 - val_accuracy: 0.9312\n",
      "Epoch 133/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.6552e-04 - accuracy: 0.9999\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.547425381431822e-06.\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 4.6519e-04 - accuracy: 0.9999 - val_loss: 0.4241 - val_accuracy: 0.9312\n",
      "Epoch 134/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.6899e-04 - accuracy: 1.0000\n",
      "Epoch 00134: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 1.6883e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9307\n",
      "Epoch 135/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2633e-04 - accuracy: 0.9999\n",
      "Epoch 00135: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 2.2611e-04 - accuracy: 0.9999 - val_loss: 0.4261 - val_accuracy: 0.9325\n",
      "Epoch 136/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8341e-04 - accuracy: 1.0000\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1.2379403415252455e-06.\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 1.8369e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9312\n",
      "Epoch 137/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.5343e-04 - accuracy: 1.0000\n",
      "Epoch 00137: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 1.5328e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9325\n",
      "Epoch 138/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.3032e-04 - accuracy: 1.0000\n",
      "Epoch 00138: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 1.3019e-04 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9321\n",
      "Epoch 139/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.0123e-04 - accuracy: 1.0000\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.903522368404083e-07.\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 2.0114e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9325\n",
      "Epoch 140/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.9454e-04 - accuracy: 0.9999\n",
      "Epoch 00140: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 2.9426e-04 - accuracy: 0.9999 - val_loss: 0.4211 - val_accuracy: 0.9329\n",
      "************ Fold 5 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8006 - accuracy: 0.4086\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56616, saving model to ./storage/mnist_test/kfold5/epoch_001_val_1.271_acc_0.566.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8004 - accuracy: 0.4086 - val_loss: 1.2708 - val_accuracy: 0.5662\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0426 - accuracy: 0.6449\n",
      "Epoch 00002: val_accuracy improved from 0.56616 to 0.73623, saving model to ./storage/mnist_test/kfold5/epoch_002_val_0.758_acc_0.736.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 1.0423 - accuracy: 0.6449 - val_loss: 0.7583 - val_accuracy: 0.7362\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7525 - accuracy: 0.7505\n",
      "Epoch 00003: val_accuracy improved from 0.73623 to 0.77531, saving model to ./storage/mnist_test/kfold5/epoch_003_val_0.661_acc_0.775.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.7527 - accuracy: 0.7504 - val_loss: 0.6607 - val_accuracy: 0.7753\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5738 - accuracy: 0.8113\n",
      "Epoch 00004: val_accuracy improved from 0.77531 to 0.81705, saving model to ./storage/mnist_test/kfold5/epoch_004_val_0.561_acc_0.817.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 0.5737 - accuracy: 0.8113 - val_loss: 0.5607 - val_accuracy: 0.8171\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4597 - accuracy: 0.8480\n",
      "Epoch 00005: val_accuracy improved from 0.81705 to 0.83970, saving model to ./storage/mnist_test/kfold5/epoch_005_val_0.503_acc_0.840.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.4596 - accuracy: 0.8480 - val_loss: 0.5033 - val_accuracy: 0.8397\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3666 - accuracy: 0.8828\n",
      "Epoch 00006: val_accuracy improved from 0.83970 to 0.84591, saving model to ./storage/mnist_test/kfold5/epoch_006_val_0.467_acc_0.846.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.3665 - accuracy: 0.8828 - val_loss: 0.4669 - val_accuracy: 0.8459\n",
      "Epoch 7/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.8992\n",
      "Epoch 00007: val_accuracy improved from 0.84591 to 0.85036, saving model to ./storage/mnist_test/kfold5/epoch_007_val_0.496_acc_0.850.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.3037 - accuracy: 0.8989 - val_loss: 0.4964 - val_accuracy: 0.8504\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9158\n",
      "Epoch 00008: val_accuracy improved from 0.85036 to 0.86812, saving model to ./storage/mnist_test/kfold5/epoch_008_val_0.420_acc_0.868.h5\n",
      "20276/20276 [==============================] - 19s 917us/sample - loss: 0.2552 - accuracy: 0.9159 - val_loss: 0.4204 - val_accuracy: 0.8681\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9274\n",
      "Epoch 00009: val_accuracy improved from 0.86812 to 0.87478, saving model to ./storage/mnist_test/kfold5/epoch_009_val_0.430_acc_0.875.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.2225 - accuracy: 0.9274 - val_loss: 0.4295 - val_accuracy: 0.8748\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.9365\n",
      "Epoch 00010: val_accuracy did not improve from 0.87478\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.1884 - accuracy: 0.9364 - val_loss: 0.4530 - val_accuracy: 0.8739\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9472\n",
      "Epoch 00011: val_accuracy improved from 0.87478 to 0.88766, saving model to ./storage/mnist_test/kfold5/epoch_011_val_0.395_acc_0.888.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.1587 - accuracy: 0.9472 - val_loss: 0.3950 - val_accuracy: 0.8877\n",
      "Epoch 12/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9512\n",
      "Epoch 00012: val_accuracy improved from 0.88766 to 0.88810, saving model to ./storage/mnist_test/kfold5/epoch_012_val_0.379_acc_0.888.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.1449 - accuracy: 0.9512 - val_loss: 0.3787 - val_accuracy: 0.8881\n",
      "Epoch 13/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.9570\n",
      "Epoch 00013: val_accuracy did not improve from 0.88810\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.1356 - accuracy: 0.9568 - val_loss: 0.3990 - val_accuracy: 0.8881\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9597\n",
      "Epoch 00014: val_accuracy improved from 0.88810 to 0.89787, saving model to ./storage/mnist_test/kfold5/epoch_014_val_0.374_acc_0.898.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.1212 - accuracy: 0.9597 - val_loss: 0.3736 - val_accuracy: 0.8979\n",
      "Epoch 15/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9635\n",
      "Epoch 00015: val_accuracy did not improve from 0.89787\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.1147 - accuracy: 0.9633 - val_loss: 0.4377 - val_accuracy: 0.8877\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9648\n",
      "Epoch 00016: val_accuracy did not improve from 0.89787\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.1036 - accuracy: 0.9648 - val_loss: 0.3980 - val_accuracy: 0.8854\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9764\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.89787\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0770 - accuracy: 0.9763 - val_loss: 0.4397 - val_accuracy: 0.8877\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9782\n",
      "Epoch 00018: val_accuracy improved from 0.89787 to 0.90409, saving model to ./storage/mnist_test/kfold5/epoch_018_val_0.375_acc_0.904.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.0647 - accuracy: 0.9781 - val_loss: 0.3749 - val_accuracy: 0.9041\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9817\n",
      "Epoch 00019: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0537 - accuracy: 0.9817 - val_loss: 0.4078 - val_accuracy: 0.9001\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9831\n",
      "Epoch 00020: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.4322 - val_accuracy: 0.8934\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9811\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0576 - accuracy: 0.9812 - val_loss: 0.4311 - val_accuracy: 0.8934\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9868\n",
      "Epoch 00022: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0404 - accuracy: 0.9868 - val_loss: 0.3915 - val_accuracy: 0.9036\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9888\n",
      "Epoch 00023: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0345 - accuracy: 0.9888 - val_loss: 0.4294 - val_accuracy: 0.9019\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9885\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0347 - accuracy: 0.9885 - val_loss: 0.4245 - val_accuracy: 0.9005\n",
      "Epoch 25/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 00025: val_accuracy did not improve from 0.90409\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.3873 - val_accuracy: 0.9014\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9929\n",
      "Epoch 00026: val_accuracy improved from 0.90409 to 0.91385, saving model to ./storage/mnist_test/kfold5/epoch_026_val_0.378_acc_0.914.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.3775 - val_accuracy: 0.9139\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9919\n",
      "Epoch 00027: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0220 - accuracy: 0.9919 - val_loss: 0.4059 - val_accuracy: 0.9121\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 00028: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.4486 - val_accuracy: 0.9059\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9921\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.4741 - val_accuracy: 0.8979\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9946\n",
      "Epoch 00030: val_accuracy improved from 0.91385 to 0.91563, saving model to ./storage/mnist_test/kfold5/epoch_030_val_0.409_acc_0.916.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.4091 - val_accuracy: 0.9156\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 00031: val_accuracy improved from 0.91563 to 0.91874, saving model to ./storage/mnist_test/kfold5/epoch_031_val_0.401_acc_0.919.h5\n",
      "20276/20276 [==============================] - 18s 900us/sample - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.4012 - val_accuracy: 0.9187\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9954\n",
      "Epoch 00032: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.4317 - val_accuracy: 0.9081\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9953\n",
      "Epoch 00033: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.4312 - val_accuracy: 0.9076\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9944\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.4382 - val_accuracy: 0.9072\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 00035: val_accuracy did not improve from 0.91874\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.3918 - val_accuracy: 0.9187\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9974\n",
      "Epoch 00036: val_accuracy improved from 0.91874 to 0.91963, saving model to ./storage/mnist_test/kfold5/epoch_036_val_0.377_acc_0.920.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.3774 - val_accuracy: 0.9196\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 00037: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.3826 - val_accuracy: 0.9196\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 00038: val_accuracy improved from 0.91963 to 0.92318, saving model to ./storage/mnist_test/kfold5/epoch_038_val_0.390_acc_0.923.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.3904 - val_accuracy: 0.9232\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9953\n",
      "Epoch 00039: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.4065 - val_accuracy: 0.9121\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 00040: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.4140 - val_accuracy: 0.9085\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.4212 - val_accuracy: 0.9107\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 00042: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.3937 - val_accuracy: 0.9218\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9981\n",
      "Epoch 00043: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.4023 - val_accuracy: 0.9174\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.4108 - val_accuracy: 0.9205\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00045: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.3803 - val_accuracy: 0.9223\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00046: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.4205 - val_accuracy: 0.9196\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.4243 - val_accuracy: 0.9170\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 00048: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.4079 - val_accuracy: 0.9205\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00049: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.3921 - val_accuracy: 0.9210\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.4178 - val_accuracy: 0.9205\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 00051: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.4240 - val_accuracy: 0.9152\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00052: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.4246 - val_accuracy: 0.9170\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3990 - val_accuracy: 0.9183\n",
      "Epoch 54/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00054: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3963 - val_accuracy: 0.9232\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00055: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3962 - val_accuracy: 0.9223\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 00056: val_accuracy improved from 0.92318 to 0.92362, saving model to ./storage/mnist_test/kfold5/epoch_056_val_0.388_acc_0.924.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.3881 - val_accuracy: 0.9236\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00057: val_accuracy did not improve from 0.92362\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3883 - val_accuracy: 0.9214\n",
      "Epoch 58/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00058: val_accuracy improved from 0.92362 to 0.92407, saving model to ./storage/mnist_test/kfold5/epoch_058_val_0.385_acc_0.924.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.3850 - val_accuracy: 0.9241\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00059: val_accuracy improved from 0.92407 to 0.92540, saving model to ./storage/mnist_test/kfold5/epoch_059_val_0.384_acc_0.925.h5\n",
      "20276/20276 [==============================] - 19s 912us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3840 - val_accuracy: 0.9254\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00060: val_accuracy improved from 0.92540 to 0.92629, saving model to ./storage/mnist_test/kfold5/epoch_060_val_0.391_acc_0.926.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.3912 - val_accuracy: 0.9263\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00061: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3855 - val_accuracy: 0.9263\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00062: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4016 - val_accuracy: 0.9250\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.3959 - val_accuracy: 0.9258\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00064: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3984 - val_accuracy: 0.9236\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00065: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3857 - val_accuracy: 0.9250\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3929 - val_accuracy: 0.9214\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.7733e-04 - accuracy: 0.9999\n",
      "Epoch 00067: val_accuracy did not improve from 0.92629\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 6.7678e-04 - accuracy: 0.9999 - val_loss: 0.3921 - val_accuracy: 0.9254\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.7267e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy improved from 0.92629 to 0.92673, saving model to ./storage/mnist_test/kfold5/epoch_068_val_0.393_acc_0.927.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 9.7174e-04 - accuracy: 0.9998 - val_loss: 0.3929 - val_accuracy: 0.9267\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.4943e-04 - accuracy: 0.9998\n",
      "Epoch 00069: val_accuracy did not improve from 0.92673\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 7.4872e-04 - accuracy: 0.9998 - val_loss: 0.3942 - val_accuracy: 0.9263\n",
      "Epoch 70/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.0038e-04 - accuracy: 0.9998\n",
      "Epoch 00070: val_accuracy improved from 0.92673 to 0.92762, saving model to ./storage/mnist_test/kfold5/epoch_070_val_0.397_acc_0.928.h5\n",
      "20276/20276 [==============================] - 19s 916us/sample - loss: 6.9875e-04 - accuracy: 0.9998 - val_loss: 0.3973 - val_accuracy: 0.9276\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6365e-04 - accuracy: 0.9999\n",
      "Epoch 00071: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.6311e-04 - accuracy: 0.9999 - val_loss: 0.4025 - val_accuracy: 0.9272\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.5836e-04 - accuracy: 0.9999\n",
      "Epoch 00072: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 5.5794e-04 - accuracy: 0.9999 - val_loss: 0.4104 - val_accuracy: 0.9258\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.7853e-04 - accuracy: 0.9999\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.92762\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 9.4924e-04 - accuracy: 0.9998 - val_loss: 0.4047 - val_accuracy: 0.9272\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6153e-04 - accuracy: 0.9998\n",
      "Epoch 00074: val_accuracy improved from 0.92762 to 0.92895, saving model to ./storage/mnist_test/kfold5/epoch_074_val_0.404_acc_0.929.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 5.6102e-04 - accuracy: 0.9998 - val_loss: 0.4037 - val_accuracy: 0.9290\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.9567e-04 - accuracy: 0.9996\n",
      "Epoch 00075: val_accuracy did not improve from 0.92895\n",
      "20276/20276 [==============================] - 18s 895us/sample - loss: 9.9485e-04 - accuracy: 0.9996 - val_loss: 0.4128 - val_accuracy: 0.9290\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.6730e-04 - accuracy: 0.9997\n",
      "Epoch 00076: val_accuracy improved from 0.92895 to 0.92940, saving model to ./storage/mnist_test/kfold5/epoch_076_val_0.412_acc_0.929.h5\n",
      "20276/20276 [==============================] - 19s 915us/sample - loss: 8.6649e-04 - accuracy: 0.9997 - val_loss: 0.4116 - val_accuracy: 0.9294\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4600e-04 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.5996e-04 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9245\n",
      "Epoch 78/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.0799e-04 - accuracy: 0.9997\n",
      "Epoch 00078: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 9.4504e-04 - accuracy: 0.9997 - val_loss: 0.4166 - val_accuracy: 0.9267\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.8349e-04 - accuracy: 0.9996\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 7.8311e-04 - accuracy: 0.9996 - val_loss: 0.4113 - val_accuracy: 0.9258\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.2623e-04 - accuracy: 0.9999\n",
      "Epoch 00080: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 7.2722e-04 - accuracy: 0.9999 - val_loss: 0.4034 - val_accuracy: 0.9263\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5903e-04 - accuracy: 0.9999\n",
      "Epoch 00081: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 4.5859e-04 - accuracy: 0.9999 - val_loss: 0.4039 - val_accuracy: 0.9245\n",
      "Epoch 82/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.7965e-04 - accuracy: 0.9998\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 5.7879e-04 - accuracy: 0.9998 - val_loss: 0.4025 - val_accuracy: 0.9250\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9842e-04 - accuracy: 1.0000\n",
      "Epoch 00083: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 3.9804e-04 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9276\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0152e-04 - accuracy: 0.9999\n",
      "Epoch 00084: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 5.0199e-04 - accuracy: 0.9999 - val_loss: 0.4033 - val_accuracy: 0.9263\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.7183e-04 - accuracy: 0.9999\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.7137e-04 - accuracy: 0.9999 - val_loss: 0.3979 - val_accuracy: 0.9276\n",
      "Epoch 86/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.8627e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 4.8508e-04 - accuracy: 0.9999 - val_loss: 0.4010 - val_accuracy: 0.9281\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4171e-04 - accuracy: 1.0000\n",
      "Epoch 00087: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.4194e-04 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9276\n",
      "Epoch 88/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.2687e-04 - accuracy: 0.9999\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 5.2583e-04 - accuracy: 0.9999 - val_loss: 0.3980 - val_accuracy: 0.9267\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5798e-04 - accuracy: 1.0000\n",
      "Epoch 00089: val_accuracy improved from 0.92940 to 0.93028, saving model to ./storage/mnist_test/kfold5/epoch_089_val_0.397_acc_0.930.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 4.5753e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9303\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2144e-04 - accuracy: 0.9998\n",
      "Epoch 00090: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 4.2982e-04 - accuracy: 0.9998 - val_loss: 0.3975 - val_accuracy: 0.9303\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.5785e-04 - accuracy: 0.9999\n",
      "Epoch 00091: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 5.5734e-04 - accuracy: 0.9999 - val_loss: 0.3955 - val_accuracy: 0.9298\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00092: val_accuracy improved from 0.93028 to 0.93117, saving model to ./storage/mnist_test/kfold5/epoch_092_val_0.392_acc_0.931.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.3923 - val_accuracy: 0.9312\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3624e-04 - accuracy: 0.9999\n",
      "Epoch 00093: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 4.3581e-04 - accuracy: 0.9999 - val_loss: 0.3976 - val_accuracy: 0.9303\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2730e-04 - accuracy: 1.0000\n",
      "Epoch 00094: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 3.2698e-04 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9298\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7744e-04 - accuracy: 0.9999\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 5.7688e-04 - accuracy: 0.9999 - val_loss: 0.3956 - val_accuracy: 0.9307\n",
      "Epoch 96/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.5291e-04 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 2.5236e-04 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9290\n",
      "Epoch 97/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8631e-04 - accuracy: 0.9999\n",
      "Epoch 00097: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.8594e-04 - accuracy: 0.9999 - val_loss: 0.3975 - val_accuracy: 0.9294\n",
      "Epoch 98/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0915e-04 - accuracy: 0.9999\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 4.0878e-04 - accuracy: 0.9999 - val_loss: 0.3989 - val_accuracy: 0.9307\n",
      "Epoch 99/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0745e-04 - accuracy: 0.9998\n",
      "Epoch 00099: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 4.0704e-04 - accuracy: 0.9998 - val_loss: 0.3974 - val_accuracy: 0.9298\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1542e-04 - accuracy: 1.0000\n",
      "Epoch 00100: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 2.1734e-04 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9290\n",
      "Epoch 101/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4918e-04 - accuracy: 1.0000\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.4889e-04 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9303\n",
      "Epoch 102/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2090e-04 - accuracy: 0.9999\n",
      "Epoch 00102: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 4.2051e-04 - accuracy: 0.9999 - val_loss: 0.4025 - val_accuracy: 0.9290\n",
      "Epoch 103/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.5949e-04 - accuracy: 1.0000\n",
      "Epoch 00103: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 1.5938e-04 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9285\n",
      "Epoch 104/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2784e-04 - accuracy: 1.0000\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 2.2765e-04 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9298\n",
      "Epoch 105/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.4491e-04 - accuracy: 1.0000\n",
      "Epoch 00105: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 2.4481e-04 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9281\n",
      "Epoch 106/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.7536e-04 - accuracy: 1.0000\n",
      "Epoch 00106: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 2.7509e-04 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9298\n",
      "Epoch 107/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8340e-04 - accuracy: 1.0000\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 1.8325e-04 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9303\n",
      "Epoch 108/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6715e-04 - accuracy: 0.9999\n",
      "Epoch 00108: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 3.6685e-04 - accuracy: 0.9999 - val_loss: 0.3961 - val_accuracy: 0.9303\n",
      "Epoch 109/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.9353e-04 - accuracy: 0.9998\n",
      "Epoch 00109: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 9.9256e-04 - accuracy: 0.9998 - val_loss: 0.3996 - val_accuracy: 0.9285\n",
      "Epoch 110/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.2447e-04 - accuracy: 1.0000\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 2.3750e-04 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9294\n",
      "Epoch 111/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8401e-04 - accuracy: 0.9999\n",
      "Epoch 00111: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 3.8434e-04 - accuracy: 0.9999 - val_loss: 0.3952 - val_accuracy: 0.9285\n",
      "Epoch 112/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4520e-04 - accuracy: 0.9999\n",
      "Epoch 00112: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 4.4477e-04 - accuracy: 0.9999 - val_loss: 0.3949 - val_accuracy: 0.9294\n",
      "Epoch 113/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.4099e-04 - accuracy: 1.0000\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 1.4065e-04 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9298\n",
      "Epoch 114/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.5391e-04 - accuracy: 1.0000\n",
      "Epoch 00114: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 2.5366e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9294\n",
      "Epoch 115/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2428e-04 - accuracy: 1.0000\n",
      "Epoch 00115: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 2.2411e-04 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9298\n",
      "Epoch 116/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5850e-04 - accuracy: 0.9999\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 3.5816e-04 - accuracy: 0.9999 - val_loss: 0.3947 - val_accuracy: 0.9307\n",
      "Epoch 117/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.7009e-04 - accuracy: 1.0000\n",
      "Epoch 00117: val_accuracy did not improve from 0.93117\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 1.7007e-04 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9307\n",
      "************ Fold 6 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.8565 - accuracy: 0.3930\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56794, saving model to ./storage/mnist_test/kfold6/epoch_001_val_1.257_acc_0.568.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8541 - accuracy: 0.3936 - val_loss: 1.2566 - val_accuracy: 0.5679\n",
      "Epoch 2/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.0705 - accuracy: 0.6378\n",
      "Epoch 00002: val_accuracy improved from 0.56794 to 0.72336, saving model to ./storage/mnist_test/kfold6/epoch_002_val_0.821_acc_0.723.h5\n",
      "20276/20276 [==============================] - 18s 897us/sample - loss: 1.0702 - accuracy: 0.6377 - val_loss: 0.8209 - val_accuracy: 0.7234\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7670 - accuracy: 0.7432\n",
      "Epoch 00003: val_accuracy improved from 0.72336 to 0.78020, saving model to ./storage/mnist_test/kfold6/epoch_003_val_0.669_acc_0.780.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.7671 - accuracy: 0.7432 - val_loss: 0.6693 - val_accuracy: 0.7802\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5931 - accuracy: 0.8039\n",
      "Epoch 00004: val_accuracy improved from 0.78020 to 0.81483, saving model to ./storage/mnist_test/kfold6/epoch_004_val_0.554_acc_0.815.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.5932 - accuracy: 0.8039 - val_loss: 0.5538 - val_accuracy: 0.8148\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.8467\n",
      "Epoch 00005: val_accuracy improved from 0.81483 to 0.82993, saving model to ./storage/mnist_test/kfold6/epoch_005_val_0.518_acc_0.830.h5\n",
      "20276/20276 [==============================] - 18s 898us/sample - loss: 0.4680 - accuracy: 0.8466 - val_loss: 0.5175 - val_accuracy: 0.8299\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8759\n",
      "Epoch 00006: val_accuracy improved from 0.82993 to 0.85302, saving model to ./storage/mnist_test/kfold6/epoch_006_val_0.473_acc_0.853.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.3734 - accuracy: 0.8759 - val_loss: 0.4730 - val_accuracy: 0.8530\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 0.8996\n",
      "Epoch 00007: val_accuracy improved from 0.85302 to 0.85524, saving model to ./storage/mnist_test/kfold6/epoch_007_val_0.483_acc_0.855.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.3096 - accuracy: 0.8996 - val_loss: 0.4828 - val_accuracy: 0.8552\n",
      "Epoch 8/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.2452 - accuracy: 0.9187\n",
      "Epoch 00008: val_accuracy improved from 0.85524 to 0.86279, saving model to ./storage/mnist_test/kfold6/epoch_008_val_0.444_acc_0.863.h5\n",
      "20276/20276 [==============================] - 18s 900us/sample - loss: 0.2450 - accuracy: 0.9188 - val_loss: 0.4444 - val_accuracy: 0.8628\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9267\n",
      "Epoch 00009: val_accuracy did not improve from 0.86279\n",
      "20276/20276 [==============================] - 18s 872us/sample - loss: 0.2222 - accuracy: 0.9268 - val_loss: 0.4746 - val_accuracy: 0.8552\n",
      "Epoch 10/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9368\n",
      "Epoch 00010: val_accuracy did not improve from 0.86279\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.1897 - accuracy: 0.9366 - val_loss: 0.4797 - val_accuracy: 0.8588\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9472\n",
      "Epoch 00011: val_accuracy improved from 0.86279 to 0.87389, saving model to ./storage/mnist_test/kfold6/epoch_011_val_0.449_acc_0.874.h5\n",
      "20276/20276 [==============================] - 18s 898us/sample - loss: 0.1604 - accuracy: 0.9472 - val_loss: 0.4490 - val_accuracy: 0.8739\n",
      "Epoch 12/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9526\n",
      "Epoch 00012: val_accuracy improved from 0.87389 to 0.87922, saving model to ./storage/mnist_test/kfold6/epoch_012_val_0.448_acc_0.879.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.1450 - accuracy: 0.9525 - val_loss: 0.4481 - val_accuracy: 0.8792\n",
      "Epoch 13/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9566\n",
      "Epoch 00013: val_accuracy improved from 0.87922 to 0.88011, saving model to ./storage/mnist_test/kfold6/epoch_013_val_0.458_acc_0.880.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.1287 - accuracy: 0.9565 - val_loss: 0.4581 - val_accuracy: 0.8801\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9607\n",
      "Epoch 00014: val_accuracy did not improve from 0.88011\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.1188 - accuracy: 0.9607 - val_loss: 0.5011 - val_accuracy: 0.8703\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9674\n",
      "Epoch 00015: val_accuracy did not improve from 0.88011\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0988 - accuracy: 0.9673 - val_loss: 0.5384 - val_accuracy: 0.8686\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9634\n",
      "Epoch 00016: val_accuracy improved from 0.88011 to 0.88277, saving model to ./storage/mnist_test/kfold6/epoch_016_val_0.462_acc_0.883.h5\n",
      "20276/20276 [==============================] - 18s 897us/sample - loss: 0.1102 - accuracy: 0.9633 - val_loss: 0.4620 - val_accuracy: 0.8828\n",
      "Epoch 17/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9695\n",
      "Epoch 00017: val_accuracy did not improve from 0.88277\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0906 - accuracy: 0.9695 - val_loss: 0.4876 - val_accuracy: 0.8761\n",
      "Epoch 18/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9718\n",
      "Epoch 00018: val_accuracy improved from 0.88277 to 0.88899, saving model to ./storage/mnist_test/kfold6/epoch_018_val_0.482_acc_0.889.h5\n",
      "20276/20276 [==============================] - 37s 2ms/sample - loss: 0.0828 - accuracy: 0.9717 - val_loss: 0.4816 - val_accuracy: 0.8890\n",
      "Epoch 19/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9695\n",
      "Epoch 00019: val_accuracy did not improve from 0.88899\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0900 - accuracy: 0.9696 - val_loss: 0.4712 - val_accuracy: 0.8814\n",
      "Epoch 20/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9735\n",
      "Epoch 00020: val_accuracy improved from 0.88899 to 0.89742, saving model to ./storage/mnist_test/kfold6/epoch_020_val_0.425_acc_0.897.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.0789 - accuracy: 0.9735 - val_loss: 0.4248 - val_accuracy: 0.8974\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9771\n",
      "Epoch 00021: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0679 - accuracy: 0.9769 - val_loss: 0.5078 - val_accuracy: 0.8832\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9764\n",
      "Epoch 00022: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0688 - accuracy: 0.9763 - val_loss: 0.5016 - val_accuracy: 0.8903\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9766\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0713 - accuracy: 0.9765 - val_loss: 0.4628 - val_accuracy: 0.8854\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9850\n",
      "Epoch 00024: val_accuracy improved from 0.89742 to 0.89964, saving model to ./storage/mnist_test/kfold6/epoch_024_val_0.416_acc_0.900.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.0463 - accuracy: 0.9851 - val_loss: 0.4156 - val_accuracy: 0.8996\n",
      "Epoch 25/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9877\n",
      "Epoch 00025: val_accuracy did not improve from 0.89964\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.4627 - val_accuracy: 0.8961\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9896\n",
      "Epoch 00026: val_accuracy did not improve from 0.89964\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.5250 - val_accuracy: 0.8872\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9845\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.89964\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.4755 - val_accuracy: 0.8970\n",
      "Epoch 28/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9904\n",
      "Epoch 00028: val_accuracy improved from 0.89964 to 0.90542, saving model to ./storage/mnist_test/kfold6/epoch_028_val_0.433_acc_0.905.h5\n",
      "20276/20276 [==============================] - 18s 896us/sample - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.4327 - val_accuracy: 0.9054\n",
      "Epoch 29/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 00029: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.4327 - val_accuracy: 0.9041\n",
      "Epoch 30/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9919\n",
      "Epoch 00030: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.5339 - val_accuracy: 0.8828\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9882\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.4643 - val_accuracy: 0.9023\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9952\n",
      "Epoch 00032: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.4658 - val_accuracy: 0.9019\n",
      "Epoch 33/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9934\n",
      "Epoch 00033: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.4966 - val_accuracy: 0.9054\n",
      "Epoch 34/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9949\n",
      "Epoch 00034: val_accuracy improved from 0.90542 to 0.92052, saving model to ./storage/mnist_test/kfold6/epoch_034_val_0.427_acc_0.921.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.4266 - val_accuracy: 0.9205\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9949\n",
      "Epoch 00035: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.4613 - val_accuracy: 0.9085\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9926\n",
      "Epoch 00036: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.4559 - val_accuracy: 0.9112\n",
      "Epoch 37/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.4639 - val_accuracy: 0.9072\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9965\n",
      "Epoch 00038: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.4495 - val_accuracy: 0.9099\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00039: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.4468 - val_accuracy: 0.9165\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.4522 - val_accuracy: 0.9112\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00041: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.4325 - val_accuracy: 0.9161\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 00042: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.4398 - val_accuracy: 0.9170\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.4820 - val_accuracy: 0.9085\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00044: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.4466 - val_accuracy: 0.9201\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00045: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.4813 - val_accuracy: 0.9161\n",
      "Epoch 46/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.5037 - val_accuracy: 0.9147\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00047: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.4847 - val_accuracy: 0.9170\n",
      "Epoch 48/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 00048: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.4819 - val_accuracy: 0.9201\n",
      "Epoch 49/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4688 - val_accuracy: 0.9205\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 00050: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.4703 - val_accuracy: 0.9205\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00051: val_accuracy improved from 0.92052 to 0.92451, saving model to ./storage/mnist_test/kfold6/epoch_051_val_0.455_acc_0.925.h5\n",
      "20276/20276 [==============================] - 18s 898us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.4545 - val_accuracy: 0.9245\n",
      "Epoch 52/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00052: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.4560 - val_accuracy: 0.9218\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00053: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.4644 - val_accuracy: 0.9241\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4476 - val_accuracy: 0.9241\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 00055: val_accuracy improved from 0.92451 to 0.92718, saving model to ./storage/mnist_test/kfold6/epoch_055_val_0.451_acc_0.927.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.4511 - val_accuracy: 0.9272\n",
      "Epoch 56/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00056: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4849 - val_accuracy: 0.9214\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00057: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4505 - val_accuracy: 0.9250\n",
      "Epoch 58/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.92718\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4555 - val_accuracy: 0.9245\n",
      "Epoch 59/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 00059: val_accuracy improved from 0.92718 to 0.92940, saving model to ./storage/mnist_test/kfold6/epoch_059_val_0.453_acc_0.929.h5\n",
      "20276/20276 [==============================] - 18s 901us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.4527 - val_accuracy: 0.9294\n",
      "Epoch 60/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00060: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.4678 - val_accuracy: 0.9290\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00061: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4524 - val_accuracy: 0.9241\n",
      "Epoch 62/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4669 - val_accuracy: 0.9276\n",
      "Epoch 63/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 00063: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.4486 - val_accuracy: 0.9285\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00064: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4671 - val_accuracy: 0.9236\n",
      "Epoch 65/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.3526e-04 - accuracy: 0.9997\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 9.3297e-04 - accuracy: 0.9997 - val_loss: 0.4568 - val_accuracy: 0.9236\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.1042e-04 - accuracy: 0.9998\n",
      "Epoch 00066: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 9.0960e-04 - accuracy: 0.9998 - val_loss: 0.4542 - val_accuracy: 0.9272\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3470e-04 - accuracy: 0.9999\n",
      "Epoch 00067: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 6.3409e-04 - accuracy: 0.9999 - val_loss: 0.4675 - val_accuracy: 0.9267\n",
      "Epoch 68/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4572 - val_accuracy: 0.9285\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.9728e-04 - accuracy: 0.9999\n",
      "Epoch 00069: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 7.9683e-04 - accuracy: 0.9999 - val_loss: 0.4493 - val_accuracy: 0.9263\n",
      "Epoch 70/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 9.7749e-04 - accuracy: 0.9998\n",
      "Epoch 00070: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 9.7502e-04 - accuracy: 0.9998 - val_loss: 0.4554 - val_accuracy: 0.9267\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.1672e-04 - accuracy: 0.9998\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 8.1592e-04 - accuracy: 0.9998 - val_loss: 0.4486 - val_accuracy: 0.9276\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.1438e-04 - accuracy: 0.9999\n",
      "Epoch 00072: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 873us/sample - loss: 7.1369e-04 - accuracy: 0.9999 - val_loss: 0.4429 - val_accuracy: 0.9281\n",
      "Epoch 73/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00073: val_accuracy did not improve from 0.92940\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4519 - val_accuracy: 0.9285\n",
      "Epoch 74/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 00074: val_accuracy improved from 0.92940 to 0.93206, saving model to ./storage/mnist_test/kfold6/epoch_074_val_0.438_acc_0.932.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.4381 - val_accuracy: 0.9321\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.93206\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4377 - val_accuracy: 0.9294\n",
      "Epoch 76/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.0115e-04 - accuracy: 0.9999\n",
      "Epoch 00076: val_accuracy did not improve from 0.93206\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 4.0083e-04 - accuracy: 0.9999 - val_loss: 0.4293 - val_accuracy: 0.9316\n",
      "Epoch 77/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.3294e-04 - accuracy: 0.9998\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.93206\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 7.3113e-04 - accuracy: 0.9998 - val_loss: 0.4313 - val_accuracy: 0.9312\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.3010e-04 - accuracy: 0.9999\n",
      "Epoch 00078: val_accuracy did not improve from 0.93206\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 5.2959e-04 - accuracy: 0.9999 - val_loss: 0.4423 - val_accuracy: 0.9316\n",
      "Epoch 79/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.2809e-04 - accuracy: 0.9999\n",
      "Epoch 00079: val_accuracy improved from 0.93206 to 0.93250, saving model to ./storage/mnist_test/kfold6/epoch_079_val_0.438_acc_0.933.h5\n",
      "20276/20276 [==============================] - 18s 900us/sample - loss: 6.2670e-04 - accuracy: 0.9999 - val_loss: 0.4376 - val_accuracy: 0.9325\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5224e-04 - accuracy: 1.0000\n",
      "Epoch 00080: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 3.5273e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9307\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4896e-04 - accuracy: 0.9999\n",
      "Epoch 00081: val_accuracy did not improve from 0.93250\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 4.5054e-04 - accuracy: 0.9999 - val_loss: 0.4407 - val_accuracy: 0.9316\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.9534e-04 - accuracy: 1.0000\n",
      "Epoch 00082: val_accuracy improved from 0.93250 to 0.93295, saving model to ./storage/mnist_test/kfold6/epoch_082_val_0.439_acc_0.933.h5\n",
      "20276/20276 [==============================] - 18s 906us/sample - loss: 2.9505e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9329\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3267e-04 - accuracy: 0.9999\n",
      "Epoch 00083: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 4.3227e-04 - accuracy: 0.9999 - val_loss: 0.4420 - val_accuracy: 0.9281\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.9538e-04 - accuracy: 0.9998\n",
      "Epoch 00084: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 6.9473e-04 - accuracy: 0.9998 - val_loss: 0.4472 - val_accuracy: 0.9276\n",
      "Epoch 85/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.6568e-04 - accuracy: 0.9999\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 3.6559e-04 - accuracy: 0.9999 - val_loss: 0.4489 - val_accuracy: 0.9303\n",
      "Epoch 86/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.5758e-04 - accuracy: 1.0000\n",
      "Epoch 00086: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 2.5698e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9307\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3273e-04 - accuracy: 0.9999\n",
      "Epoch 00087: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 6.3214e-04 - accuracy: 0.9999 - val_loss: 0.4470 - val_accuracy: 0.9312\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8176e-04 - accuracy: 1.0000\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 3.8155e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9312\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3430e-04 - accuracy: 0.9999\n",
      "Epoch 00089: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 4.3388e-04 - accuracy: 0.9999 - val_loss: 0.4427 - val_accuracy: 0.9307\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.2130e-04 - accuracy: 0.9998\n",
      "Epoch 00090: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 6.2234e-04 - accuracy: 0.9998 - val_loss: 0.4410 - val_accuracy: 0.9307\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.5779e-04 - accuracy: 0.9999\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 2.5755e-04 - accuracy: 0.9999 - val_loss: 0.4411 - val_accuracy: 0.9312\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.9022e-04 - accuracy: 1.0000\n",
      "Epoch 00092: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 2.8995e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9307\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5649e-04 - accuracy: 0.9999\n",
      "Epoch 00093: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 4.6009e-04 - accuracy: 0.9999 - val_loss: 0.4420 - val_accuracy: 0.9312\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3985e-04 - accuracy: 0.9998\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 6.3923e-04 - accuracy: 0.9998 - val_loss: 0.4457 - val_accuracy: 0.9290\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8119e-04 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 874us/sample - loss: 2.8114e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9298\n",
      "Epoch 96/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 2.3686e-04 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 2.3650e-04 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9298\n",
      "Epoch 97/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4639e-04 - accuracy: 0.9999\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 4.4605e-04 - accuracy: 0.9999 - val_loss: 0.4419 - val_accuracy: 0.9307\n",
      "Epoch 98/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.0441e-04 - accuracy: 0.9998\n",
      "Epoch 00098: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 6.0387e-04 - accuracy: 0.9998 - val_loss: 0.4369 - val_accuracy: 0.9303\n",
      "Epoch 99/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.6293e-04 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 1.6304e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9307\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.9341e-04 - accuracy: 1.0000\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 875us/sample - loss: 1.9324e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9281\n",
      "Epoch 101/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.6539e-04 - accuracy: 1.0000\n",
      "Epoch 00101: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 2.6535e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9303\n",
      "Epoch 102/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.2556e-04 - accuracy: 1.0000\n",
      "Epoch 00102: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 2.2550e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9294\n",
      "Epoch 103/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.1608e-04 - accuracy: 1.0000\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 2.1622e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9298\n",
      "Epoch 104/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 1.8411e-04 - accuracy: 1.0000\n",
      "Epoch 00104: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 876us/sample - loss: 1.8372e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9298\n",
      "Epoch 105/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.3230e-04 - accuracy: 0.9999\n",
      "Epoch 00105: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 3.3148e-04 - accuracy: 0.9999 - val_loss: 0.4437 - val_accuracy: 0.9307\n",
      "Epoch 106/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.2360e-04 - accuracy: 0.9999\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 3.5558e-04 - accuracy: 0.9999 - val_loss: 0.4361 - val_accuracy: 0.9312\n",
      "Epoch 107/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.9363e-05 - accuracy: 1.0000\n",
      "Epoch 00107: val_accuracy did not improve from 0.93295\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 9.1750e-05 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9307\n",
      "************ Fold 7 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8467 - accuracy: 0.3942\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56705, saving model to ./storage/mnist_test/kfold7/epoch_001_val_1.290_acc_0.567.h5\n",
      "20276/20276 [==============================] - 26s 1ms/sample - loss: 1.8462 - accuracy: 0.3943 - val_loss: 1.2898 - val_accuracy: 0.5671\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0422 - accuracy: 0.6485\n",
      "Epoch 00002: val_accuracy improved from 0.56705 to 0.72957, saving model to ./storage/mnist_test/kfold7/epoch_002_val_0.801_acc_0.730.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 1.0427 - accuracy: 0.6484 - val_loss: 0.8014 - val_accuracy: 0.7296\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7395 - accuracy: 0.7530\n",
      "Epoch 00003: val_accuracy improved from 0.72957 to 0.78464, saving model to ./storage/mnist_test/kfold7/epoch_003_val_0.637_acc_0.785.h5\n",
      "20276/20276 [==============================] - 19s 920us/sample - loss: 0.7396 - accuracy: 0.7530 - val_loss: 0.6373 - val_accuracy: 0.7846\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.5808 - accuracy: 0.8091\n",
      "Epoch 00004: val_accuracy improved from 0.78464 to 0.82194, saving model to ./storage/mnist_test/kfold7/epoch_004_val_0.525_acc_0.822.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.5806 - accuracy: 0.8091 - val_loss: 0.5251 - val_accuracy: 0.8219\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4591 - accuracy: 0.8464\n",
      "Epoch 00005: val_accuracy improved from 0.82194 to 0.82638, saving model to ./storage/mnist_test/kfold7/epoch_005_val_0.525_acc_0.826.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.4598 - accuracy: 0.8463 - val_loss: 0.5253 - val_accuracy: 0.8264\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8753\n",
      "Epoch 00006: val_accuracy improved from 0.82638 to 0.84503, saving model to ./storage/mnist_test/kfold7/epoch_006_val_0.455_acc_0.845.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.3872 - accuracy: 0.8753 - val_loss: 0.4548 - val_accuracy: 0.8450\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3083 - accuracy: 0.8982\n",
      "Epoch 00007: val_accuracy improved from 0.84503 to 0.86545, saving model to ./storage/mnist_test/kfold7/epoch_007_val_0.426_acc_0.865.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.3082 - accuracy: 0.8983 - val_loss: 0.4256 - val_accuracy: 0.8655\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.9162\n",
      "Epoch 00008: val_accuracy did not improve from 0.86545\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.2524 - accuracy: 0.9162 - val_loss: 0.4360 - val_accuracy: 0.8610\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9285\n",
      "Epoch 00009: val_accuracy improved from 0.86545 to 0.86901, saving model to ./storage/mnist_test/kfold7/epoch_009_val_0.427_acc_0.869.h5\n",
      "20276/20276 [==============================] - 19s 917us/sample - loss: 0.2169 - accuracy: 0.9285 - val_loss: 0.4272 - val_accuracy: 0.8690\n",
      "Epoch 10/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 0.9415\n",
      "Epoch 00010: val_accuracy did not improve from 0.86901\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.1785 - accuracy: 0.9415 - val_loss: 0.4421 - val_accuracy: 0.8650\n",
      "Epoch 11/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9424\n",
      "Epoch 00011: val_accuracy improved from 0.86901 to 0.87567, saving model to ./storage/mnist_test/kfold7/epoch_011_val_0.406_acc_0.876.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.1753 - accuracy: 0.9424 - val_loss: 0.4058 - val_accuracy: 0.8757\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9497\n",
      "Epoch 00012: val_accuracy improved from 0.87567 to 0.88899, saving model to ./storage/mnist_test/kfold7/epoch_012_val_0.402_acc_0.889.h5\n",
      "20276/20276 [==============================] - 19s 919us/sample - loss: 0.1528 - accuracy: 0.9497 - val_loss: 0.4020 - val_accuracy: 0.8890\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9590\n",
      "Epoch 00013: val_accuracy did not improve from 0.88899\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.1286 - accuracy: 0.9590 - val_loss: 0.4222 - val_accuracy: 0.8845\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9645\n",
      "Epoch 00014: val_accuracy did not improve from 0.88899\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.1098 - accuracy: 0.9645 - val_loss: 0.4339 - val_accuracy: 0.8881\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9583\n",
      "Epoch 00015: val_accuracy improved from 0.88899 to 0.89210, saving model to ./storage/mnist_test/kfold7/epoch_015_val_0.408_acc_0.892.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.1233 - accuracy: 0.9582 - val_loss: 0.4082 - val_accuracy: 0.8921\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9696\n",
      "Epoch 00016: val_accuracy did not improve from 0.89210\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0965 - accuracy: 0.9695 - val_loss: 0.4554 - val_accuracy: 0.8832\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9700\n",
      "Epoch 00017: val_accuracy improved from 0.89210 to 0.89254, saving model to ./storage/mnist_test/kfold7/epoch_017_val_0.443_acc_0.893.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0895 - accuracy: 0.9700 - val_loss: 0.4433 - val_accuracy: 0.8925\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9666\n",
      "Epoch 00018: val_accuracy improved from 0.89254 to 0.89343, saving model to ./storage/mnist_test/kfold7/epoch_018_val_0.401_acc_0.893.h5\n",
      "20276/20276 [==============================] - 19s 915us/sample - loss: 0.0996 - accuracy: 0.9666 - val_loss: 0.4010 - val_accuracy: 0.8934\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9758\n",
      "Epoch 00019: val_accuracy did not improve from 0.89343\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0741 - accuracy: 0.9757 - val_loss: 0.4290 - val_accuracy: 0.8908\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9719\n",
      "Epoch 00020: val_accuracy did not improve from 0.89343\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0859 - accuracy: 0.9719 - val_loss: 0.3988 - val_accuracy: 0.8934\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9780\n",
      "Epoch 00021: val_accuracy improved from 0.89343 to 0.90053, saving model to ./storage/mnist_test/kfold7/epoch_021_val_0.402_acc_0.901.h5\n",
      "20276/20276 [==============================] - 19s 920us/sample - loss: 0.0660 - accuracy: 0.9780 - val_loss: 0.4021 - val_accuracy: 0.9005\n",
      "Epoch 22/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 0.9743\n",
      "Epoch 00022: val_accuracy did not improve from 0.90053\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.4267 - val_accuracy: 0.8894\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9766\n",
      "Epoch 00023: val_accuracy did not improve from 0.90053\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0728 - accuracy: 0.9765 - val_loss: 0.4335 - val_accuracy: 0.8899\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9776\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.90053\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0690 - accuracy: 0.9775 - val_loss: 0.4127 - val_accuracy: 0.8943\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9854\n",
      "Epoch 00025: val_accuracy improved from 0.90053 to 0.90275, saving model to ./storage/mnist_test/kfold7/epoch_025_val_0.436_acc_0.903.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0437 - accuracy: 0.9855 - val_loss: 0.4356 - val_accuracy: 0.9028\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9877\n",
      "Epoch 00026: val_accuracy improved from 0.90275 to 0.90320, saving model to ./storage/mnist_test/kfold7/epoch_026_val_0.395_acc_0.903.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.3950 - val_accuracy: 0.9032\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 00027: val_accuracy did not improve from 0.90320\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.4179 - val_accuracy: 0.8992\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9854\n",
      "Epoch 00028: val_accuracy did not improve from 0.90320\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0449 - accuracy: 0.9854 - val_loss: 0.3991 - val_accuracy: 0.9023\n",
      "Epoch 29/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9882\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90320\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.4658 - val_accuracy: 0.8899\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9903\n",
      "Epoch 00030: val_accuracy improved from 0.90320 to 0.90897, saving model to ./storage/mnist_test/kfold7/epoch_030_val_0.415_acc_0.909.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.4145 - val_accuracy: 0.9090\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 00031: val_accuracy improved from 0.90897 to 0.91474, saving model to ./storage/mnist_test/kfold7/epoch_031_val_0.378_acc_0.915.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.3781 - val_accuracy: 0.9147\n",
      "Epoch 32/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 00032: val_accuracy did not improve from 0.91474\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.4403 - val_accuracy: 0.9023\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9911\n",
      "Epoch 00033: val_accuracy did not improve from 0.91474\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.4453 - val_accuracy: 0.9014\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9929\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.91474\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.4258 - val_accuracy: 0.9107\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9947\n",
      "Epoch 00035: val_accuracy improved from 0.91474 to 0.91652, saving model to ./storage/mnist_test/kfold7/epoch_035_val_0.408_acc_0.917.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.4082 - val_accuracy: 0.9165\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9942\n",
      "Epoch 00036: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.3828 - val_accuracy: 0.9130\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9949\n",
      "Epoch 00037: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.4461 - val_accuracy: 0.9107\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9950\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.4405 - val_accuracy: 0.9081\n",
      "Epoch 39/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 00039: val_accuracy improved from 0.91652 to 0.91918, saving model to ./storage/mnist_test/kfold7/epoch_039_val_0.385_acc_0.919.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.3852 - val_accuracy: 0.9192\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 00040: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4113 - val_accuracy: 0.9116\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9968\n",
      "Epoch 00041: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4208 - val_accuracy: 0.9170\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9973\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.91918\n",
      "20276/20276 [==============================] - 18s 897us/sample - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.3948 - val_accuracy: 0.9192\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9972\n",
      "Epoch 00043: val_accuracy improved from 0.91918 to 0.92185, saving model to ./storage/mnist_test/kfold7/epoch_043_val_0.389_acc_0.922.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.3892 - val_accuracy: 0.9218\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 00044: val_accuracy improved from 0.92185 to 0.93028, saving model to ./storage/mnist_test/kfold7/epoch_044_val_0.336_acc_0.930.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.3362 - val_accuracy: 0.9303\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 00045: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.3728 - val_accuracy: 0.9227\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 00046: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.3919 - val_accuracy: 0.9214\n",
      "Epoch 47/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.4073 - val_accuracy: 0.9223\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00048: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.3780 - val_accuracy: 0.9210\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00049: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.3818 - val_accuracy: 0.9232\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.3956 - val_accuracy: 0.9214\n",
      "Epoch 51/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00051: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.3798 - val_accuracy: 0.9285\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00052: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3805 - val_accuracy: 0.9294\n",
      "Epoch 53/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.93028\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.4007 - val_accuracy: 0.9241\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00054: val_accuracy improved from 0.93028 to 0.93250, saving model to ./storage/mnist_test/kfold7/epoch_054_val_0.359_acc_0.933.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.3585 - val_accuracy: 0.9325\n",
      "Epoch 55/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00055: val_accuracy improved from 0.93250 to 0.93339, saving model to ./storage/mnist_test/kfold7/epoch_055_val_0.365_acc_0.933.h5\n",
      "20276/20276 [==============================] - 19s 918us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3650 - val_accuracy: 0.9334\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00056: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.3702 - val_accuracy: 0.9321\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00057: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.3679 - val_accuracy: 0.9298\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.3832 - val_accuracy: 0.9267\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 00059: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.3591 - val_accuracy: 0.9321\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00060: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.3633 - val_accuracy: 0.9321\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.3689 - val_accuracy: 0.9303\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.4175e-04 - accuracy: 0.9997\n",
      "Epoch 00062: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 9.4152e-04 - accuracy: 0.9997 - val_loss: 0.3609 - val_accuracy: 0.9334\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00063: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3689 - val_accuracy: 0.9312\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3660 - val_accuracy: 0.9334\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 00065: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.3584 - val_accuracy: 0.9298\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.2070e-04 - accuracy: 0.9998\n",
      "Epoch 00066: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 8.2260e-04 - accuracy: 0.9998 - val_loss: 0.3634 - val_accuracy: 0.9303\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3632 - val_accuracy: 0.9303\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.1879e-04 - accuracy: 0.9997\n",
      "Epoch 00068: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 9.1799e-04 - accuracy: 0.9997 - val_loss: 0.3617 - val_accuracy: 0.9325\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.0673e-04 - accuracy: 0.9998\n",
      "Epoch 00069: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 9.0584e-04 - accuracy: 0.9998 - val_loss: 0.3610 - val_accuracy: 0.9307\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7557e-04 - accuracy: 0.9999\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 5.7508e-04 - accuracy: 0.9999 - val_loss: 0.3623 - val_accuracy: 0.9325\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.8271e-04 - accuracy: 0.9997\n",
      "Epoch 00071: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 9.8175e-04 - accuracy: 0.9997 - val_loss: 0.3737 - val_accuracy: 0.9329\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.0150e-04 - accuracy: 0.9998\n",
      "Epoch 00072: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 8.0374e-04 - accuracy: 0.9998 - val_loss: 0.3691 - val_accuracy: 0.9312\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.6301e-04 - accuracy: 0.9997\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 9.8044e-04 - accuracy: 0.9997 - val_loss: 0.3725 - val_accuracy: 0.9307\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7824e-04 - accuracy: 0.9999\n",
      "Epoch 00074: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 5.7783e-04 - accuracy: 0.9999 - val_loss: 0.3707 - val_accuracy: 0.9298\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.4193e-04 - accuracy: 1.0000\n",
      "Epoch 00075: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 5.4155e-04 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9316\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.8592e-04 - accuracy: 0.9999\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 5.8574e-04 - accuracy: 0.9999 - val_loss: 0.3634 - val_accuracy: 0.9307\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5411e-04 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 4.5375e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9303\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1496e-04 - accuracy: 1.0000\n",
      "Epoch 00078: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 4.1903e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9321\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.3172e-04 - accuracy: 1.0000\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 4.3363e-04 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9316\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.8864e-04 - accuracy: 0.9997\n",
      "Epoch 00080: val_accuracy did not improve from 0.93339\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 9.8780e-04 - accuracy: 0.9997 - val_loss: 0.3700 - val_accuracy: 0.9316\n",
      "************ Fold 8 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8167 - accuracy: 0.4082\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57460, saving model to ./storage/mnist_test/kfold8/epoch_001_val_1.249_acc_0.575.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8163 - accuracy: 0.4083 - val_loss: 1.2492 - val_accuracy: 0.5746\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0521 - accuracy: 0.6449\n",
      "Epoch 00002: val_accuracy improved from 0.57460 to 0.68295, saving model to ./storage/mnist_test/kfold8/epoch_002_val_0.926_acc_0.683.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 1.0523 - accuracy: 0.6449 - val_loss: 0.9263 - val_accuracy: 0.6829\n",
      "Epoch 3/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.7644 - accuracy: 0.7436\n",
      "Epoch 00003: val_accuracy improved from 0.68295 to 0.76510, saving model to ./storage/mnist_test/kfold8/epoch_003_val_0.706_acc_0.765.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.7639 - accuracy: 0.7438 - val_loss: 0.7061 - val_accuracy: 0.7651\n",
      "Epoch 4/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.8052\n",
      "Epoch 00004: val_accuracy improved from 0.76510 to 0.80595, saving model to ./storage/mnist_test/kfold8/epoch_004_val_0.603_acc_0.806.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.5880 - accuracy: 0.8054 - val_loss: 0.6034 - val_accuracy: 0.8060\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4690 - accuracy: 0.8433\n",
      "Epoch 00005: val_accuracy improved from 0.80595 to 0.82504, saving model to ./storage/mnist_test/kfold8/epoch_005_val_0.532_acc_0.825.h5\n",
      "20276/20276 [==============================] - 18s 905us/sample - loss: 0.4694 - accuracy: 0.8432 - val_loss: 0.5319 - val_accuracy: 0.8250\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8714\n",
      "Epoch 00006: val_accuracy improved from 0.82504 to 0.84547, saving model to ./storage/mnist_test/kfold8/epoch_006_val_0.505_acc_0.845.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.3898 - accuracy: 0.8713 - val_loss: 0.5055 - val_accuracy: 0.8455\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.9008\n",
      "Epoch 00007: val_accuracy improved from 0.84547 to 0.86412, saving model to ./storage/mnist_test/kfold8/epoch_007_val_0.449_acc_0.864.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.2980 - accuracy: 0.9007 - val_loss: 0.4489 - val_accuracy: 0.8641\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2682 - accuracy: 0.9103\n",
      "Epoch 00008: val_accuracy did not improve from 0.86412\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.2687 - accuracy: 0.9102 - val_loss: 0.4813 - val_accuracy: 0.8521\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9269\n",
      "Epoch 00009: val_accuracy improved from 0.86412 to 0.86679, saving model to ./storage/mnist_test/kfold8/epoch_009_val_0.450_acc_0.867.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.2200 - accuracy: 0.9269 - val_loss: 0.4495 - val_accuracy: 0.8668\n",
      "Epoch 10/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9377\n",
      "Epoch 00010: val_accuracy did not improve from 0.86679\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.1902 - accuracy: 0.9377 - val_loss: 0.5071 - val_accuracy: 0.8566\n",
      "Epoch 11/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9422\n",
      "Epoch 00011: val_accuracy improved from 0.86679 to 0.87300, saving model to ./storage/mnist_test/kfold8/epoch_011_val_0.477_acc_0.873.h5\n",
      "20276/20276 [==============================] - 18s 900us/sample - loss: 0.1750 - accuracy: 0.9423 - val_loss: 0.4775 - val_accuracy: 0.8730\n",
      "Epoch 12/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9531\n",
      "Epoch 00012: val_accuracy improved from 0.87300 to 0.87611, saving model to ./storage/mnist_test/kfold8/epoch_012_val_0.448_acc_0.876.h5\n",
      "20276/20276 [==============================] - 18s 902us/sample - loss: 0.1415 - accuracy: 0.9531 - val_loss: 0.4482 - val_accuracy: 0.8761\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1323 - accuracy: 0.9559\n",
      "Epoch 00013: val_accuracy improved from 0.87611 to 0.88055, saving model to ./storage/mnist_test/kfold8/epoch_013_val_0.472_acc_0.881.h5\n",
      "20276/20276 [==============================] - 18s 903us/sample - loss: 0.1324 - accuracy: 0.9558 - val_loss: 0.4719 - val_accuracy: 0.8806\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 0.9586\n",
      "Epoch 00014: val_accuracy did not improve from 0.88055\n",
      "20276/20276 [==============================] - 18s 878us/sample - loss: 0.1266 - accuracy: 0.9586 - val_loss: 0.4813 - val_accuracy: 0.8792\n",
      "Epoch 15/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9665\n",
      "Epoch 00015: val_accuracy did not improve from 0.88055\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.1022 - accuracy: 0.9665 - val_loss: 0.4965 - val_accuracy: 0.8788\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9649\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.88055\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.1068 - accuracy: 0.9649 - val_loss: 0.4920 - val_accuracy: 0.8806\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9768\n",
      "Epoch 00017: val_accuracy improved from 0.88055 to 0.89165, saving model to ./storage/mnist_test/kfold8/epoch_017_val_0.422_acc_0.892.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0718 - accuracy: 0.9767 - val_loss: 0.4218 - val_accuracy: 0.8917\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9825\n",
      "Epoch 00018: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0525 - accuracy: 0.9824 - val_loss: 0.4748 - val_accuracy: 0.8912\n",
      "Epoch 19/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9796\n",
      "Epoch 00019: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.5150 - val_accuracy: 0.8841\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9797\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.89165\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0638 - accuracy: 0.9797 - val_loss: 0.4866 - val_accuracy: 0.8841\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9860\n",
      "Epoch 00021: val_accuracy improved from 0.89165 to 0.89698, saving model to ./storage/mnist_test/kfold8/epoch_021_val_0.454_acc_0.897.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0407 - accuracy: 0.9860 - val_loss: 0.4537 - val_accuracy: 0.8970\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9882\n",
      "Epoch 00022: val_accuracy did not improve from 0.89698\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.5019 - val_accuracy: 0.8921\n",
      "Epoch 23/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9879\n",
      "Epoch 00023: val_accuracy improved from 0.89698 to 0.90320, saving model to ./storage/mnist_test/kfold8/epoch_023_val_0.492_acc_0.903.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.4917 - val_accuracy: 0.9032\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9888\n",
      "Epoch 00024: val_accuracy did not improve from 0.90320\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.4983 - val_accuracy: 0.8921\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9883\n",
      "Epoch 00025: val_accuracy improved from 0.90320 to 0.90542, saving model to ./storage/mnist_test/kfold8/epoch_025_val_0.484_acc_0.905.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.4835 - val_accuracy: 0.9054\n",
      "Epoch 26/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9894\n",
      "Epoch 00026: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.4965 - val_accuracy: 0.9001\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9883\n",
      "Epoch 00027: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0357 - accuracy: 0.9883 - val_loss: 0.4866 - val_accuracy: 0.9014\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9886\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90542\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0349 - accuracy: 0.9886 - val_loss: 0.4647 - val_accuracy: 0.9001\n",
      "Epoch 29/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 00029: val_accuracy improved from 0.90542 to 0.90897, saving model to ./storage/mnist_test/kfold8/epoch_029_val_0.441_acc_0.909.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.4414 - val_accuracy: 0.9090\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9915\n",
      "Epoch 00030: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.4678 - val_accuracy: 0.9054\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9919\n",
      "Epoch 00031: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0224 - accuracy: 0.9919 - val_loss: 0.4671 - val_accuracy: 0.9081\n",
      "Epoch 32/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9941\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.4921 - val_accuracy: 0.9050\n",
      "Epoch 33/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9940\n",
      "Epoch 00033: val_accuracy did not improve from 0.90897\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.4772 - val_accuracy: 0.9081\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9967\n",
      "Epoch 00034: val_accuracy improved from 0.90897 to 0.91341, saving model to ./storage/mnist_test/kfold8/epoch_034_val_0.478_acc_0.913.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.4783 - val_accuracy: 0.9134\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 00035: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.4887 - val_accuracy: 0.9121\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9950\n",
      "Epoch 00036: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.5256 - val_accuracy: 0.9041\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9958\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.4908 - val_accuracy: 0.9081\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9964\n",
      "Epoch 00038: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.5195 - val_accuracy: 0.9045\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9960\n",
      "Epoch 00039: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.4969 - val_accuracy: 0.9063\n",
      "Epoch 40/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.5024 - val_accuracy: 0.9023\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 00041: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.5243 - val_accuracy: 0.9054\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9974\n",
      "Epoch 00042: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.4924 - val_accuracy: 0.9103\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.5015 - val_accuracy: 0.9116\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00044: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.5004 - val_accuracy: 0.9121\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 00045: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5237 - val_accuracy: 0.9130\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5259 - val_accuracy: 0.9094\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 00047: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.5280 - val_accuracy: 0.9094\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 00048: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.5130 - val_accuracy: 0.9116\n",
      "Epoch 49/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.5154 - val_accuracy: 0.9103\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n",
      "Epoch 00050: val_accuracy did not improve from 0.91341\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.4993 - val_accuracy: 0.9134\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00051: val_accuracy improved from 0.91341 to 0.91385, saving model to ./storage/mnist_test/kfold8/epoch_051_val_0.521_acc_0.914.h5\n",
      "20276/20276 [==============================] - 19s 918us/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.5207 - val_accuracy: 0.9139\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00052: val_accuracy improved from 0.91385 to 0.91696, saving model to ./storage/mnist_test/kfold8/epoch_052_val_0.522_acc_0.917.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.5222 - val_accuracy: 0.9170\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 00053: val_accuracy improved from 0.91696 to 0.91963, saving model to ./storage/mnist_test/kfold8/epoch_053_val_0.514_acc_0.920.h5\n",
      "20276/20276 [==============================] - 18s 904us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.5139 - val_accuracy: 0.9196\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00054: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.5104 - val_accuracy: 0.9156\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00055: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.5327 - val_accuracy: 0.9161\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.5195 - val_accuracy: 0.9187\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00057: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5103 - val_accuracy: 0.9143\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00058: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.5165 - val_accuracy: 0.9143\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.5079 - val_accuracy: 0.9170\n",
      "Epoch 60/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00060: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5015 - val_accuracy: 0.9165\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00061: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.5079 - val_accuracy: 0.9183\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 877us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.5062 - val_accuracy: 0.9161\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00063: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.5061 - val_accuracy: 0.9143\n",
      "Epoch 64/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 8.7193e-04 - accuracy: 0.9998\n",
      "Epoch 00064: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 9.6416e-04 - accuracy: 0.9998 - val_loss: 0.4999 - val_accuracy: 0.9174\n",
      "Epoch 65/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.5058 - val_accuracy: 0.9156\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.6402e-04 - accuracy: 0.9998\n",
      "Epoch 00066: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 8.6318e-04 - accuracy: 0.9998 - val_loss: 0.4993 - val_accuracy: 0.9174\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.1881e-04 - accuracy: 0.9999\n",
      "Epoch 00067: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 6.1844e-04 - accuracy: 0.9999 - val_loss: 0.5081 - val_accuracy: 0.9165\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.6645e-04 - accuracy: 0.9999\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 6.6582e-04 - accuracy: 0.9999 - val_loss: 0.5186 - val_accuracy: 0.9165\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.8707e-04 - accuracy: 0.9999\n",
      "Epoch 00069: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 5.8684e-04 - accuracy: 0.9999 - val_loss: 0.5144 - val_accuracy: 0.9170\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.2707e-04 - accuracy: 0.9999\n",
      "Epoch 00070: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.3833e-04 - accuracy: 0.9999 - val_loss: 0.5139 - val_accuracy: 0.9161\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.6359e-04 - accuracy: 0.9998\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 8.6275e-04 - accuracy: 0.9998 - val_loss: 0.5040 - val_accuracy: 0.9161\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.7344e-04 - accuracy: 1.0000\n",
      "Epoch 00072: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 4.7299e-04 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.9170\n",
      "Epoch 73/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.6194e-04 - accuracy: 0.9998\n",
      "Epoch 00073: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 7.6150e-04 - accuracy: 0.9998 - val_loss: 0.5049 - val_accuracy: 0.9179\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.5823e-04 - accuracy: 0.9998\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.91963\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 6.5759e-04 - accuracy: 0.9998 - val_loss: 0.5008 - val_accuracy: 0.9187\n",
      "Epoch 75/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.0478e-04 - accuracy: 0.9998\n",
      "Epoch 00075: val_accuracy improved from 0.91963 to 0.92052, saving model to ./storage/mnist_test/kfold8/epoch_075_val_0.500_acc_0.921.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 6.0375e-04 - accuracy: 0.9998 - val_loss: 0.5003 - val_accuracy: 0.9205\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.3775e-04 - accuracy: 0.9999\n",
      "Epoch 00076: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 5.3727e-04 - accuracy: 0.9999 - val_loss: 0.5030 - val_accuracy: 0.9192\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.2371e-04 - accuracy: 0.9999\n",
      "Epoch 00077: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 5.2322e-04 - accuracy: 0.9999 - val_loss: 0.5107 - val_accuracy: 0.9174\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.2993e-04 - accuracy: 0.9998\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 7.2926e-04 - accuracy: 0.9998 - val_loss: 0.5082 - val_accuracy: 0.9201\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1687e-04 - accuracy: 0.9999\n",
      "Epoch 00079: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 4.4618e-04 - accuracy: 0.9999 - val_loss: 0.5120 - val_accuracy: 0.9205\n",
      "Epoch 80/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.5430e-04 - accuracy: 0.9999\n",
      "Epoch 00080: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 4.5359e-04 - accuracy: 0.9999 - val_loss: 0.5124 - val_accuracy: 0.9192\n",
      "Epoch 81/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2710e-04 - accuracy: 0.9999\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.2700e-04 - accuracy: 0.9999 - val_loss: 0.5125 - val_accuracy: 0.9192\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6533e-04 - accuracy: 0.9998\n",
      "Epoch 00082: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 5.6478e-04 - accuracy: 0.9998 - val_loss: 0.5132 - val_accuracy: 0.9183\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.4717e-04 - accuracy: 0.9999\n",
      "Epoch 00083: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 4.5566e-04 - accuracy: 0.9999 - val_loss: 0.5177 - val_accuracy: 0.9196\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0103e-04 - accuracy: 0.9999\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.0054e-04 - accuracy: 0.9999 - val_loss: 0.5152 - val_accuracy: 0.9201\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.7404e-04 - accuracy: 1.0000\n",
      "Epoch 00085: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 4.7358e-04 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.9201\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4750e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 3.4731e-04 - accuracy: 0.9999 - val_loss: 0.5126 - val_accuracy: 0.9205\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.1681e-04 - accuracy: 0.9998\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.92052\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 5.1630e-04 - accuracy: 0.9998 - val_loss: 0.5140 - val_accuracy: 0.9201\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.2918e-04 - accuracy: 0.9999\n",
      "Epoch 00088: val_accuracy improved from 0.92052 to 0.92274, saving model to ./storage/mnist_test/kfold8/epoch_088_val_0.516_acc_0.923.h5\n",
      "20276/20276 [==============================] - 19s 915us/sample - loss: 4.2915e-04 - accuracy: 0.9999 - val_loss: 0.5160 - val_accuracy: 0.9227\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5702e-04 - accuracy: 0.9999\n",
      "Epoch 00089: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 4.5658e-04 - accuracy: 0.9999 - val_loss: 0.5149 - val_accuracy: 0.9210\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.0591e-04 - accuracy: 0.9998\n",
      "Epoch 00090: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 7.0522e-04 - accuracy: 0.9998 - val_loss: 0.5193 - val_accuracy: 0.9205\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0537e-04 - accuracy: 1.0000\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.0488e-04 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.9201\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.6382e-04 - accuracy: 0.9999\n",
      "Epoch 00092: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 5.6381e-04 - accuracy: 0.9999 - val_loss: 0.5189 - val_accuracy: 0.9205\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8681e-04 - accuracy: 0.9999\n",
      "Epoch 00093: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 3.8984e-04 - accuracy: 0.9999 - val_loss: 0.5159 - val_accuracy: 0.9201\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4381e-04 - accuracy: 0.9999\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 3.4393e-04 - accuracy: 0.9999 - val_loss: 0.5154 - val_accuracy: 0.9205\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0683e-04 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.0643e-04 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9201\n",
      "Epoch 96/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.0947e-04 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 2.0931e-04 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.9214\n",
      "Epoch 97/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 3.8486e-04 - accuracy: 1.0000\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 881us/sample - loss: 3.8404e-04 - accuracy: 1.0000 - val_loss: 0.5160 - val_accuracy: 0.9210\n",
      "Epoch 98/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6810e-04 - accuracy: 1.0000\n",
      "Epoch 00098: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 3.6778e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9205\n",
      "Epoch 99/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 4.1716e-04 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 4.1701e-04 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9201\n",
      "Epoch 100/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.0490e-04 - accuracy: 1.0000\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 4.0574e-04 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9201\n",
      "Epoch 101/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.7062e-04 - accuracy: 0.9999\n",
      "Epoch 00101: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 3.7029e-04 - accuracy: 0.9999 - val_loss: 0.5179 - val_accuracy: 0.9192\n",
      "Epoch 102/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6898e-04 - accuracy: 0.9999\n",
      "Epoch 00102: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 3.6892e-04 - accuracy: 0.9999 - val_loss: 0.5167 - val_accuracy: 0.9210\n",
      "Epoch 103/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5760e-04 - accuracy: 0.9999\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 879us/sample - loss: 4.5828e-04 - accuracy: 0.9999 - val_loss: 0.5182 - val_accuracy: 0.9201\n",
      "Epoch 104/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.5381e-04 - accuracy: 0.9999\n",
      "Epoch 00104: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 3.5347e-04 - accuracy: 0.9999 - val_loss: 0.5183 - val_accuracy: 0.9201\n",
      "Epoch 105/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.8690e-04 - accuracy: 0.9999\n",
      "Epoch 00105: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 3.8655e-04 - accuracy: 0.9999 - val_loss: 0.5177 - val_accuracy: 0.9192\n",
      "Epoch 106/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.4839e-04 - accuracy: 1.0000\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 3.0223149224184457e-06.\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 3.4805e-04 - accuracy: 1.0000 - val_loss: 0.5176 - val_accuracy: 0.9192\n",
      "Epoch 107/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1307e-04 - accuracy: 0.9999\n",
      "Epoch 00107: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 4.1269e-04 - accuracy: 0.9999 - val_loss: 0.5166 - val_accuracy: 0.9205\n",
      "Epoch 108/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.7211e-04 - accuracy: 0.9998\n",
      "Epoch 00108: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 5.7155e-04 - accuracy: 0.9998 - val_loss: 0.5152 - val_accuracy: 0.9214\n",
      "Epoch 109/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.1543e-04 - accuracy: 1.0000\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.4178520106943328e-06.\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 3.1516e-04 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.9201\n",
      "Epoch 110/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 6.9609e-04 - accuracy: 0.9998\n",
      "Epoch 00110: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 6.9439e-04 - accuracy: 0.9998 - val_loss: 0.5139 - val_accuracy: 0.9201\n",
      "Epoch 111/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8049e-04 - accuracy: 1.0000\n",
      "Epoch 00111: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 2.8028e-04 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9201\n",
      "Epoch 112/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0909e-04 - accuracy: 1.0000\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.9342816813150422e-06.\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 3.0886e-04 - accuracy: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.9192\n",
      "Epoch 113/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0331e-04 - accuracy: 0.9999\n",
      "Epoch 00113: val_accuracy did not improve from 0.92274\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 3.0322e-04 - accuracy: 0.9999 - val_loss: 0.5130 - val_accuracy: 0.9201\n",
      "************ Fold 9 training ************\n",
      "Train on 20276 samples, validate on 2252 samples\n",
      "Epoch 1/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8182 - accuracy: 0.4093\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57726, saving model to ./storage/mnist_test/kfold9/epoch_001_val_1.265_acc_0.577.h5\n",
      "20276/20276 [==============================] - 25s 1ms/sample - loss: 1.8185 - accuracy: 0.4092 - val_loss: 1.2650 - val_accuracy: 0.5773\n",
      "Epoch 2/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.0627 - accuracy: 0.6412\n",
      "Epoch 00002: val_accuracy improved from 0.57726 to 0.70604, saving model to ./storage/mnist_test/kfold9/epoch_002_val_0.841_acc_0.706.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 1.0624 - accuracy: 0.6414 - val_loss: 0.8410 - val_accuracy: 0.7060\n",
      "Epoch 3/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.7568 - accuracy: 0.7464\n",
      "Epoch 00003: val_accuracy improved from 0.70604 to 0.76909, saving model to ./storage/mnist_test/kfold9/epoch_003_val_0.700_acc_0.769.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.7574 - accuracy: 0.7461 - val_loss: 0.7005 - val_accuracy: 0.7691\n",
      "Epoch 4/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.8001\n",
      "Epoch 00004: val_accuracy improved from 0.76909 to 0.78153, saving model to ./storage/mnist_test/kfold9/epoch_004_val_0.662_acc_0.782.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 0.5998 - accuracy: 0.8001 - val_loss: 0.6620 - val_accuracy: 0.7815\n",
      "Epoch 5/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.4727 - accuracy: 0.8453\n",
      "Epoch 00005: val_accuracy improved from 0.78153 to 0.81661, saving model to ./storage/mnist_test/kfold9/epoch_005_val_0.553_acc_0.817.h5\n",
      "20276/20276 [==============================] - 19s 914us/sample - loss: 0.4725 - accuracy: 0.8453 - val_loss: 0.5529 - val_accuracy: 0.8166\n",
      "Epoch 6/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8687\n",
      "Epoch 00006: val_accuracy improved from 0.81661 to 0.85657, saving model to ./storage/mnist_test/kfold9/epoch_006_val_0.471_acc_0.857.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.3911 - accuracy: 0.8687 - val_loss: 0.4711 - val_accuracy: 0.8566\n",
      "Epoch 7/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8999\n",
      "Epoch 00007: val_accuracy did not improve from 0.85657\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.3086 - accuracy: 0.8996 - val_loss: 0.4901 - val_accuracy: 0.8552\n",
      "Epoch 8/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9131\n",
      "Epoch 00008: val_accuracy improved from 0.85657 to 0.85835, saving model to ./storage/mnist_test/kfold9/epoch_008_val_0.483_acc_0.858.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.2657 - accuracy: 0.9130 - val_loss: 0.4825 - val_accuracy: 0.8583\n",
      "Epoch 9/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9272\n",
      "Epoch 00009: val_accuracy improved from 0.85835 to 0.86279, saving model to ./storage/mnist_test/kfold9/epoch_009_val_0.483_acc_0.863.h5\n",
      "20276/20276 [==============================] - 19s 922us/sample - loss: 0.2205 - accuracy: 0.9271 - val_loss: 0.4835 - val_accuracy: 0.8628\n",
      "Epoch 10/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1811 - accuracy: 0.9418\n",
      "Epoch 00010: val_accuracy improved from 0.86279 to 0.87522, saving model to ./storage/mnist_test/kfold9/epoch_010_val_0.460_acc_0.875.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.1810 - accuracy: 0.9419 - val_loss: 0.4603 - val_accuracy: 0.8752\n",
      "Epoch 11/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9459\n",
      "Epoch 00011: val_accuracy did not improve from 0.87522\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.1647 - accuracy: 0.9458 - val_loss: 0.4743 - val_accuracy: 0.8708\n",
      "Epoch 12/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9484\n",
      "Epoch 00012: val_accuracy improved from 0.87522 to 0.88188, saving model to ./storage/mnist_test/kfold9/epoch_012_val_0.413_acc_0.882.h5\n",
      "20276/20276 [==============================] - 19s 921us/sample - loss: 0.1527 - accuracy: 0.9484 - val_loss: 0.4130 - val_accuracy: 0.8819\n",
      "Epoch 13/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9578\n",
      "Epoch 00013: val_accuracy did not improve from 0.88188\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.1239 - accuracy: 0.9578 - val_loss: 0.4626 - val_accuracy: 0.8761\n",
      "Epoch 14/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9579\n",
      "Epoch 00014: val_accuracy did not improve from 0.88188\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 0.1283 - accuracy: 0.9578 - val_loss: 0.4628 - val_accuracy: 0.8739\n",
      "Epoch 15/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9679\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.88188\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0980 - accuracy: 0.9679 - val_loss: 0.5149 - val_accuracy: 0.8766\n",
      "Epoch 16/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9725\n",
      "Epoch 00016: val_accuracy improved from 0.88188 to 0.89742, saving model to ./storage/mnist_test/kfold9/epoch_016_val_0.421_acc_0.897.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.0825 - accuracy: 0.9725 - val_loss: 0.4209 - val_accuracy: 0.8974\n",
      "Epoch 17/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 0.9791\n",
      "Epoch 00017: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0645 - accuracy: 0.9790 - val_loss: 0.4497 - val_accuracy: 0.8917\n",
      "Epoch 18/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9786\n",
      "Epoch 00018: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0629 - accuracy: 0.9786 - val_loss: 0.5002 - val_accuracy: 0.8810\n",
      "Epoch 19/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9756\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.89742\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0724 - accuracy: 0.9756 - val_loss: 0.4657 - val_accuracy: 0.8841\n",
      "Epoch 20/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9839\n",
      "Epoch 00020: val_accuracy improved from 0.89742 to 0.90586, saving model to ./storage/mnist_test/kfold9/epoch_020_val_0.416_acc_0.906.h5\n",
      "20276/20276 [==============================] - 18s 910us/sample - loss: 0.0477 - accuracy: 0.9838 - val_loss: 0.4160 - val_accuracy: 0.9059\n",
      "Epoch 21/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9879\n",
      "Epoch 00021: val_accuracy did not improve from 0.90586\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.4447 - val_accuracy: 0.8921\n",
      "Epoch 22/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9880\n",
      "Epoch 00022: val_accuracy did not improve from 0.90586\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.4785 - val_accuracy: 0.8956\n",
      "Epoch 23/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9885\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90586\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0372 - accuracy: 0.9886 - val_loss: 0.4841 - val_accuracy: 0.8912\n",
      "Epoch 24/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9923\n",
      "Epoch 00024: val_accuracy did not improve from 0.90586\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.4598 - val_accuracy: 0.8983\n",
      "Epoch 25/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9907\n",
      "Epoch 00025: val_accuracy improved from 0.90586 to 0.90986, saving model to ./storage/mnist_test/kfold9/epoch_025_val_0.426_acc_0.910.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.4265 - val_accuracy: 0.9099\n",
      "Epoch 26/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9909\n",
      "Epoch 00026: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.4861 - val_accuracy: 0.8965\n",
      "Epoch 27/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9923\n",
      "Epoch 00027: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.4336 - val_accuracy: 0.9028\n",
      "Epoch 28/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.4452 - val_accuracy: 0.9036\n",
      "Epoch 29/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9949\n",
      "Epoch 00029: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.4433 - val_accuracy: 0.9045\n",
      "Epoch 30/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9960\n",
      "Epoch 00030: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.4579 - val_accuracy: 0.9045\n",
      "Epoch 31/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.99 - ETA: 0s - loss: 0.0173 - accuracy: 0.9940\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.4560 - val_accuracy: 0.9036\n",
      "Epoch 32/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9951\n",
      "Epoch 00032: val_accuracy did not improve from 0.90986\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.4254 - val_accuracy: 0.9099\n",
      "Epoch 33/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9967\n",
      "Epoch 00033: val_accuracy improved from 0.90986 to 0.91297, saving model to ./storage/mnist_test/kfold9/epoch_033_val_0.433_acc_0.913.h5\n",
      "20276/20276 [==============================] - 19s 913us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.4332 - val_accuracy: 0.9130\n",
      "Epoch 34/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 00034: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.4480 - val_accuracy: 0.9076\n",
      "Epoch 35/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 00035: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.4755 - val_accuracy: 0.9072\n",
      "Epoch 36/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9968\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.91297\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.4551 - val_accuracy: 0.9103\n",
      "Epoch 37/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 00037: val_accuracy improved from 0.91297 to 0.91385, saving model to ./storage/mnist_test/kfold9/epoch_037_val_0.461_acc_0.914.h5\n",
      "20276/20276 [==============================] - 18s 907us/sample - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.4606 - val_accuracy: 0.9139\n",
      "Epoch 38/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00038: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.4502 - val_accuracy: 0.9125\n",
      "Epoch 39/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00039: val_accuracy did not improve from 0.91385\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.4447 - val_accuracy: 0.9121\n",
      "Epoch 40/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 00040: val_accuracy improved from 0.91385 to 0.91563, saving model to ./storage/mnist_test/kfold9/epoch_040_val_0.435_acc_0.916.h5\n",
      "20276/20276 [==============================] - 18s 909us/sample - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.4351 - val_accuracy: 0.9156\n",
      "Epoch 41/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00041: val_accuracy did not improve from 0.91563\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.4569 - val_accuracy: 0.9090\n",
      "Epoch 42/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00042: val_accuracy did not improve from 0.91563\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.4371 - val_accuracy: 0.9139\n",
      "Epoch 43/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.91563\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.4554 - val_accuracy: 0.9094\n",
      "Epoch 44/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 00044: val_accuracy did not improve from 0.91563\n",
      "20276/20276 [==============================] - 18s 895us/sample - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.4391 - val_accuracy: 0.9121\n",
      "Epoch 45/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00045: val_accuracy improved from 0.91563 to 0.91652, saving model to ./storage/mnist_test/kfold9/epoch_045_val_0.451_acc_0.917.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.4512 - val_accuracy: 0.9165\n",
      "Epoch 46/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 00046: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.4501 - val_accuracy: 0.9130\n",
      "Epoch 47/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00047: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.4487 - val_accuracy: 0.9130\n",
      "Epoch 48/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.4539 - val_accuracy: 0.9125\n",
      "Epoch 49/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00049: val_accuracy did not improve from 0.91652\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.4400 - val_accuracy: 0.9143\n",
      "Epoch 50/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00050: val_accuracy improved from 0.91652 to 0.91741, saving model to ./storage/mnist_test/kfold9/epoch_050_val_0.431_acc_0.917.h5\n",
      "20276/20276 [==============================] - 19s 923us/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.4312 - val_accuracy: 0.9174\n",
      "Epoch 51/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 00051: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.4538 - val_accuracy: 0.9152\n",
      "Epoch 52/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 00052: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 899us/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.4689 - val_accuracy: 0.9139\n",
      "Epoch 53/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.91741\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.4708 - val_accuracy: 0.9174\n",
      "Epoch 54/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 00054: val_accuracy improved from 0.91741 to 0.91963, saving model to ./storage/mnist_test/kfold9/epoch_054_val_0.436_acc_0.920.h5\n",
      "20276/20276 [==============================] - 18s 912us/sample - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.4364 - val_accuracy: 0.9196\n",
      "Epoch 55/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00055: val_accuracy improved from 0.91963 to 0.92096, saving model to ./storage/mnist_test/kfold9/epoch_055_val_0.438_acc_0.921.h5\n",
      "20276/20276 [==============================] - 18s 911us/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4385 - val_accuracy: 0.9210\n",
      "Epoch 56/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00056: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4529 - val_accuracy: 0.9179\n",
      "Epoch 57/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 00057: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.4580 - val_accuracy: 0.9125\n",
      "Epoch 58/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 885us/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.4449 - val_accuracy: 0.9147\n",
      "Epoch 59/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00059: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.4331 - val_accuracy: 0.9156\n",
      "Epoch 60/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00060: val_accuracy did not improve from 0.92096\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4272 - val_accuracy: 0.9205\n",
      "Epoch 61/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00061: val_accuracy improved from 0.92096 to 0.92318, saving model to ./storage/mnist_test/kfold9/epoch_061_val_0.436_acc_0.923.h5\n",
      "20276/20276 [==============================] - 18s 908us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4357 - val_accuracy: 0.9232\n",
      "Epoch 62/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00062: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.4384 - val_accuracy: 0.9187\n",
      "Epoch 63/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00063: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 882us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4532 - val_accuracy: 0.9210\n",
      "Epoch 64/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 8.3583e-04 - accuracy: 0.9999\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 8.3512e-04 - accuracy: 0.9999 - val_loss: 0.4495 - val_accuracy: 0.9214\n",
      "Epoch 65/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.3329e-04 - accuracy: 0.9999\n",
      "Epoch 00065: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 9.3256e-04 - accuracy: 0.9999 - val_loss: 0.4571 - val_accuracy: 0.9152\n",
      "Epoch 66/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.5364e-04 - accuracy: 0.9999\n",
      "Epoch 00066: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 7.5382e-04 - accuracy: 0.9999 - val_loss: 0.4577 - val_accuracy: 0.9187\n",
      "Epoch 67/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.4678 - val_accuracy: 0.9170\n",
      "Epoch 68/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.2132e-04 - accuracy: 0.9998\n",
      "Epoch 00068: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 9.2050e-04 - accuracy: 0.9998 - val_loss: 0.4556 - val_accuracy: 0.9174\n",
      "Epoch 69/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.2146e-04 - accuracy: 0.9998\n",
      "Epoch 00069: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 9.2066e-04 - accuracy: 0.9998 - val_loss: 0.4542 - val_accuracy: 0.9152\n",
      "Epoch 70/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.3409e-04 - accuracy: 0.9999\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 7.3716e-04 - accuracy: 0.9999 - val_loss: 0.4501 - val_accuracy: 0.9179\n",
      "Epoch 71/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.2937e-04 - accuracy: 0.9999\n",
      "Epoch 00071: val_accuracy did not improve from 0.92318\n",
      "20276/20276 [==============================] - 18s 888us/sample - loss: 6.2911e-04 - accuracy: 0.9999 - val_loss: 0.4483 - val_accuracy: 0.9227\n",
      "Epoch 72/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.3310e-04 - accuracy: 0.9997\n",
      "Epoch 00072: val_accuracy improved from 0.92318 to 0.92451, saving model to ./storage/mnist_test/kfold9/epoch_072_val_0.449_acc_0.925.h5\n",
      "20276/20276 [==============================] - 19s 918us/sample - loss: 7.3256e-04 - accuracy: 0.9997 - val_loss: 0.4488 - val_accuracy: 0.9245\n",
      "Epoch 73/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 7.1932e-04 - accuracy: 0.9998\n",
      "Epoch 00073: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 7.1773e-04 - accuracy: 0.9998 - val_loss: 0.4505 - val_accuracy: 0.9196\n",
      "Epoch 74/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 9.9006e-04 - accuracy: 0.9996\n",
      "Epoch 00074: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 892us/sample - loss: 9.8925e-04 - accuracy: 0.9996 - val_loss: 0.4523 - val_accuracy: 0.9201\n",
      "Epoch 75/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.0105e-04 - accuracy: 0.9999\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 6.0046e-04 - accuracy: 0.9999 - val_loss: 0.4543 - val_accuracy: 0.9210\n",
      "Epoch 76/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.8350e-04 - accuracy: 1.0000\n",
      "Epoch 00076: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.8304e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9196\n",
      "Epoch 77/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.8606e-04 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 4.8561e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9214\n",
      "Epoch 78/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3489e-04 - accuracy: 0.9999\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 6.3427e-04 - accuracy: 0.9999 - val_loss: 0.4439 - val_accuracy: 0.9214\n",
      "Epoch 79/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6652e-04 - accuracy: 1.0000\n",
      "Epoch 00079: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 893us/sample - loss: 3.6618e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9227\n",
      "Epoch 80/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.3266e-04 - accuracy: 0.9998\n",
      "Epoch 00080: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 895us/sample - loss: 7.3776e-04 - accuracy: 0.9998 - val_loss: 0.4424 - val_accuracy: 0.9214\n",
      "Epoch 81/300\n",
      "20224/20276 [============================>.] - ETA: 0s - loss: 5.1315e-04 - accuracy: 1.0000\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 889us/sample - loss: 5.1228e-04 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9210\n",
      "Epoch 82/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.1353e-04 - accuracy: 0.9999\n",
      "Epoch 00082: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 894us/sample - loss: 4.1339e-04 - accuracy: 0.9999 - val_loss: 0.4393 - val_accuracy: 0.9201\n",
      "Epoch 83/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.6070e-04 - accuracy: 0.9998\n",
      "Epoch 00083: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 880us/sample - loss: 7.5999e-04 - accuracy: 0.9998 - val_loss: 0.4394 - val_accuracy: 0.9218\n",
      "Epoch 84/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0880e-04 - accuracy: 0.9999\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 5.0843e-04 - accuracy: 0.9999 - val_loss: 0.4408 - val_accuracy: 0.9192\n",
      "Epoch 85/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.8968e-04 - accuracy: 0.9997\n",
      "Epoch 00085: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 6.8912e-04 - accuracy: 0.9997 - val_loss: 0.4406 - val_accuracy: 0.9192\n",
      "Epoch 86/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.5968e-04 - accuracy: 0.9999\n",
      "Epoch 00086: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 883us/sample - loss: 4.5929e-04 - accuracy: 0.9999 - val_loss: 0.4466 - val_accuracy: 0.9196\n",
      "Epoch 87/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 5.0581e-04 - accuracy: 0.9999\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 5.0533e-04 - accuracy: 0.9999 - val_loss: 0.4400 - val_accuracy: 0.9196\n",
      "Epoch 88/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.9530e-04 - accuracy: 0.9999\n",
      "Epoch 00088: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 7.9452e-04 - accuracy: 0.9999 - val_loss: 0.4446 - val_accuracy: 0.9179\n",
      "Epoch 89/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 4.7113e-04 - accuracy: 0.9999\n",
      "Epoch 00089: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 891us/sample - loss: 4.7091e-04 - accuracy: 0.9999 - val_loss: 0.4468 - val_accuracy: 0.9187\n",
      "Epoch 90/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 7.5240e-04 - accuracy: 0.9998\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 7.5168e-04 - accuracy: 0.9998 - val_loss: 0.4420 - val_accuracy: 0.9174\n",
      "Epoch 91/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 6.3235e-04 - accuracy: 0.9998\n",
      "Epoch 00091: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 887us/sample - loss: 6.3175e-04 - accuracy: 0.9998 - val_loss: 0.4405 - val_accuracy: 0.9201\n",
      "Epoch 92/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.9706e-04 - accuracy: 1.0000\n",
      "Epoch 00092: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 2.9677e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9196\n",
      "Epoch 93/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.9611e-04 - accuracy: 0.9999\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 884us/sample - loss: 3.9575e-04 - accuracy: 0.9999 - val_loss: 0.4356 - val_accuracy: 0.9218\n",
      "Epoch 94/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.6955e-04 - accuracy: 0.9999\n",
      "Epoch 00094: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 894us/sample - loss: 3.7374e-04 - accuracy: 0.9999 - val_loss: 0.4388 - val_accuracy: 0.9218\n",
      "Epoch 95/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 2.8017e-04 - accuracy: 0.9999\n",
      "Epoch 00095: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 890us/sample - loss: 2.7994e-04 - accuracy: 0.9999 - val_loss: 0.4391 - val_accuracy: 0.9205\n",
      "Epoch 96/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 3.0578e-04 - accuracy: 0.9999\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 3.0550e-04 - accuracy: 0.9999 - val_loss: 0.4350 - val_accuracy: 0.9201\n",
      "Epoch 97/300\n",
      "20256/20276 [============================>.] - ETA: 0s - loss: 1.8818e-04 - accuracy: 1.0000\n",
      "Epoch 00097: val_accuracy did not improve from 0.92451\n",
      "20276/20276 [==============================] - 18s 886us/sample - loss: 1.8842e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9205\n",
      "************ Fold 10 training ************\n",
      "Train on 20268 samples, validate on 2260 samples\n",
      "Epoch 1/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 1.8128 - accuracy: 0.4058\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58451, saving model to ./storage/mnist_test/kfold10/epoch_001_val_1.212_acc_0.585.h5\n",
      "20268/20268 [==============================] - 25s 1ms/sample - loss: 1.8128 - accuracy: 0.4058 - val_loss: 1.2121 - val_accuracy: 0.5845\n",
      "Epoch 2/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 1.0687 - accuracy: 0.6385\n",
      "Epoch 00002: val_accuracy improved from 0.58451 to 0.72301, saving model to ./storage/mnist_test/kfold10/epoch_002_val_0.815_acc_0.723.h5\n",
      "20268/20268 [==============================] - 18s 905us/sample - loss: 1.0685 - accuracy: 0.6386 - val_loss: 0.8148 - val_accuracy: 0.7230\n",
      "Epoch 3/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.7580 - accuracy: 0.7495\n",
      "Epoch 00003: val_accuracy improved from 0.72301 to 0.77257, saving model to ./storage/mnist_test/kfold10/epoch_003_val_0.672_acc_0.773.h5\n",
      "20268/20268 [==============================] - 19s 921us/sample - loss: 0.7582 - accuracy: 0.7494 - val_loss: 0.6717 - val_accuracy: 0.7726\n",
      "Epoch 4/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.8090\n",
      "Epoch 00004: val_accuracy improved from 0.77257 to 0.79735, saving model to ./storage/mnist_test/kfold10/epoch_004_val_0.636_acc_0.797.h5\n",
      "20268/20268 [==============================] - 19s 914us/sample - loss: 0.5757 - accuracy: 0.8090 - val_loss: 0.6362 - val_accuracy: 0.7973\n",
      "Epoch 5/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.4611 - accuracy: 0.8451\n",
      "Epoch 00005: val_accuracy improved from 0.79735 to 0.83407, saving model to ./storage/mnist_test/kfold10/epoch_005_val_0.522_acc_0.834.h5\n",
      "20268/20268 [==============================] - 18s 905us/sample - loss: 0.4610 - accuracy: 0.8452 - val_loss: 0.5217 - val_accuracy: 0.8341\n",
      "Epoch 6/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.3736 - accuracy: 0.8763\n",
      "Epoch 00006: val_accuracy did not improve from 0.83407\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.3735 - accuracy: 0.8763 - val_loss: 0.5363 - val_accuracy: 0.8310\n",
      "Epoch 7/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.3122 - accuracy: 0.8962\n",
      "Epoch 00007: val_accuracy improved from 0.83407 to 0.85000, saving model to ./storage/mnist_test/kfold10/epoch_007_val_0.485_acc_0.850.h5\n",
      "20268/20268 [==============================] - 18s 905us/sample - loss: 0.3120 - accuracy: 0.8963 - val_loss: 0.4851 - val_accuracy: 0.8500\n",
      "Epoch 8/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.2524 - accuracy: 0.9165\n",
      "Epoch 00008: val_accuracy improved from 0.85000 to 0.85531, saving model to ./storage/mnist_test/kfold10/epoch_008_val_0.488_acc_0.855.h5\n",
      "20268/20268 [==============================] - 18s 906us/sample - loss: 0.2523 - accuracy: 0.9165 - val_loss: 0.4883 - val_accuracy: 0.8553\n",
      "Epoch 9/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9269\n",
      "Epoch 00009: val_accuracy improved from 0.85531 to 0.85841, saving model to ./storage/mnist_test/kfold10/epoch_009_val_0.506_acc_0.858.h5\n",
      "20268/20268 [==============================] - 19s 919us/sample - loss: 0.2191 - accuracy: 0.9269 - val_loss: 0.5057 - val_accuracy: 0.8584\n",
      "Epoch 10/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9407\n",
      "Epoch 00010: val_accuracy improved from 0.85841 to 0.86947, saving model to ./storage/mnist_test/kfold10/epoch_010_val_0.451_acc_0.869.h5\n",
      "20268/20268 [==============================] - 18s 906us/sample - loss: 0.1781 - accuracy: 0.9406 - val_loss: 0.4511 - val_accuracy: 0.8695\n",
      "Epoch 11/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9442\n",
      "Epoch 00011: val_accuracy improved from 0.86947 to 0.87257, saving model to ./storage/mnist_test/kfold10/epoch_011_val_0.462_acc_0.873.h5\n",
      "20268/20268 [==============================] - 18s 906us/sample - loss: 0.1677 - accuracy: 0.9442 - val_loss: 0.4625 - val_accuracy: 0.8726\n",
      "Epoch 12/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9516\n",
      "Epoch 00012: val_accuracy improved from 0.87257 to 0.87699, saving model to ./storage/mnist_test/kfold10/epoch_012_val_0.455_acc_0.877.h5\n",
      "20268/20268 [==============================] - 18s 901us/sample - loss: 0.1483 - accuracy: 0.9515 - val_loss: 0.4551 - val_accuracy: 0.8770\n",
      "Epoch 13/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1275 - accuracy: 0.9585\n",
      "Epoch 00013: val_accuracy did not improve from 0.87699\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.1275 - accuracy: 0.9585 - val_loss: 0.4920 - val_accuracy: 0.8637\n",
      "Epoch 14/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9605\n",
      "Epoch 00014: val_accuracy did not improve from 0.87699\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.1198 - accuracy: 0.9605 - val_loss: 0.4874 - val_accuracy: 0.8726\n",
      "Epoch 15/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.1060 - accuracy: 0.9643\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.87699\n",
      "20268/20268 [==============================] - 18s 887us/sample - loss: 0.1063 - accuracy: 0.9642 - val_loss: 0.4877 - val_accuracy: 0.8721\n",
      "Epoch 16/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9741\n",
      "Epoch 00016: val_accuracy improved from 0.87699 to 0.88363, saving model to ./storage/mnist_test/kfold10/epoch_016_val_0.456_acc_0.884.h5\n",
      "20268/20268 [==============================] - 18s 913us/sample - loss: 0.0766 - accuracy: 0.9740 - val_loss: 0.4558 - val_accuracy: 0.8836\n",
      "Epoch 17/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9762\n",
      "Epoch 00017: val_accuracy did not improve from 0.88363\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0720 - accuracy: 0.9760 - val_loss: 0.4970 - val_accuracy: 0.8770\n",
      "Epoch 18/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9782\n",
      "Epoch 00018: val_accuracy improved from 0.88363 to 0.88496, saving model to ./storage/mnist_test/kfold10/epoch_018_val_0.500_acc_0.885.h5\n",
      "20268/20268 [==============================] - 19s 913us/sample - loss: 0.0686 - accuracy: 0.9782 - val_loss: 0.4996 - val_accuracy: 0.8850\n",
      "Epoch 19/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9799\n",
      "Epoch 00019: val_accuracy did not improve from 0.88496\n",
      "20268/20268 [==============================] - 18s 881us/sample - loss: 0.0630 - accuracy: 0.9799 - val_loss: 0.5084 - val_accuracy: 0.8792\n",
      "Epoch 20/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.9811\n",
      "Epoch 00020: val_accuracy did not improve from 0.88496\n",
      "20268/20268 [==============================] - 18s 880us/sample - loss: 0.0560 - accuracy: 0.9812 - val_loss: 0.4726 - val_accuracy: 0.8801\n",
      "Epoch 21/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9804\n",
      "Epoch 00021: val_accuracy improved from 0.88496 to 0.88938, saving model to ./storage/mnist_test/kfold10/epoch_021_val_0.461_acc_0.889.h5\n",
      "20268/20268 [==============================] - 19s 913us/sample - loss: 0.0603 - accuracy: 0.9804 - val_loss: 0.4608 - val_accuracy: 0.8894\n",
      "Epoch 22/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9811\n",
      "Epoch 00022: val_accuracy did not improve from 0.88938\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.4679 - val_accuracy: 0.8850\n",
      "Epoch 23/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9816\n",
      "Epoch 00023: val_accuracy improved from 0.88938 to 0.88982, saving model to ./storage/mnist_test/kfold10/epoch_023_val_0.467_acc_0.890.h5\n",
      "20268/20268 [==============================] - 18s 911us/sample - loss: 0.0541 - accuracy: 0.9815 - val_loss: 0.4668 - val_accuracy: 0.8898\n",
      "Epoch 24/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9844\n",
      "Epoch 00024: val_accuracy improved from 0.88982 to 0.89292, saving model to ./storage/mnist_test/kfold10/epoch_024_val_0.490_acc_0.893.h5\n",
      "20268/20268 [==============================] - 19s 918us/sample - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.4895 - val_accuracy: 0.8929\n",
      "Epoch 25/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9845\n",
      "Epoch 00025: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 18s 880us/sample - loss: 0.0466 - accuracy: 0.9845 - val_loss: 0.5332 - val_accuracy: 0.8819\n",
      "Epoch 26/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9808\n",
      "Epoch 00026: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0577 - accuracy: 0.9808 - val_loss: 0.5420 - val_accuracy: 0.8788\n",
      "Epoch 27/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9845\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.89292\n",
      "20268/20268 [==============================] - 18s 880us/sample - loss: 0.0478 - accuracy: 0.9845 - val_loss: 0.4852 - val_accuracy: 0.8920\n",
      "Epoch 28/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9902\n",
      "Epoch 00028: val_accuracy improved from 0.89292 to 0.90177, saving model to ./storage/mnist_test/kfold10/epoch_028_val_0.455_acc_0.902.h5\n",
      "20268/20268 [==============================] - 18s 903us/sample - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.4548 - val_accuracy: 0.9018\n",
      "Epoch 29/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9923\n",
      "Epoch 00029: val_accuracy did not improve from 0.90177\n",
      "20268/20268 [==============================] - 18s 877us/sample - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.5229 - val_accuracy: 0.8858\n",
      "Epoch 30/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9915\n",
      "Epoch 00030: val_accuracy did not improve from 0.90177\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.4911 - val_accuracy: 0.8951\n",
      "Epoch 31/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90177\n",
      "20268/20268 [==============================] - 18s 882us/sample - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.5009 - val_accuracy: 0.8925\n",
      "Epoch 32/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 00032: val_accuracy improved from 0.90177 to 0.90265, saving model to ./storage/mnist_test/kfold10/epoch_032_val_0.458_acc_0.903.h5\n",
      "20268/20268 [==============================] - 18s 910us/sample - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.4583 - val_accuracy: 0.9027\n",
      "Epoch 33/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 00033: val_accuracy improved from 0.90265 to 0.90619, saving model to ./storage/mnist_test/kfold10/epoch_033_val_0.445_acc_0.906.h5\n",
      "20268/20268 [==============================] - 18s 910us/sample - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.4450 - val_accuracy: 0.9062\n",
      "Epoch 34/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 00034: val_accuracy did not improve from 0.90619\n",
      "20268/20268 [==============================] - 18s 882us/sample - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.4809 - val_accuracy: 0.8982\n",
      "Epoch 35/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9950\n",
      "Epoch 00035: val_accuracy did not improve from 0.90619\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.4926 - val_accuracy: 0.9018\n",
      "Epoch 36/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90619\n",
      "20268/20268 [==============================] - 18s 880us/sample - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.5117 - val_accuracy: 0.9009\n",
      "Epoch 37/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 00037: val_accuracy did not improve from 0.90619\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.4926 - val_accuracy: 0.9013\n",
      "Epoch 38/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9955\n",
      "Epoch 00038: val_accuracy did not improve from 0.90619\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.4578 - val_accuracy: 0.9062\n",
      "Epoch 39/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 00039: val_accuracy improved from 0.90619 to 0.91018, saving model to ./storage/mnist_test/kfold10/epoch_039_val_0.467_acc_0.910.h5\n",
      "20268/20268 [==============================] - 18s 910us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.4669 - val_accuracy: 0.9102\n",
      "Epoch 40/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9943\n",
      "Epoch 00040: val_accuracy did not improve from 0.91018\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.4572 - val_accuracy: 0.9049\n",
      "Epoch 41/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9961\n",
      "Epoch 00041: val_accuracy did not improve from 0.91018\n",
      "20268/20268 [==============================] - 18s 881us/sample - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.4632 - val_accuracy: 0.9058\n",
      "Epoch 42/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.91018\n",
      "20268/20268 [==============================] - 18s 884us/sample - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.4627 - val_accuracy: 0.9058\n",
      "Epoch 43/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9968\n",
      "Epoch 00043: val_accuracy improved from 0.91018 to 0.91062, saving model to ./storage/mnist_test/kfold10/epoch_043_val_0.437_acc_0.911.h5\n",
      "20268/20268 [==============================] - 19s 920us/sample - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.4373 - val_accuracy: 0.9106\n",
      "Epoch 44/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 00044: val_accuracy did not improve from 0.91062\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.4529 - val_accuracy: 0.9031\n",
      "Epoch 45/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9978\n",
      "Epoch 00045: val_accuracy did not improve from 0.91062\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.4576 - val_accuracy: 0.9097\n",
      "Epoch 46/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.91062\n",
      "20268/20268 [==============================] - 18s 884us/sample - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4986 - val_accuracy: 0.8987\n",
      "Epoch 47/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 00047: val_accuracy did not improve from 0.91062\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4675 - val_accuracy: 0.9080\n",
      "Epoch 48/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 00048: val_accuracy did not improve from 0.91062\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4948 - val_accuracy: 0.9071\n",
      "Epoch 49/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 00049: val_accuracy improved from 0.91062 to 0.91372, saving model to ./storage/mnist_test/kfold10/epoch_049_val_0.440_acc_0.914.h5\n",
      "20268/20268 [==============================] - 19s 923us/sample - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.4404 - val_accuracy: 0.9137\n",
      "Epoch 50/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 00050: val_accuracy did not improve from 0.91372\n",
      "20268/20268 [==============================] - 18s 880us/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.4454 - val_accuracy: 0.9115\n",
      "Epoch 51/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 00051: val_accuracy did not improve from 0.91372\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.4673 - val_accuracy: 0.9124\n",
      "Epoch 52/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.91372\n",
      "20268/20268 [==============================] - 18s 881us/sample - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5077 - val_accuracy: 0.9066\n",
      "Epoch 53/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 00053: val_accuracy did not improve from 0.91372\n",
      "20268/20268 [==============================] - 18s 884us/sample - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.4971 - val_accuracy: 0.9044\n",
      "Epoch 54/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 00054: val_accuracy did not improve from 0.91372\n",
      "20268/20268 [==============================] - 18s 880us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.4856 - val_accuracy: 0.9066\n",
      "Epoch 55/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00055: val_accuracy improved from 0.91372 to 0.91549, saving model to ./storage/mnist_test/kfold10/epoch_055_val_0.481_acc_0.915.h5\n",
      "20268/20268 [==============================] - 19s 918us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.4807 - val_accuracy: 0.9155\n",
      "Epoch 56/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00056: val_accuracy did not improve from 0.91549\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.4927 - val_accuracy: 0.9062\n",
      "Epoch 57/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00057: val_accuracy did not improve from 0.91549\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.4666 - val_accuracy: 0.9115\n",
      "Epoch 58/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.91549\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.4907 - val_accuracy: 0.9124\n",
      "Epoch 59/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 00059: val_accuracy improved from 0.91549 to 0.91858, saving model to ./storage/mnist_test/kfold10/epoch_059_val_0.476_acc_0.919.h5\n",
      "20268/20268 [==============================] - 18s 907us/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.4763 - val_accuracy: 0.9186\n",
      "Epoch 60/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 00060: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4805 - val_accuracy: 0.9119\n",
      "Epoch 61/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00061: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.4756 - val_accuracy: 0.9159\n",
      "Epoch 62/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 888us/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.4797 - val_accuracy: 0.9146\n",
      "Epoch 63/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00063: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4806 - val_accuracy: 0.9119\n",
      "Epoch 64/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00064: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4901 - val_accuracy: 0.9124\n",
      "Epoch 65/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.4918 - val_accuracy: 0.9119\n",
      "Epoch 66/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00066: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4813 - val_accuracy: 0.9137\n",
      "Epoch 67/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00067: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 882us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5082 - val_accuracy: 0.9115\n",
      "Epoch 68/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4927 - val_accuracy: 0.9111\n",
      "Epoch 69/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00069: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 884us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4930 - val_accuracy: 0.9115\n",
      "Epoch 70/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00070: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4999 - val_accuracy: 0.9124\n",
      "Epoch 71/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 882us/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4997 - val_accuracy: 0.9084\n",
      "Epoch 72/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00072: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4896 - val_accuracy: 0.9115\n",
      "Epoch 73/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 8.8328e-04 - accuracy: 0.9998\n",
      "Epoch 00073: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 8.8279e-04 - accuracy: 0.9998 - val_loss: 0.4894 - val_accuracy: 0.9111\n",
      "Epoch 74/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 7.0158e-04 - accuracy: 0.9999\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 881us/sample - loss: 7.0330e-04 - accuracy: 0.9999 - val_loss: 0.4895 - val_accuracy: 0.9150\n",
      "Epoch 75/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 9.1327e-04 - accuracy: 0.9997\n",
      "Epoch 00075: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 881us/sample - loss: 9.3672e-04 - accuracy: 0.9997 - val_loss: 0.4864 - val_accuracy: 0.9164\n",
      "Epoch 76/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00076: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4932 - val_accuracy: 0.9146\n",
      "Epoch 77/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 9.1462e-04 - accuracy: 0.9997\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 9.1408e-04 - accuracy: 0.9997 - val_loss: 0.5068 - val_accuracy: 0.9150\n",
      "Epoch 78/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 5.8641e-04 - accuracy: 1.0000\n",
      "Epoch 00078: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 886us/sample - loss: 5.8609e-04 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9137\n",
      "Epoch 79/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00079: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4939 - val_accuracy: 0.9150\n",
      "Epoch 80/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 5.7262e-04 - accuracy: 0.9999\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 883us/sample - loss: 5.8841e-04 - accuracy: 0.9999 - val_loss: 0.4918 - val_accuracy: 0.9155\n",
      "Epoch 81/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00081: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 882us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4891 - val_accuracy: 0.9155\n",
      "Epoch 82/300\n",
      "20224/20268 [============================>.] - ETA: 0s - loss: 3.7840e-04 - accuracy: 0.9999\n",
      "Epoch 00082: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 885us/sample - loss: 4.6312e-04 - accuracy: 0.9999 - val_loss: 0.4878 - val_accuracy: 0.9137\n",
      "Epoch 83/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 6.6543e-04 - accuracy: 0.9999\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 884us/sample - loss: 6.8110e-04 - accuracy: 0.9999 - val_loss: 0.4868 - val_accuracy: 0.9137\n",
      "Epoch 84/300\n",
      "20256/20268 [============================>.] - ETA: 0s - loss: 8.8565e-04 - accuracy: 0.9998\n",
      "Epoch 00084: val_accuracy did not improve from 0.91858\n",
      "20268/20268 [==============================] - 18s 890us/sample - loss: 8.8516e-04 - accuracy: 0.9998 - val_loss: 0.4854 - val_accuracy: 0.9142\n"
     ]
    }
   ],
   "source": [
    "# implement k-fold cv \n",
    "def k_fold(k,files):  \n",
    "    folds = [] \n",
    "    fold_size = len(files) // k \n",
    "    for i in range(k): \n",
    "        if i == k-1:  \n",
    "            l = files[i*fold_size:] \n",
    "        else: \n",
    "            l = files[i*fold_size:(i+1)*fold_size]  \n",
    "        folds.append(l)   \n",
    "    return folds  \n",
    "\n",
    "# shuffle before splitting data into folds \n",
    "x_train, y_train, train_letters_numeric = shuffle(x_train, y_train, train_letters_numeric)\n",
    "# split data into 5 folds \n",
    "k = 10\n",
    "x_train_folds = k_fold(k, x_train)\n",
    "y_train_folds = k_fold(k, y_train) \n",
    "letter_train_folds = k_fold(k,train_letters_numeric)\n",
    "\n",
    "for t in range(k):  \n",
    "    print(\"************ Fold {} training ************\".format(t+1)) \n",
    "    cur_val_x = x_train_folds[t] \n",
    "    cur_val_y = y_train_folds[t] \n",
    "    cur_val_letter = letter_train_folds[t]\n",
    "    train_folds_x = x_train_folds[0:t] + x_train_folds[t+1:] \n",
    "    train_folds_y = y_train_folds[0:t] + y_train_folds[t+1:]\n",
    "    train_fold_letter = letter_train_folds[0:t] + letter_train_folds[t+1:]\n",
    "    cur_train_x = [] \n",
    "    cur_train_y = [] \n",
    "    cur_letter = [] \n",
    "    for j in train_folds_x:  \n",
    "        for q in j:  \n",
    "            cur_train_x.append(q) \n",
    "    for j in train_folds_y:  \n",
    "        for q in j:  \n",
    "            cur_train_y.append(q)  \n",
    "    for j in train_fold_letter: \n",
    "        for q in j: \n",
    "            cur_letter.append(q) \n",
    "    cur_train_x = np.asarray(cur_train_x)\n",
    "    cur_train_y = np.asarray(cur_train_y)\n",
    "    cur_letter = np.asarray(cur_letter) \n",
    "    model_path = './storage/mnist_test/' + 'kfold' + str(t+1) + '/epoch_{epoch:03d}_val_{val_loss:.3f}_acc_{val_accuracy:.3f}.h5' \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.8)\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_accuracy',verbose=1,save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',patience=25)\n",
    "    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) # possible alternative to ReduceLROnPlateau\n",
    "    model = base_cnn_grade_5() \n",
    "    \n",
    "    history = model.fit([cur_train_x,cur_letter],\n",
    "                        cur_train_y, \n",
    "                       batch_size = 32,\n",
    "                       shuffle = True, \n",
    "                       validation_data = ([cur_val_x,cur_val_letter],cur_val_y),\n",
    "                       verbose = 1, \n",
    "                       epochs = 300,\n",
    "                       callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
