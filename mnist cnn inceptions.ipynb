{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# environment: Paperspace Quadro P4000 GPU\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras # run pip install keras==2.3 beforehand for compatability \n",
    "from tensorflow.keras import Input, Model \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in file and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './storage/modified_mnist_dataset/train.csv'  \n",
    "test_path = './storage/modified_mnist_dataset/test.csv' \n",
    "submission_path = './storage/modified_mnist_dataset/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path) \n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types of digit and letter columns to categorical \n",
    "train.iloc[:,1] = pd.Categorical(train.iloc[:,1])\n",
    "train.iloc[:,2] = pd.Categorical(train.iloc[:,2]) \n",
    "test.iloc[:,1] = pd.Categorical(test.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and re-format train and test data \n",
    "x_train = train.iloc[:,3:].values.reshape(-1,28,28,1).astype(np.float32) \n",
    "x_train /= 255.0 \n",
    "y_train = train.iloc[:,1].values\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "train_letters = train.iloc[:,2].values\n",
    "\n",
    "x_test = test.iloc[:,2:].values.reshape(-1,28,28,1).astype(np.float32) \n",
    "x_test /= 255.0\n",
    "test_letters = test.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 28, 28, 1), (2048, 10), (20480, 28, 28, 1), (2048, 26), (20480, 26))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letters_numeric = [] \n",
    "test_letters_numeric = [] \n",
    "for letter in train_letters: \n",
    "    train_letters_numeric.append(ord(letter) - ord(\"A\"))\n",
    "for letter in test_letters: \n",
    "    test_letters_numeric.append(ord(letter) - ord(\"A\")) \n",
    "    \n",
    "train_letters_numeric = np.asarray(train_letters_numeric) \n",
    "test_letters_numeric = np.asarray(test_letters_numeric) \n",
    "\n",
    "train_letters_numeric = to_categorical(train_letters_numeric, num_classes = 26) \n",
    "test_letters_numeric = to_categorical(test_letters_numeric, num_classes = 26)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, train_letters_numeric.shape, test_letters_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test data generators \n",
    "train_datagen = ImageDataGenerator(rotation_range = 40, \n",
    "                                  width_shift_range = 0.2, \n",
    "                                  height_shift_range = 0.2, \n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models to be used for experimentation \n",
    "# a basic model that obtains around a 74% validation loss on 9:1 train/validation split. \n",
    "def base_cnn(): \n",
    "    inputs = Input((28,28,1))\n",
    "    conv = Conv2D(64, 3, activation = 'relu')(inputs)\n",
    "    conv = Conv2D(64, 3, activation = 'relu')(conv)\n",
    "    conv = MaxPooling2D((2,2))(conv)\n",
    "    bn = BatchNormalization()(conv) \n",
    "    conv = Conv2D(128, 3, activation = 'relu')(bn)\n",
    "    conv = Conv2D(128, 3, activation = 'relu')(conv) \n",
    "    conv = MaxPooling2D((2,2))(conv) \n",
    "    bn = BatchNormalization()(conv)\n",
    "    conv = Conv2D(256, 3, activation = 'relu')(bn)\n",
    "    conv = MaxPooling2D((2,2))(conv)\n",
    "    outputs = Flatten()(conv)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(512, activation = 'relu')(outputs)\n",
    "    outputs = Dense(10, activation = 'softmax')(outputs) \n",
    "    model = Model(inputs = inputs, outputs = outputs) \n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses skip connections and also adds information from both MaxPooling2D and AveragePooling2D \n",
    "def conv2d_block(input_layer, n_filters, kernel):\n",
    "    conv1 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same')(conv1)\n",
    "    conv1 = Add()([conv1, conv2])   \n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    maxpool = MaxPooling2D((2,2))(conv1) \n",
    "    avgpool = AveragePooling2D((2,2))(conv1)\n",
    "    ret = Add()([maxpool,avgpool])\n",
    "    return ret \n",
    "\n",
    "def dense_block(input_layer, units): \n",
    "    dense1 = Dense(units, activation = 'relu')(input_layer)\n",
    "    for i in range(3): \n",
    "        bn = BatchNormalization()(dense1)\n",
    "        dense2 = Dense(units, activation = 'relu')(bn)\n",
    "        dense1 = Add()([dense1,dense2]) \n",
    "    return dense1 \n",
    "    \n",
    "# obtains around 75% validation loss on a 9:1 train/validation split \n",
    "def base_cnn_grade_2(): \n",
    "    inputs = Input((28,28,1))\n",
    "    conv0 = conv2d_block(inputs, 64, 7)    \n",
    "    conv1 = conv2d_block(inputs, 64, 5) \n",
    "    conv2 = conv2d_block(inputs, 64, 4) \n",
    "    conv3 = conv2d_block(inputs, 64, 3)\n",
    "    conv = Concatenate()([conv0,conv1,conv2,conv3])   \n",
    "    conv0 = conv2d_block(conv, 32, 7)\n",
    "    conv1 = conv2d_block(conv, 32, 5)\n",
    "    conv2 = conv2d_block(conv, 32, 4)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv = Concatenate()([conv0,conv1,conv2,conv3]) \n",
    "    outputs = Flatten()(conv)\n",
    "    for unit in [256, 128, 64]: \n",
    "        outputs = Dense(unit, activation = 'selu', kernel_initializer = 'lecun_normal')(outputs)  \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model \n",
    "\n",
    "# obtains around 80% validation loss on a 9:1 train/validation split \n",
    "def base_cnn_grade_3(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))\n",
    "    conv0 = conv2d_block(inputs, 64, 7)    \n",
    "    conv1 = conv2d_block(inputs, 64, 5) \n",
    "    conv2 = conv2d_block(inputs, 64, 4) \n",
    "    conv3 = conv2d_block(inputs, 64, 3)\n",
    "    conv = Concatenate()([conv0,conv1,conv2,conv3])   \n",
    "    conv0 = conv2d_block(conv, 32, 7)\n",
    "    conv1 = conv2d_block(conv, 32, 5)\n",
    "    conv2 = conv2d_block(conv, 32, 4)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv = Concatenate()([conv0,conv1,conv2,conv3]) \n",
    "    outputs = Flatten()(conv) \n",
    "    outputs = Concatenate()([outputs,letter_input])\n",
    "    for unit in [512, 256, 128]: \n",
    "        outputs = Dense(unit, activation = 'selu', kernel_initializer = 'lecun_normal')(outputs)  \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "# obtains around 82% validation loss on a 9:1 train/validation split\n",
    "# the most promising model so far, until we come up with a potentially more powerful grade 5 model \n",
    "def base_cnn_grade_4(): \n",
    "    inputs = Input((28,28,1))\n",
    "    letter_input = Input((26,))   \n",
    "    conv1 = conv2d_block(inputs, 64, 7) \n",
    "    conv2 = conv2d_block(inputs, 64, 5) \n",
    "    conv3 = conv2d_block(inputs, 64, 3) \n",
    "    conv = Concatenate()([conv1,conv2,conv3])   \n",
    "    conv1 = conv2d_block(conv, 32, 7)\n",
    "    conv2 = conv2d_block(conv, 32, 5)\n",
    "    conv3 = conv2d_block(conv, 32, 3) \n",
    "    conv = Concatenate()([conv1,conv2,conv3]) \n",
    "    outputs = Flatten()(conv) \n",
    "    outputs = Concatenate()([outputs,letter_input])\n",
    "    for unit in [512, 256, 128]: \n",
    "        outputs = Dense(unit, activation = 'relu')(outputs)  \n",
    "        outputs = BatchNormalization()(outputs) \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = [inputs, letter_input], outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "# baseline model presented by Dacon. \n",
    "def cnn_dacon(): \n",
    "    inputs = Input((28,28,1)) \n",
    "    letter_data = Input((26,)) \n",
    "\n",
    "    bn = BatchNormalization()(inputs)\n",
    "    conv = Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    conv = Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    bn = BatchNormalization()(pool)\n",
    "    conv = Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    bn = BatchNormalization()(conv)\n",
    "    conv = Conv2D(256, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
    "    pool = MaxPooling2D((2, 2))(conv)\n",
    "\n",
    "    flatten = Flatten()(pool)\n",
    "    flatten = Concatenate()([flatten, letter_data])\n",
    "    bn = BatchNormalization()(flatten)\n",
    "    dense = Dense(1000, activation='relu')(bn)\n",
    "\n",
    "    bn = BatchNormalization()(dense)\n",
    "    outputs = Dense(10, activation='softmax')(bn)\n",
    "    model = Model(inputs = [inputs,letter_data], outputs = outputs) \n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']) \n",
    "    return model \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# codeblock to delete files in model directory - for experimentation \n",
    "files = [os.path.join('./storage/kfold1/',x) for x in os.listdir('./storage/kfold1/')] \n",
    "for file in files:  \n",
    "    if 'epoch' in file: \n",
    "        os.remove(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Fold 1 training ************\n",
      "Train on 1639 samples, validate on 409 samples\n",
      "Epoch 1/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 2.4964 - accuracy: 0.2610\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.09535, saving model to ./storage/kfold1/epoch_001_val_3.439_acc_0.095.h5\n",
      "1639/1639 [==============================] - 6s 4ms/sample - loss: 2.4920 - accuracy: 0.2624 - val_loss: 3.4389 - val_accuracy: 0.0954\n",
      "Epoch 2/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.6684 - accuracy: 0.4638\n",
      "Epoch 00002: val_accuracy did not improve from 0.09535\n",
      "1639/1639 [==============================] - 2s 973us/sample - loss: 1.6683 - accuracy: 0.4643 - val_loss: 5.2898 - val_accuracy: 0.0513\n",
      "Epoch 3/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.1855 - accuracy: 0.6140\n",
      "Epoch 00003: val_accuracy improved from 0.09535 to 0.10758, saving model to ./storage/kfold1/epoch_003_val_11.266_acc_0.108.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 1.1863 - accuracy: 0.6138 - val_loss: 11.2657 - val_accuracy: 0.1076\n",
      "Epoch 4/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.8876 - accuracy: 0.6998\n",
      "Epoch 00004: val_accuracy did not improve from 0.10758\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.8917 - accuracy: 0.6986 - val_loss: 14.9278 - val_accuracy: 0.1076\n",
      "Epoch 5/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.7172 - accuracy: 0.7610\n",
      "Epoch 00005: val_accuracy did not improve from 0.10758\n",
      "1639/1639 [==============================] - 2s 964us/sample - loss: 0.7163 - accuracy: 0.7614 - val_loss: 12.9651 - val_accuracy: 0.1076\n",
      "Epoch 6/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.5411 - accuracy: 0.8266\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.10758\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.5443 - accuracy: 0.8267 - val_loss: 14.4114 - val_accuracy: 0.1076\n",
      "Epoch 7/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8554\n",
      "Epoch 00007: val_accuracy did not improve from 0.10758\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.4389 - accuracy: 0.8548 - val_loss: 12.5395 - val_accuracy: 0.1076\n",
      "Epoch 8/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3464 - accuracy: 0.8885\n",
      "Epoch 00008: val_accuracy improved from 0.10758 to 0.14425, saving model to ./storage/kfold1/epoch_008_val_8.176_acc_0.144.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3472 - accuracy: 0.8877 - val_loss: 8.1758 - val_accuracy: 0.1443\n",
      "Epoch 9/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2894 - accuracy: 0.9056\n",
      "Epoch 00009: val_accuracy did not improve from 0.14425\n",
      "1639/1639 [==============================] - 2s 979us/sample - loss: 0.2941 - accuracy: 0.9036 - val_loss: 8.8230 - val_accuracy: 0.1100\n",
      "Epoch 10/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2870 - accuracy: 0.9087\n",
      "Epoch 00010: val_accuracy improved from 0.14425 to 0.31296, saving model to ./storage/kfold1/epoch_010_val_2.707_acc_0.313.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2885 - accuracy: 0.9085 - val_loss: 2.7074 - val_accuracy: 0.3130\n",
      "Epoch 11/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2397 - accuracy: 0.9259\n",
      "Epoch 00011: val_accuracy improved from 0.31296 to 0.49144, saving model to ./storage/kfold1/epoch_011_val_1.988_acc_0.491.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2431 - accuracy: 0.9250 - val_loss: 1.9875 - val_accuracy: 0.4914\n",
      "Epoch 12/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.9197\n",
      "Epoch 00012: val_accuracy improved from 0.49144 to 0.51100, saving model to ./storage/kfold1/epoch_012_val_1.839_acc_0.511.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2583 - accuracy: 0.9182 - val_loss: 1.8390 - val_accuracy: 0.5110\n",
      "Epoch 13/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9381\n",
      "Epoch 00013: val_accuracy improved from 0.51100 to 0.70416, saving model to ./storage/kfold1/epoch_013_val_1.075_acc_0.704.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2033 - accuracy: 0.9378 - val_loss: 1.0746 - val_accuracy: 0.7042\n",
      "Epoch 14/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9455\n",
      "Epoch 00014: val_accuracy improved from 0.70416 to 0.74083, saving model to ./storage/kfold1/epoch_014_val_1.007_acc_0.741.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1668 - accuracy: 0.9451 - val_loss: 1.0068 - val_accuracy: 0.7408\n",
      "Epoch 15/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2193 - accuracy: 0.9259\n",
      "Epoch 00015: val_accuracy did not improve from 0.74083\n",
      "1639/1639 [==============================] - 2s 974us/sample - loss: 0.2225 - accuracy: 0.9243 - val_loss: 1.3111 - val_accuracy: 0.6675\n",
      "Epoch 16/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.8915\n",
      "Epoch 00016: val_accuracy did not improve from 0.74083\n",
      "1639/1639 [==============================] - 2s 981us/sample - loss: 0.3603 - accuracy: 0.8908 - val_loss: 1.0921 - val_accuracy: 0.7017\n",
      "Epoch 17/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9400\n",
      "Epoch 00017: val_accuracy improved from 0.74083 to 0.77751, saving model to ./storage/kfold1/epoch_017_val_0.902_acc_0.778.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1826 - accuracy: 0.9402 - val_loss: 0.9022 - val_accuracy: 0.7775\n",
      "Epoch 18/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9718\n",
      "Epoch 00018: val_accuracy improved from 0.77751 to 0.78484, saving model to ./storage/kfold1/epoch_018_val_0.874_acc_0.785.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1074 - accuracy: 0.9713 - val_loss: 0.8738 - val_accuracy: 0.7848\n",
      "Epoch 19/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9822\n",
      "Epoch 00019: val_accuracy did not improve from 0.78484\n",
      "1639/1639 [==============================] - 2s 960us/sample - loss: 0.0720 - accuracy: 0.9823 - val_loss: 0.8217 - val_accuracy: 0.7800\n",
      "Epoch 20/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9890\n",
      "Epoch 00020: val_accuracy improved from 0.78484 to 0.80196, saving model to ./storage/kfold1/epoch_020_val_0.792_acc_0.802.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0491 - accuracy: 0.9884 - val_loss: 0.7920 - val_accuracy: 0.8020\n",
      "Epoch 21/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9877\n",
      "Epoch 00021: val_accuracy did not improve from 0.80196\n",
      "1639/1639 [==============================] - 2s 976us/sample - loss: 0.0584 - accuracy: 0.9866 - val_loss: 0.8838 - val_accuracy: 0.7775\n",
      "Epoch 22/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9871\n",
      "Epoch 00022: val_accuracy did not improve from 0.80196\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.0561 - accuracy: 0.9866 - val_loss: 0.8835 - val_accuracy: 0.7702\n",
      "Epoch 23/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9835\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.80196\n",
      "1639/1639 [==============================] - 2s 978us/sample - loss: 0.0658 - accuracy: 0.9817 - val_loss: 0.8724 - val_accuracy: 0.7800\n",
      "Epoch 24/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9259\n",
      "Epoch 00024: val_accuracy did not improve from 0.80196\n",
      "1639/1639 [==============================] - 2s 985us/sample - loss: 0.1939 - accuracy: 0.9256 - val_loss: 1.0774 - val_accuracy: 0.7335\n",
      "Epoch 25/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9688\n",
      "Epoch 00025: val_accuracy did not improve from 0.80196\n",
      "1639/1639 [==============================] - 2s 961us/sample - loss: 0.1001 - accuracy: 0.9689 - val_loss: 0.9129 - val_accuracy: 0.7775\n",
      "Epoch 26/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9835\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.80196\n",
      "1639/1639 [==============================] - 2s 972us/sample - loss: 0.0595 - accuracy: 0.9829 - val_loss: 0.8225 - val_accuracy: 0.7848\n",
      "Epoch 27/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9859\n",
      "Epoch 00027: val_accuracy improved from 0.80196 to 0.80685, saving model to ./storage/kfold1/epoch_027_val_0.843_acc_0.807.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0486 - accuracy: 0.9860 - val_loss: 0.8428 - val_accuracy: 0.8068\n",
      "Epoch 28/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9926\n",
      "Epoch 00028: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 956us/sample - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.8440 - val_accuracy: 0.8044\n",
      "Epoch 29/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.0324 - accuracy: 0.9927 - val_loss: 0.8521 - val_accuracy: 0.7897\n",
      "Epoch 30/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9877\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 974us/sample - loss: 0.0464 - accuracy: 0.9878 - val_loss: 0.8257 - val_accuracy: 0.7873\n",
      "Epoch 31/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9933\n",
      "Epoch 00031: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 980us/sample - loss: 0.0316 - accuracy: 0.9927 - val_loss: 0.8348 - val_accuracy: 0.7971\n",
      "Epoch 32/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9908\n",
      "Epoch 00032: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.8224 - val_accuracy: 0.7946\n",
      "Epoch 33/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9957\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 990us/sample - loss: 0.0213 - accuracy: 0.9957 - val_loss: 0.8114 - val_accuracy: 0.7946\n",
      "Epoch 34/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9988\n",
      "Epoch 00034: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 972us/sample - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.8126 - val_accuracy: 0.8068\n",
      "Epoch 35/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9975\n",
      "Epoch 00035: val_accuracy did not improve from 0.80685\n",
      "1639/1639 [==============================] - 2s 976us/sample - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.8325 - val_accuracy: 0.8044\n",
      "Epoch 36/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9933\n",
      "Epoch 00036: val_accuracy improved from 0.80685 to 0.80929, saving model to ./storage/kfold1/epoch_036_val_0.875_acc_0.809.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0271 - accuracy: 0.9933 - val_loss: 0.8746 - val_accuracy: 0.8093\n",
      "Epoch 37/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9957\n",
      "Epoch 00037: val_accuracy did not improve from 0.80929\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.8310 - val_accuracy: 0.7922\n",
      "Epoch 38/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9945\n",
      "Epoch 00038: val_accuracy did not improve from 0.80929\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.8725 - val_accuracy: 0.7946\n",
      "Epoch 39/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9975\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.80929\n",
      "1639/1639 [==============================] - 2s 972us/sample - loss: 0.0165 - accuracy: 0.9976 - val_loss: 0.8537 - val_accuracy: 0.8020\n",
      "Epoch 40/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.80929\n",
      "1639/1639 [==============================] - 2s 976us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.8068\n",
      "Epoch 41/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9994\n",
      "Epoch 00041: val_accuracy improved from 0.80929 to 0.81418, saving model to ./storage/kfold1/epoch_041_val_0.831_acc_0.814.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.8307 - val_accuracy: 0.8142\n",
      "Epoch 42/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9994\n",
      "Epoch 00042: val_accuracy did not improve from 0.81418\n",
      "1639/1639 [==============================] - 2s 986us/sample - loss: 0.0087 - accuracy: 0.9994 - val_loss: 0.8419 - val_accuracy: 0.8044\n",
      "Epoch 43/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy improved from 0.81418 to 0.81663, saving model to ./storage/kfold1/epoch_043_val_0.832_acc_0.817.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8323 - val_accuracy: 0.8166\n",
      "Epoch 44/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9994\n",
      "Epoch 00044: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.0119 - accuracy: 0.9982 - val_loss: 0.8262 - val_accuracy: 0.8166\n",
      "Epoch 45/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9908\n",
      "Epoch 00045: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 974us/sample - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.9304 - val_accuracy: 0.7848\n",
      "Epoch 46/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9994\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 977us/sample - loss: 0.0143 - accuracy: 0.9982 - val_loss: 0.8934 - val_accuracy: 0.8020\n",
      "Epoch 47/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 00047: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 977us/sample - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.8401 - val_accuracy: 0.8044\n",
      "Epoch 48/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9982\n",
      "Epoch 00048: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.8432 - val_accuracy: 0.7971\n",
      "Epoch 49/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9982\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 972us/sample - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.8412 - val_accuracy: 0.7995\n",
      "Epoch 50/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9988\n",
      "Epoch 00050: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 972us/sample - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.8556 - val_accuracy: 0.7995\n",
      "Epoch 51/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 00051: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 974us/sample - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.8492 - val_accuracy: 0.8044\n",
      "Epoch 52/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 984us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.8044\n",
      "Epoch 53/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9994\n",
      "Epoch 00053: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.8537 - val_accuracy: 0.7971\n",
      "Epoch 54/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9994\n",
      "Epoch 00054: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.8991 - val_accuracy: 0.7995\n",
      "Epoch 55/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 961us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.8044\n",
      "Epoch 56/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9988\n",
      "Epoch 00056: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 978us/sample - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.9079 - val_accuracy: 0.8068\n",
      "Epoch 57/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 00057: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 977us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.8972 - val_accuracy: 0.8068\n",
      "Epoch 58/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.7995\n",
      "Epoch 59/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 00059: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 974us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.8068\n",
      "Epoch 60/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9982\n",
      "Epoch 00060: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 963us/sample - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.9156 - val_accuracy: 0.8044\n",
      "Epoch 61/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9982\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.9064 - val_accuracy: 0.8020\n",
      "Epoch 62/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 00062: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 961us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.7995\n",
      "Epoch 63/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9994\n",
      "Epoch 00063: val_accuracy did not improve from 0.81663\n",
      "1639/1639 [==============================] - 2s 973us/sample - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.8983 - val_accuracy: 0.7971\n",
      "************ Fold 2 training ************\n",
      "Train on 1639 samples, validate on 409 samples\n",
      "Epoch 1/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 2.5055 - accuracy: 0.2488\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.08802, saving model to ./storage/kfold2/epoch_001_val_3.943_acc_0.088.h5\n",
      "1639/1639 [==============================] - 6s 4ms/sample - loss: 2.5067 - accuracy: 0.2483 - val_loss: 3.9430 - val_accuracy: 0.0880\n",
      "Epoch 2/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.7901 - accuracy: 0.4062\n",
      "Epoch 00002: val_accuracy improved from 0.08802 to 0.09046, saving model to ./storage/kfold2/epoch_002_val_6.549_acc_0.090.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 1.7957 - accuracy: 0.4057 - val_loss: 6.5490 - val_accuracy: 0.0905\n",
      "Epoch 3/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.2914 - accuracy: 0.5766\n",
      "Epoch 00003: val_accuracy did not improve from 0.09046\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 1.2950 - accuracy: 0.5754 - val_loss: 10.7152 - val_accuracy: 0.0880\n",
      "Epoch 4/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.0164 - accuracy: 0.6538\n",
      "Epoch 00004: val_accuracy did not improve from 0.09046\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 1.0157 - accuracy: 0.6541 - val_loss: 9.3727 - val_accuracy: 0.0880\n",
      "Epoch 5/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.7385 - accuracy: 0.7665\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.09046\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.7408 - accuracy: 0.7663 - val_loss: 13.6757 - val_accuracy: 0.0880\n",
      "Epoch 6/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.5743 - accuracy: 0.8070\n",
      "Epoch 00006: val_accuracy did not improve from 0.09046\n",
      "1639/1639 [==============================] - 2s 978us/sample - loss: 0.5743 - accuracy: 0.8066 - val_loss: 16.0915 - val_accuracy: 0.0880\n",
      "Epoch 7/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.4788 - accuracy: 0.8382\n",
      "Epoch 00007: val_accuracy did not improve from 0.09046\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.4796 - accuracy: 0.8377 - val_loss: 13.0555 - val_accuracy: 0.0880\n",
      "Epoch 8/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8444\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.09046\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.4360 - accuracy: 0.8444 - val_loss: 17.6133 - val_accuracy: 0.0880\n",
      "Epoch 9/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3028 - accuracy: 0.8989\n",
      "Epoch 00009: val_accuracy improved from 0.09046 to 0.11736, saving model to ./storage/kfold2/epoch_009_val_9.118_acc_0.117.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3046 - accuracy: 0.8987 - val_loss: 9.1177 - val_accuracy: 0.1174\n",
      "Epoch 10/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9393\n",
      "Epoch 00010: val_accuracy improved from 0.11736 to 0.20049, saving model to ./storage/kfold2/epoch_010_val_5.155_acc_0.200.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2122 - accuracy: 0.9396 - val_loss: 5.1546 - val_accuracy: 0.2005\n",
      "Epoch 11/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9510\n",
      "Epoch 00011: val_accuracy improved from 0.20049 to 0.27139, saving model to ./storage/kfold2/epoch_011_val_3.888_acc_0.271.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1722 - accuracy: 0.9506 - val_loss: 3.8880 - val_accuracy: 0.2714\n",
      "Epoch 12/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9553\n",
      "Epoch 00012: val_accuracy improved from 0.27139 to 0.44010, saving model to ./storage/kfold2/epoch_012_val_2.481_acc_0.440.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1549 - accuracy: 0.9555 - val_loss: 2.4814 - val_accuracy: 0.4401\n",
      "Epoch 13/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9608\n",
      "Epoch 00013: val_accuracy improved from 0.44010 to 0.65526, saving model to ./storage/kfold2/epoch_013_val_1.205_acc_0.655.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1411 - accuracy: 0.9610 - val_loss: 1.2051 - val_accuracy: 0.6553\n",
      "Epoch 14/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9712\n",
      "Epoch 00014: val_accuracy improved from 0.65526 to 0.68460, saving model to ./storage/kfold2/epoch_014_val_1.159_acc_0.685.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1244 - accuracy: 0.9707 - val_loss: 1.1587 - val_accuracy: 0.6846\n",
      "Epoch 15/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9657\n",
      "Epoch 00015: val_accuracy improved from 0.68460 to 0.73105, saving model to ./storage/kfold2/epoch_015_val_1.031_acc_0.731.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1227 - accuracy: 0.9658 - val_loss: 1.0312 - val_accuracy: 0.7311\n",
      "Epoch 16/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9847\n",
      "Epoch 00016: val_accuracy improved from 0.73105 to 0.78240, saving model to ./storage/kfold2/epoch_016_val_0.776_acc_0.782.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0775 - accuracy: 0.9829 - val_loss: 0.7762 - val_accuracy: 0.7824\n",
      "Epoch 17/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9626\n",
      "Epoch 00017: val_accuracy did not improve from 0.78240\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 0.1375 - accuracy: 0.9622 - val_loss: 0.8458 - val_accuracy: 0.7653\n",
      "Epoch 18/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9577\n",
      "Epoch 00018: val_accuracy did not improve from 0.78240\n",
      "1639/1639 [==============================] - 2s 982us/sample - loss: 0.1449 - accuracy: 0.9579 - val_loss: 1.0581 - val_accuracy: 0.7604\n",
      "Epoch 19/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9473\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.78240\n",
      "1639/1639 [==============================] - 2s 966us/sample - loss: 0.1491 - accuracy: 0.9469 - val_loss: 0.8859 - val_accuracy: 0.7531\n",
      "Epoch 20/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9632\n",
      "Epoch 00020: val_accuracy improved from 0.78240 to 0.79218, saving model to ./storage/kfold2/epoch_020_val_0.742_acc_0.792.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1160 - accuracy: 0.9634 - val_loss: 0.7424 - val_accuracy: 0.7922\n",
      "Epoch 21/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9871\n",
      "Epoch 00021: val_accuracy improved from 0.79218 to 0.81418, saving model to ./storage/kfold2/epoch_021_val_0.684_acc_0.814.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0639 - accuracy: 0.9866 - val_loss: 0.6836 - val_accuracy: 0.8142\n",
      "Epoch 22/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9718\n",
      "Epoch 00022: val_accuracy did not improve from 0.81418\n",
      "1639/1639 [==============================] - 2s 966us/sample - loss: 0.1017 - accuracy: 0.9695 - val_loss: 0.8038 - val_accuracy: 0.7531\n",
      "Epoch 23/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.9026\n",
      "Epoch 00023: val_accuracy did not improve from 0.81418\n",
      "1639/1639 [==============================] - 2s 976us/sample - loss: 0.2855 - accuracy: 0.9030 - val_loss: 1.1144 - val_accuracy: 0.6773\n",
      "Epoch 24/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9522\n",
      "Epoch 00024: val_accuracy improved from 0.81418 to 0.81907, saving model to ./storage/kfold2/epoch_024_val_0.754_acc_0.819.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1428 - accuracy: 0.9518 - val_loss: 0.7536 - val_accuracy: 0.8191\n",
      "Epoch 25/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9798\n",
      "Epoch 00025: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 0.0792 - accuracy: 0.9799 - val_loss: 0.7518 - val_accuracy: 0.7946\n",
      "Epoch 26/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9890\n",
      "Epoch 00026: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0521 - accuracy: 0.9884 - val_loss: 0.7430 - val_accuracy: 0.7922\n",
      "Epoch 27/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9871\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 982us/sample - loss: 0.0574 - accuracy: 0.9866 - val_loss: 0.7423 - val_accuracy: 0.7922\n",
      "Epoch 28/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9914\n",
      "Epoch 00028: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0430 - accuracy: 0.9908 - val_loss: 0.7283 - val_accuracy: 0.7971\n",
      "Epoch 29/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9951\n",
      "Epoch 00029: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0366 - accuracy: 0.9945 - val_loss: 0.7736 - val_accuracy: 0.7946\n",
      "Epoch 30/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9810\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.0706 - accuracy: 0.9805 - val_loss: 0.7747 - val_accuracy: 0.7897\n",
      "Epoch 31/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9871\n",
      "Epoch 00031: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 984us/sample - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.7586 - val_accuracy: 0.8068\n",
      "Epoch 32/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9951\n",
      "Epoch 00032: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0332 - accuracy: 0.9945 - val_loss: 0.8141 - val_accuracy: 0.8093\n",
      "Epoch 33/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9926\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 966us/sample - loss: 0.0285 - accuracy: 0.9927 - val_loss: 0.7559 - val_accuracy: 0.7995\n",
      "Epoch 34/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9945\n",
      "Epoch 00034: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 972us/sample - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.7684 - val_accuracy: 0.7971\n",
      "Epoch 35/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9969\n",
      "Epoch 00035: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 962us/sample - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.7280 - val_accuracy: 0.8068\n",
      "Epoch 36/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9994\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 992us/sample - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.7286 - val_accuracy: 0.8020\n",
      "Epoch 37/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9982\n",
      "Epoch 00037: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.7151 - val_accuracy: 0.8068\n",
      "Epoch 38/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9969\n",
      "Epoch 00038: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.7066 - val_accuracy: 0.8044\n",
      "Epoch 39/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9994\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 973us/sample - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.6975 - val_accuracy: 0.8117\n",
      "Epoch 40/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9994\n",
      "Epoch 00040: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0100 - accuracy: 0.9994 - val_loss: 0.6872 - val_accuracy: 0.8093\n",
      "Epoch 41/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.0116 - accuracy: 0.9994 - val_loss: 0.6919 - val_accuracy: 0.8117\n",
      "Epoch 42/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9988\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.0105 - accuracy: 0.9988 - val_loss: 0.7221 - val_accuracy: 0.8093\n",
      "Epoch 43/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9988\n",
      "Epoch 00043: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 960us/sample - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.7411 - val_accuracy: 0.8191\n",
      "Epoch 44/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9988\n",
      "Epoch 00044: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 980us/sample - loss: 0.0120 - accuracy: 0.9988 - val_loss: 0.7301 - val_accuracy: 0.8166\n",
      "************ Fold 3 training ************\n",
      "Train on 1639 samples, validate on 409 samples\n",
      "Epoch 1/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 2.5102 - accuracy: 0.2390\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10024, saving model to ./storage/kfold3/epoch_001_val_4.122_acc_0.100.h5\n",
      "1639/1639 [==============================] - 6s 4ms/sample - loss: 2.5042 - accuracy: 0.2398 - val_loss: 4.1215 - val_accuracy: 0.1002\n",
      "Epoch 2/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.7723 - accuracy: 0.4277\n",
      "Epoch 00002: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 962us/sample - loss: 1.7685 - accuracy: 0.4283 - val_loss: 6.7784 - val_accuracy: 0.1002\n",
      "Epoch 3/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.2687 - accuracy: 0.5539\n",
      "Epoch 00003: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 973us/sample - loss: 1.2650 - accuracy: 0.5552 - val_loss: 8.6904 - val_accuracy: 0.0978\n",
      "Epoch 4/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.9614 - accuracy: 0.6783\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 983us/sample - loss: 0.9617 - accuracy: 0.6779 - val_loss: 8.7367 - val_accuracy: 0.0978\n",
      "Epoch 5/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.7463\n",
      "Epoch 00005: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.7613 - accuracy: 0.7462 - val_loss: 8.9039 - val_accuracy: 0.0954\n",
      "Epoch 6/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.6206 - accuracy: 0.7782\n",
      "Epoch 00006: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 987us/sample - loss: 0.6221 - accuracy: 0.7779 - val_loss: 11.8878 - val_accuracy: 0.0978\n",
      "Epoch 7/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.5130 - accuracy: 0.8248\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.5166 - accuracy: 0.8243 - val_loss: 6.7164 - val_accuracy: 0.0611\n",
      "Epoch 8/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8676\n",
      "Epoch 00008: val_accuracy did not improve from 0.10024\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.3915 - accuracy: 0.8670 - val_loss: 7.8145 - val_accuracy: 0.0831\n",
      "Epoch 9/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3126 - accuracy: 0.8995\n",
      "Epoch 00009: val_accuracy improved from 0.10024 to 0.13936, saving model to ./storage/kfold3/epoch_009_val_4.863_acc_0.139.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3142 - accuracy: 0.8993 - val_loss: 4.8629 - val_accuracy: 0.1394\n",
      "Epoch 10/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2405 - accuracy: 0.9246\n",
      "Epoch 00010: val_accuracy improved from 0.13936 to 0.22738, saving model to ./storage/kfold3/epoch_010_val_4.312_acc_0.227.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2410 - accuracy: 0.9250 - val_loss: 4.3123 - val_accuracy: 0.2274\n",
      "Epoch 11/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9461\n",
      "Epoch 00011: val_accuracy improved from 0.22738 to 0.22983, saving model to ./storage/kfold3/epoch_011_val_3.714_acc_0.230.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1985 - accuracy: 0.9451 - val_loss: 3.7144 - val_accuracy: 0.2298\n",
      "Epoch 12/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9277\n",
      "Epoch 00012: val_accuracy improved from 0.22983 to 0.44743, saving model to ./storage/kfold3/epoch_012_val_2.138_acc_0.447.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2366 - accuracy: 0.9274 - val_loss: 2.1377 - val_accuracy: 0.4474\n",
      "Epoch 13/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9498\n",
      "Epoch 00013: val_accuracy improved from 0.44743 to 0.59658, saving model to ./storage/kfold3/epoch_013_val_1.378_acc_0.597.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1814 - accuracy: 0.9494 - val_loss: 1.3779 - val_accuracy: 0.5966\n",
      "Epoch 14/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1328 - accuracy: 0.9663\n",
      "Epoch 00014: val_accuracy improved from 0.59658 to 0.71638, saving model to ./storage/kfold3/epoch_014_val_1.009_acc_0.716.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1331 - accuracy: 0.9658 - val_loss: 1.0094 - val_accuracy: 0.7164\n",
      "Epoch 15/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9779\n",
      "Epoch 00015: val_accuracy improved from 0.71638 to 0.73839, saving model to ./storage/kfold3/epoch_015_val_0.916_acc_0.738.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0963 - accuracy: 0.9780 - val_loss: 0.9157 - val_accuracy: 0.7384\n",
      "Epoch 16/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9804\n",
      "Epoch 00016: val_accuracy improved from 0.73839 to 0.78729, saving model to ./storage/kfold3/epoch_016_val_0.826_acc_0.787.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0751 - accuracy: 0.9805 - val_loss: 0.8260 - val_accuracy: 0.7873\n",
      "Epoch 17/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9841\n",
      "Epoch 00017: val_accuracy did not improve from 0.78729\n",
      "1639/1639 [==============================] - 2s 960us/sample - loss: 0.0709 - accuracy: 0.9841 - val_loss: 0.8525 - val_accuracy: 0.7555\n",
      "Epoch 18/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9749\n",
      "Epoch 00018: val_accuracy improved from 0.78729 to 0.78973, saving model to ./storage/kfold3/epoch_018_val_0.840_acc_0.790.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1030 - accuracy: 0.9738 - val_loss: 0.8401 - val_accuracy: 0.7897\n",
      "Epoch 19/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.9651\n",
      "Epoch 00019: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 981us/sample - loss: 0.1173 - accuracy: 0.9652 - val_loss: 0.9236 - val_accuracy: 0.7531\n",
      "Epoch 20/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9761\n",
      "Epoch 00020: val_accuracy improved from 0.78973 to 0.79462, saving model to ./storage/kfold3/epoch_020_val_0.833_acc_0.795.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0877 - accuracy: 0.9762 - val_loss: 0.8327 - val_accuracy: 0.7946\n",
      "Epoch 21/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9871\n",
      "Epoch 00021: val_accuracy improved from 0.79462 to 0.82152, saving model to ./storage/kfold3/epoch_021_val_0.706_acc_0.822.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0618 - accuracy: 0.9866 - val_loss: 0.7064 - val_accuracy: 0.8215\n",
      "Epoch 22/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9730\n",
      "Epoch 00022: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 977us/sample - loss: 0.0959 - accuracy: 0.9725 - val_loss: 0.9836 - val_accuracy: 0.7555\n",
      "Epoch 23/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9700\n",
      "Epoch 00023: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 961us/sample - loss: 0.1054 - accuracy: 0.9701 - val_loss: 0.9276 - val_accuracy: 0.7359\n",
      "Epoch 24/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9559\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.1262 - accuracy: 0.9549 - val_loss: 0.8299 - val_accuracy: 0.7677\n",
      "Epoch 25/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9724\n",
      "Epoch 00025: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 982us/sample - loss: 0.0946 - accuracy: 0.9707 - val_loss: 0.7482 - val_accuracy: 0.8044\n",
      "Epoch 26/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9553\n",
      "Epoch 00026: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 955us/sample - loss: 0.1353 - accuracy: 0.9555 - val_loss: 0.7663 - val_accuracy: 0.7971\n",
      "Epoch 27/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.9743\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.0801 - accuracy: 0.9744 - val_loss: 0.7415 - val_accuracy: 0.7897\n",
      "Epoch 28/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9926\n",
      "Epoch 00028: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 959us/sample - loss: 0.0414 - accuracy: 0.9927 - val_loss: 0.6975 - val_accuracy: 0.8044\n",
      "Epoch 29/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9926\n",
      "Epoch 00029: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0310 - accuracy: 0.9915 - val_loss: 0.6956 - val_accuracy: 0.8191\n",
      "Epoch 30/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9926\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0443 - accuracy: 0.9927 - val_loss: 0.7234 - val_accuracy: 0.8142\n",
      "Epoch 31/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9975\n",
      "Epoch 00031: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 973us/sample - loss: 0.0211 - accuracy: 0.9976 - val_loss: 0.7576 - val_accuracy: 0.8020\n",
      "Epoch 32/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9963\n",
      "Epoch 00032: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0210 - accuracy: 0.9963 - val_loss: 0.7081 - val_accuracy: 0.8191\n",
      "Epoch 33/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9969\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 961us/sample - loss: 0.0197 - accuracy: 0.9969 - val_loss: 0.7186 - val_accuracy: 0.8142\n",
      "Epoch 34/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9969\n",
      "Epoch 00034: val_accuracy did not improve from 0.82152\n",
      "1639/1639 [==============================] - 2s 964us/sample - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.7434 - val_accuracy: 0.8044\n",
      "Epoch 35/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9975\n",
      "Epoch 00035: val_accuracy improved from 0.82152 to 0.82396, saving model to ./storage/kfold3/epoch_035_val_0.725_acc_0.824.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.7247 - val_accuracy: 0.8240\n",
      "Epoch 36/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9982\n",
      "Epoch 00036: val_accuracy improved from 0.82396 to 0.82641, saving model to ./storage/kfold3/epoch_036_val_0.697_acc_0.826.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0154 - accuracy: 0.9982 - val_loss: 0.6971 - val_accuracy: 0.8264\n",
      "Epoch 37/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9988\n",
      "Epoch 00037: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 963us/sample - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.7394 - val_accuracy: 0.8093\n",
      "Epoch 38/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9951\n",
      "Epoch 00038: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.8667 - val_accuracy: 0.7946\n",
      "Epoch 39/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9969\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 963us/sample - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.7399 - val_accuracy: 0.8117\n",
      "Epoch 40/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9982\n",
      "Epoch 00040: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0112 - accuracy: 0.9982 - val_loss: 0.7603 - val_accuracy: 0.8166\n",
      "Epoch 41/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9982\n",
      "Epoch 00041: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 979us/sample - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.7438 - val_accuracy: 0.8166\n",
      "Epoch 42/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9975\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 957us/sample - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.7094 - val_accuracy: 0.8264\n",
      "Epoch 43/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 00043: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 958us/sample - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.7512 - val_accuracy: 0.7995\n",
      "Epoch 44/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9963\n",
      "Epoch 00044: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 957us/sample - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.7875 - val_accuracy: 0.7971\n",
      "Epoch 45/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 980us/sample - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.7756 - val_accuracy: 0.7922\n",
      "Epoch 46/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 960us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.7484 - val_accuracy: 0.8117\n",
      "Epoch 47/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.8142\n",
      "Epoch 48/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9994\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 978us/sample - loss: 0.0103 - accuracy: 0.9988 - val_loss: 0.7319 - val_accuracy: 0.8191\n",
      "Epoch 49/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9988\n",
      "Epoch 00049: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.7362 - val_accuracy: 0.8191\n",
      "Epoch 50/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9988\n",
      "Epoch 00050: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 961us/sample - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.7348 - val_accuracy: 0.8264\n",
      "Epoch 51/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9975\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 979us/sample - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.7766 - val_accuracy: 0.8166\n",
      "Epoch 52/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9982\n",
      "Epoch 00052: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 955us/sample - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.7311 - val_accuracy: 0.8215\n",
      "Epoch 53/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9982\n",
      "Epoch 00053: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 966us/sample - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.7452 - val_accuracy: 0.8142\n",
      "Epoch 54/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9994\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 963us/sample - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.7385 - val_accuracy: 0.8240\n",
      "Epoch 55/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9988\n",
      "Epoch 00055: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.7258 - val_accuracy: 0.8240\n",
      "Epoch 56/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9994\n",
      "Epoch 00056: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 964us/sample - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.7263 - val_accuracy: 0.8215\n",
      "************ Fold 4 training ************\n",
      "Train on 1639 samples, validate on 409 samples\n",
      "Epoch 1/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 2.4116 - accuracy: 0.2653\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.08313, saving model to ./storage/kfold4/epoch_001_val_3.939_acc_0.083.h5\n",
      "1639/1639 [==============================] - 6s 4ms/sample - loss: 2.4108 - accuracy: 0.2660 - val_loss: 3.9388 - val_accuracy: 0.0831\n",
      "Epoch 2/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.6336 - accuracy: 0.4602\n",
      "Epoch 00002: val_accuracy improved from 0.08313 to 0.09291, saving model to ./storage/kfold4/epoch_002_val_9.214_acc_0.093.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 1.6313 - accuracy: 0.4613 - val_loss: 9.2144 - val_accuracy: 0.0929\n",
      "Epoch 3/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 1.2426 - accuracy: 0.5662\n",
      "Epoch 00003: val_accuracy did not improve from 0.09291\n",
      "1639/1639 [==============================] - 2s 979us/sample - loss: 1.2460 - accuracy: 0.5650 - val_loss: 12.4482 - val_accuracy: 0.0929\n",
      "Epoch 4/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.9841 - accuracy: 0.6667\n",
      "Epoch 00004: val_accuracy did not improve from 0.09291\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.9853 - accuracy: 0.6669 - val_loss: 13.4896 - val_accuracy: 0.0929\n",
      "Epoch 5/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.7969 - accuracy: 0.7292\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.09291\n",
      "1639/1639 [==============================] - 2s 988us/sample - loss: 0.7987 - accuracy: 0.7291 - val_loss: 12.4463 - val_accuracy: 0.0929\n",
      "Epoch 6/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.5603 - accuracy: 0.8174\n",
      "Epoch 00006: val_accuracy did not improve from 0.09291\n",
      "1639/1639 [==============================] - 2s 963us/sample - loss: 0.5610 - accuracy: 0.8170 - val_loss: 9.7901 - val_accuracy: 0.0929\n",
      "Epoch 7/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.4221 - accuracy: 0.8615\n",
      "Epoch 00007: val_accuracy improved from 0.09291 to 0.09780, saving model to ./storage/kfold4/epoch_007_val_7.705_acc_0.098.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.4248 - accuracy: 0.8603 - val_loss: 7.7055 - val_accuracy: 0.0978\n",
      "Epoch 8/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8707\n",
      "Epoch 00008: val_accuracy did not improve from 0.09780\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 0.3815 - accuracy: 0.8707 - val_loss: 7.2575 - val_accuracy: 0.0929\n",
      "Epoch 9/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.9240\n",
      "Epoch 00009: val_accuracy did not improve from 0.09780\n",
      "1639/1639 [==============================] - 2s 977us/sample - loss: 0.2698 - accuracy: 0.9225 - val_loss: 7.7803 - val_accuracy: 0.0929\n",
      "Epoch 10/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.8934\n",
      "Epoch 00010: val_accuracy improved from 0.09780 to 0.17604, saving model to ./storage/kfold4/epoch_010_val_5.190_acc_0.176.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.3130 - accuracy: 0.8920 - val_loss: 5.1899 - val_accuracy: 0.1760\n",
      "Epoch 11/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.2514 - accuracy: 0.9179\n",
      "Epoch 00011: val_accuracy improved from 0.17604 to 0.44254, saving model to ./storage/kfold4/epoch_011_val_2.245_acc_0.443.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.2508 - accuracy: 0.9182 - val_loss: 2.2446 - val_accuracy: 0.4425\n",
      "Epoch 12/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9577\n",
      "Epoch 00012: val_accuracy improved from 0.44254 to 0.58680, saving model to ./storage/kfold4/epoch_012_val_1.581_acc_0.587.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1628 - accuracy: 0.9573 - val_loss: 1.5809 - val_accuracy: 0.5868\n",
      "Epoch 13/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9485\n",
      "Epoch 00013: val_accuracy improved from 0.58680 to 0.72127, saving model to ./storage/kfold4/epoch_013_val_0.997_acc_0.721.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1623 - accuracy: 0.9487 - val_loss: 0.9973 - val_accuracy: 0.7213\n",
      "Epoch 14/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9651\n",
      "Epoch 00014: val_accuracy improved from 0.72127 to 0.75061, saving model to ./storage/kfold4/epoch_014_val_0.872_acc_0.751.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1211 - accuracy: 0.9640 - val_loss: 0.8722 - val_accuracy: 0.7506\n",
      "Epoch 15/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1550 - accuracy: 0.9485\n",
      "Epoch 00015: val_accuracy did not improve from 0.75061\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 0.1552 - accuracy: 0.9481 - val_loss: 1.0102 - val_accuracy: 0.7457\n",
      "Epoch 16/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9516\n",
      "Epoch 00016: val_accuracy did not improve from 0.75061\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.1410 - accuracy: 0.9512 - val_loss: 0.9741 - val_accuracy: 0.7506\n",
      "Epoch 17/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9461\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75061\n",
      "1639/1639 [==============================] - 2s 976us/sample - loss: 0.1699 - accuracy: 0.9457 - val_loss: 0.9718 - val_accuracy: 0.7433\n",
      "Epoch 18/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9651\n",
      "Epoch 00018: val_accuracy improved from 0.75061 to 0.78484, saving model to ./storage/kfold4/epoch_018_val_0.863_acc_0.785.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.1205 - accuracy: 0.9646 - val_loss: 0.8631 - val_accuracy: 0.7848\n",
      "Epoch 19/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9761\n",
      "Epoch 00019: val_accuracy did not improve from 0.78484\n",
      "1639/1639 [==============================] - 2s 969us/sample - loss: 0.0952 - accuracy: 0.9756 - val_loss: 0.8955 - val_accuracy: 0.7457\n",
      "Epoch 20/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9810\n",
      "Epoch 00020: val_accuracy improved from 0.78484 to 0.78973, saving model to ./storage/kfold4/epoch_020_val_0.732_acc_0.790.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0750 - accuracy: 0.9793 - val_loss: 0.7316 - val_accuracy: 0.7897\n",
      "Epoch 21/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9577\n",
      "Epoch 00021: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 974us/sample - loss: 0.1188 - accuracy: 0.9573 - val_loss: 0.8406 - val_accuracy: 0.7751\n",
      "Epoch 22/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9706\n",
      "Epoch 00022: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.1011 - accuracy: 0.9701 - val_loss: 0.8514 - val_accuracy: 0.7702\n",
      "Epoch 23/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9645\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 964us/sample - loss: 0.1059 - accuracy: 0.9640 - val_loss: 0.9042 - val_accuracy: 0.7653\n",
      "Epoch 24/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9737\n",
      "Epoch 00024: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 990us/sample - loss: 0.0975 - accuracy: 0.9725 - val_loss: 0.8884 - val_accuracy: 0.7506\n",
      "Epoch 25/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9718\n",
      "Epoch 00025: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 966us/sample - loss: 0.0919 - accuracy: 0.9713 - val_loss: 0.7361 - val_accuracy: 0.7800\n",
      "Epoch 26/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9871\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.78973\n",
      "1639/1639 [==============================] - 2s 973us/sample - loss: 0.0471 - accuracy: 0.9872 - val_loss: 0.7560 - val_accuracy: 0.7873\n",
      "Epoch 27/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9933\n",
      "Epoch 00027: val_accuracy improved from 0.78973 to 0.81907, saving model to ./storage/kfold4/epoch_027_val_0.656_acc_0.819.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0316 - accuracy: 0.9927 - val_loss: 0.6561 - val_accuracy: 0.8191\n",
      "Epoch 28/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9957\n",
      "Epoch 00028: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 962us/sample - loss: 0.0260 - accuracy: 0.9957 - val_loss: 0.7408 - val_accuracy: 0.7971\n",
      "Epoch 29/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9951\n",
      "Epoch 00029: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 960us/sample - loss: 0.0290 - accuracy: 0.9945 - val_loss: 0.7074 - val_accuracy: 0.8068\n",
      "Epoch 30/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9939\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 988us/sample - loss: 0.0327 - accuracy: 0.9921 - val_loss: 0.6260 - val_accuracy: 0.8117\n",
      "Epoch 31/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9669\n",
      "Epoch 00031: val_accuracy did not improve from 0.81907\n",
      "1639/1639 [==============================] - 2s 967us/sample - loss: 0.0906 - accuracy: 0.9671 - val_loss: 0.7865 - val_accuracy: 0.7653\n",
      "Epoch 32/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9945\n",
      "Epoch 00032: val_accuracy improved from 0.81907 to 0.82641, saving model to ./storage/kfold4/epoch_032_val_0.696_acc_0.826.h5\n",
      "1639/1639 [==============================] - 2s 1ms/sample - loss: 0.0313 - accuracy: 0.9933 - val_loss: 0.6964 - val_accuracy: 0.8264\n",
      "Epoch 33/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9926\n",
      "Epoch 00033: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 985us/sample - loss: 0.0386 - accuracy: 0.9921 - val_loss: 0.7584 - val_accuracy: 0.8020\n",
      "Epoch 34/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9926\n",
      "Epoch 00034: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 962us/sample - loss: 0.0394 - accuracy: 0.9902 - val_loss: 0.6872 - val_accuracy: 0.8215\n",
      "Epoch 35/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9859\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0561 - accuracy: 0.9860 - val_loss: 0.8143 - val_accuracy: 0.7897\n",
      "Epoch 36/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9951\n",
      "Epoch 00036: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0284 - accuracy: 0.9951 - val_loss: 0.6900 - val_accuracy: 0.8191\n",
      "Epoch 37/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9939\n",
      "Epoch 00037: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 979us/sample - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.6549 - val_accuracy: 0.8264\n",
      "Epoch 38/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9982\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.6881 - val_accuracy: 0.7995\n",
      "Epoch 39/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9963\n",
      "Epoch 00039: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 976us/sample - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.7028 - val_accuracy: 0.8020\n",
      "Epoch 40/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9957\n",
      "Epoch 00040: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 991us/sample - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.6261 - val_accuracy: 0.8093\n",
      "Epoch 41/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9969\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.6756 - val_accuracy: 0.7971\n",
      "Epoch 42/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9988\n",
      "Epoch 00042: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0135 - accuracy: 0.9988 - val_loss: 0.6471 - val_accuracy: 0.8068\n",
      "Epoch 43/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9988\n",
      "Epoch 00043: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 984us/sample - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.6375 - val_accuracy: 0.8020\n",
      "Epoch 44/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9988\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0174 - accuracy: 0.9982 - val_loss: 0.6896 - val_accuracy: 0.8044\n",
      "Epoch 45/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9988\n",
      "Epoch 00045: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0125 - accuracy: 0.9988 - val_loss: 0.6798 - val_accuracy: 0.8142\n",
      "Epoch 46/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9975\n",
      "Epoch 00046: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 968us/sample - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.6891 - val_accuracy: 0.8020\n",
      "Epoch 47/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9939\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 980us/sample - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.6385 - val_accuracy: 0.8166\n",
      "Epoch 48/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9982\n",
      "Epoch 00048: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 965us/sample - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.6350 - val_accuracy: 0.8215\n",
      "Epoch 49/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9994\n",
      "Epoch 00049: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 970us/sample - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.6234 - val_accuracy: 0.8191\n",
      "Epoch 50/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9994\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 975us/sample - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.6484 - val_accuracy: 0.8240\n",
      "Epoch 51/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9988\n",
      "Epoch 00051: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 971us/sample - loss: 0.0116 - accuracy: 0.9988 - val_loss: 0.6417 - val_accuracy: 0.8166\n",
      "Epoch 52/200\n",
      "1632/1639 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.82641\n",
      "1639/1639 [==============================] - 2s 962us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.8191\n",
      "************ Fold 5 training ************\n",
      "Train on 1636 samples, validate on 412 samples\n",
      "Epoch 1/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 2.5830 - accuracy: 0.2359\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10680, saving model to ./storage/kfold5/epoch_001_val_5.913_acc_0.107.h5\n",
      "1636/1636 [==============================] - 6s 4ms/sample - loss: 2.5812 - accuracy: 0.2366 - val_loss: 5.9132 - val_accuracy: 0.1068\n",
      "Epoch 2/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 1.9243 - accuracy: 0.3756\n",
      "Epoch 00002: val_accuracy did not improve from 0.10680\n",
      "1636/1636 [==============================] - 2s 968us/sample - loss: 1.9241 - accuracy: 0.3753 - val_loss: 9.1323 - val_accuracy: 0.1068\n",
      "Epoch 3/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 1.4940 - accuracy: 0.4841\n",
      "Epoch 00003: val_accuracy improved from 0.10680 to 0.10922, saving model to ./storage/kfold5/epoch_003_val_12.255_acc_0.109.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 1.4924 - accuracy: 0.4841 - val_loss: 12.2546 - val_accuracy: 0.1092\n",
      "Epoch 4/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 1.1175 - accuracy: 0.6189\n",
      "Epoch 00004: val_accuracy did not improve from 0.10922\n",
      "1636/1636 [==============================] - 2s 971us/sample - loss: 1.1229 - accuracy: 0.6174 - val_loss: 15.0399 - val_accuracy: 0.1068\n",
      "Epoch 5/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 1.0209 - accuracy: 0.6581\n",
      "Epoch 00005: val_accuracy did not improve from 0.10922\n",
      "1636/1636 [==============================] - 2s 980us/sample - loss: 1.0237 - accuracy: 0.6577 - val_loss: 17.7460 - val_accuracy: 0.1068\n",
      "Epoch 6/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.9129 - accuracy: 0.6918\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.10922\n",
      "1636/1636 [==============================] - 2s 983us/sample - loss: 0.9129 - accuracy: 0.6919 - val_loss: 18.8013 - val_accuracy: 0.1068\n",
      "Epoch 7/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.7113 - accuracy: 0.7610\n",
      "Epoch 00007: val_accuracy did not improve from 0.10922\n",
      "1636/1636 [==============================] - 2s 967us/sample - loss: 0.7124 - accuracy: 0.7610 - val_loss: 12.1650 - val_accuracy: 0.1068\n",
      "Epoch 8/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.5602 - accuracy: 0.8070\n",
      "Epoch 00008: val_accuracy improved from 0.10922 to 0.11165, saving model to ./storage/kfold5/epoch_008_val_11.374_acc_0.112.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.5614 - accuracy: 0.8062 - val_loss: 11.3743 - val_accuracy: 0.1117\n",
      "Epoch 9/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8401\n",
      "Epoch 00009: val_accuracy did not improve from 0.11165\n",
      "1636/1636 [==============================] - 2s 970us/sample - loss: 0.4618 - accuracy: 0.8392 - val_loss: 11.0113 - val_accuracy: 0.1117\n",
      "Epoch 10/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.3733 - accuracy: 0.8811\n",
      "Epoch 00010: val_accuracy improved from 0.11165 to 0.18204, saving model to ./storage/kfold5/epoch_010_val_7.379_acc_0.182.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.3752 - accuracy: 0.8808 - val_loss: 7.3789 - val_accuracy: 0.1820\n",
      "Epoch 11/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.8683\n",
      "Epoch 00011: val_accuracy improved from 0.18204 to 0.31311, saving model to ./storage/kfold5/epoch_011_val_3.338_acc_0.313.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.4073 - accuracy: 0.8674 - val_loss: 3.3382 - val_accuracy: 0.3131\n",
      "Epoch 12/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8591\n",
      "Epoch 00012: val_accuracy improved from 0.31311 to 0.35194, saving model to ./storage/kfold5/epoch_012_val_3.267_acc_0.352.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.4238 - accuracy: 0.8582 - val_loss: 3.2673 - val_accuracy: 0.3519\n",
      "Epoch 13/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.3415 - accuracy: 0.8903\n",
      "Epoch 00013: val_accuracy improved from 0.35194 to 0.62621, saving model to ./storage/kfold5/epoch_013_val_1.282_acc_0.626.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.3447 - accuracy: 0.8894 - val_loss: 1.2815 - val_accuracy: 0.6262\n",
      "Epoch 14/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9173\n",
      "Epoch 00014: val_accuracy improved from 0.62621 to 0.71359, saving model to ./storage/kfold5/epoch_014_val_1.007_acc_0.714.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.2546 - accuracy: 0.9163 - val_loss: 1.0074 - val_accuracy: 0.7136\n",
      "Epoch 15/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.9056\n",
      "Epoch 00015: val_accuracy did not improve from 0.71359\n",
      "1636/1636 [==============================] - 2s 964us/sample - loss: 0.2788 - accuracy: 0.9059 - val_loss: 1.1611 - val_accuracy: 0.6578\n",
      "Epoch 16/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.9161\n",
      "Epoch 00016: val_accuracy improved from 0.71359 to 0.71845, saving model to ./storage/kfold5/epoch_016_val_1.022_acc_0.718.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.2555 - accuracy: 0.9144 - val_loss: 1.0219 - val_accuracy: 0.7184\n",
      "Epoch 17/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9271\n",
      "Epoch 00017: val_accuracy improved from 0.71845 to 0.76214, saving model to ./storage/kfold5/epoch_017_val_0.867_acc_0.762.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.2384 - accuracy: 0.9260 - val_loss: 0.8670 - val_accuracy: 0.7621\n",
      "Epoch 18/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.8064\n",
      "Epoch 00018: val_accuracy did not improve from 0.76214\n",
      "1636/1636 [==============================] - 2s 967us/sample - loss: 0.5422 - accuracy: 0.8056 - val_loss: 1.1832 - val_accuracy: 0.6796\n",
      "Epoch 19/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8713\n",
      "Epoch 00019: val_accuracy did not improve from 0.76214\n",
      "1636/1636 [==============================] - 2s 976us/sample - loss: 0.3868 - accuracy: 0.8710 - val_loss: 1.0378 - val_accuracy: 0.6845\n",
      "Epoch 20/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8517\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76214\n",
      "1636/1636 [==============================] - 2s 989us/sample - loss: 0.4309 - accuracy: 0.8515 - val_loss: 0.8126 - val_accuracy: 0.7524\n",
      "Epoch 21/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9308\n",
      "Epoch 00021: val_accuracy did not improve from 0.76214\n",
      "1636/1636 [==============================] - 2s 961us/sample - loss: 0.2146 - accuracy: 0.9303 - val_loss: 0.9480 - val_accuracy: 0.7136\n",
      "Epoch 22/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9626\n",
      "Epoch 00022: val_accuracy improved from 0.76214 to 0.76699, saving model to ./storage/kfold5/epoch_022_val_0.769_acc_0.767.h5\n",
      "1636/1636 [==============================] - 3s 2ms/sample - loss: 0.1445 - accuracy: 0.9615 - val_loss: 0.7688 - val_accuracy: 0.7670\n",
      "Epoch 23/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9608\n",
      "Epoch 00023: val_accuracy improved from 0.76699 to 0.80097, saving model to ./storage/kfold5/epoch_023_val_0.634_acc_0.801.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.1480 - accuracy: 0.9603 - val_loss: 0.6340 - val_accuracy: 0.8010\n",
      "Epoch 24/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9412\n",
      "Epoch 00024: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 979us/sample - loss: 0.1759 - accuracy: 0.9413 - val_loss: 0.7382 - val_accuracy: 0.7816\n",
      "Epoch 25/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9596\n",
      "Epoch 00025: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 998us/sample - loss: 0.1488 - accuracy: 0.9590 - val_loss: 0.7560 - val_accuracy: 0.7670\n",
      "Epoch 26/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.9694\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 966us/sample - loss: 0.1054 - accuracy: 0.9688 - val_loss: 0.6941 - val_accuracy: 0.8010\n",
      "Epoch 27/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9737\n",
      "Epoch 00027: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 963us/sample - loss: 0.0953 - accuracy: 0.9725 - val_loss: 0.7045 - val_accuracy: 0.7937\n",
      "Epoch 28/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9651\n",
      "Epoch 00028: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 969us/sample - loss: 0.1173 - accuracy: 0.9645 - val_loss: 0.7145 - val_accuracy: 0.7985\n",
      "Epoch 29/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9620\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 986us/sample - loss: 0.1212 - accuracy: 0.9615 - val_loss: 0.8101 - val_accuracy: 0.7573\n",
      "Epoch 30/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9638\n",
      "Epoch 00030: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 987us/sample - loss: 0.1242 - accuracy: 0.9633 - val_loss: 0.7442 - val_accuracy: 0.7694\n",
      "Epoch 31/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 0.9749\n",
      "Epoch 00031: val_accuracy did not improve from 0.80097\n",
      "1636/1636 [==============================] - 2s 972us/sample - loss: 0.0895 - accuracy: 0.9749 - val_loss: 0.7036 - val_accuracy: 0.7961\n",
      "Epoch 32/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9816\n",
      "Epoch 00032: val_accuracy improved from 0.80097 to 0.82039, saving model to ./storage/kfold5/epoch_032_val_0.665_acc_0.820.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.0675 - accuracy: 0.9817 - val_loss: 0.6649 - val_accuracy: 0.8204\n",
      "Epoch 33/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9828\n",
      "Epoch 00033: val_accuracy did not improve from 0.82039\n",
      "1636/1636 [==============================] - 2s 966us/sample - loss: 0.0699 - accuracy: 0.9817 - val_loss: 0.7263 - val_accuracy: 0.7961\n",
      "Epoch 34/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9804\n",
      "Epoch 00034: val_accuracy did not improve from 0.82039\n",
      "1636/1636 [==============================] - 2s 971us/sample - loss: 0.0728 - accuracy: 0.9792 - val_loss: 0.8136 - val_accuracy: 0.7937\n",
      "Epoch 35/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9804\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.82039\n",
      "1636/1636 [==============================] - 2s 981us/sample - loss: 0.0773 - accuracy: 0.9804 - val_loss: 0.7478 - val_accuracy: 0.7840\n",
      "Epoch 36/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9939\n",
      "Epoch 00036: val_accuracy did not improve from 0.82039\n",
      "1636/1636 [==============================] - 2s 966us/sample - loss: 0.0507 - accuracy: 0.9927 - val_loss: 0.7005 - val_accuracy: 0.8083\n",
      "Epoch 37/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9810\n",
      "Epoch 00037: val_accuracy did not improve from 0.82039\n",
      "1636/1636 [==============================] - 2s 967us/sample - loss: 0.0829 - accuracy: 0.9804 - val_loss: 0.6991 - val_accuracy: 0.7961\n",
      "Epoch 38/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9902\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.82039\n",
      "1636/1636 [==============================] - 2s 977us/sample - loss: 0.0439 - accuracy: 0.9902 - val_loss: 0.6805 - val_accuracy: 0.8131\n",
      "Epoch 39/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9920\n",
      "Epoch 00039: val_accuracy improved from 0.82039 to 0.82524, saving model to ./storage/kfold5/epoch_039_val_0.682_acc_0.825.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.0366 - accuracy: 0.9921 - val_loss: 0.6819 - val_accuracy: 0.8252\n",
      "Epoch 40/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9957\n",
      "Epoch 00040: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 969us/sample - loss: 0.0266 - accuracy: 0.9957 - val_loss: 0.6809 - val_accuracy: 0.8228\n",
      "Epoch 41/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9969\n",
      "Epoch 00041: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 978us/sample - loss: 0.0255 - accuracy: 0.9969 - val_loss: 0.6714 - val_accuracy: 0.8252\n",
      "Epoch 42/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9969\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 974us/sample - loss: 0.0266 - accuracy: 0.9969 - val_loss: 0.7069 - val_accuracy: 0.8155\n",
      "Epoch 43/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9988\n",
      "Epoch 00043: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 982us/sample - loss: 0.0288 - accuracy: 0.9969 - val_loss: 0.7094 - val_accuracy: 0.8228\n",
      "Epoch 44/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9835\n",
      "Epoch 00044: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 973us/sample - loss: 0.0715 - accuracy: 0.9823 - val_loss: 0.7634 - val_accuracy: 0.8058\n",
      "Epoch 45/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9920\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 974us/sample - loss: 0.0430 - accuracy: 0.9908 - val_loss: 0.8130 - val_accuracy: 0.7985\n",
      "Epoch 46/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9957\n",
      "Epoch 00046: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 965us/sample - loss: 0.0324 - accuracy: 0.9951 - val_loss: 0.7765 - val_accuracy: 0.8058\n",
      "Epoch 47/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9933\n",
      "Epoch 00047: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 966us/sample - loss: 0.0331 - accuracy: 0.9927 - val_loss: 0.7806 - val_accuracy: 0.8131\n",
      "Epoch 48/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9884\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 982us/sample - loss: 0.0497 - accuracy: 0.9872 - val_loss: 0.7129 - val_accuracy: 0.8204\n",
      "Epoch 49/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9890\n",
      "Epoch 00049: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 964us/sample - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.6892 - val_accuracy: 0.8204\n",
      "Epoch 50/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9914\n",
      "Epoch 00050: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 969us/sample - loss: 0.0382 - accuracy: 0.9914 - val_loss: 0.6610 - val_accuracy: 0.8204\n",
      "Epoch 51/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9914\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 967us/sample - loss: 0.0431 - accuracy: 0.9902 - val_loss: 0.6797 - val_accuracy: 0.8107\n",
      "Epoch 52/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9939\n",
      "Epoch 00052: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 965us/sample - loss: 0.0421 - accuracy: 0.9927 - val_loss: 0.6612 - val_accuracy: 0.8131\n",
      "Epoch 53/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9963\n",
      "Epoch 00053: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 975us/sample - loss: 0.0282 - accuracy: 0.9957 - val_loss: 0.6566 - val_accuracy: 0.8155\n",
      "Epoch 54/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9951\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.82524\n",
      "1636/1636 [==============================] - 2s 983us/sample - loss: 0.0290 - accuracy: 0.9945 - val_loss: 0.6582 - val_accuracy: 0.8204\n",
      "Epoch 55/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9975\n",
      "Epoch 00055: val_accuracy improved from 0.82524 to 0.82767, saving model to ./storage/kfold5/epoch_055_val_0.659_acc_0.828.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.6588 - val_accuracy: 0.8277\n",
      "Epoch 56/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9957\n",
      "Epoch 00056: val_accuracy improved from 0.82767 to 0.83010, saving model to ./storage/kfold5/epoch_056_val_0.661_acc_0.830.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.0262 - accuracy: 0.9957 - val_loss: 0.6610 - val_accuracy: 0.8301\n",
      "Epoch 57/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9951\n",
      "Epoch 00057: val_accuracy did not improve from 0.83010\n",
      "1636/1636 [==============================] - 2s 984us/sample - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.6608 - val_accuracy: 0.8252\n",
      "Epoch 58/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9969\n",
      "Epoch 00058: val_accuracy did not improve from 0.83010\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.0266 - accuracy: 0.9963 - val_loss: 0.6871 - val_accuracy: 0.8301\n",
      "Epoch 59/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9963\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.83010\n",
      "1636/1636 [==============================] - 2s 964us/sample - loss: 0.0251 - accuracy: 0.9957 - val_loss: 0.6763 - val_accuracy: 0.8155\n",
      "Epoch 60/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9982\n",
      "Epoch 00060: val_accuracy did not improve from 0.83010\n",
      "1636/1636 [==============================] - 2s 965us/sample - loss: 0.0197 - accuracy: 0.9982 - val_loss: 0.6604 - val_accuracy: 0.8252\n",
      "Epoch 61/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9975\n",
      "Epoch 00061: val_accuracy improved from 0.83010 to 0.83252, saving model to ./storage/kfold5/epoch_061_val_0.661_acc_0.833.h5\n",
      "1636/1636 [==============================] - 2s 1ms/sample - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.6607 - val_accuracy: 0.8325\n",
      "Epoch 62/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9982\n",
      "Epoch 00062: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 968us/sample - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.6644 - val_accuracy: 0.8325\n",
      "Epoch 63/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9957\n",
      "Epoch 00063: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 973us/sample - loss: 0.0299 - accuracy: 0.9945 - val_loss: 0.6659 - val_accuracy: 0.8277\n",
      "Epoch 64/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9982\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 975us/sample - loss: 0.0273 - accuracy: 0.9963 - val_loss: 0.6716 - val_accuracy: 0.8204\n",
      "Epoch 65/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9969\n",
      "Epoch 00065: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 975us/sample - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.6806 - val_accuracy: 0.8180\n",
      "Epoch 66/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9975\n",
      "Epoch 00066: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 977us/sample - loss: 0.0215 - accuracy: 0.9976 - val_loss: 0.6687 - val_accuracy: 0.8083\n",
      "Epoch 67/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9994\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 966us/sample - loss: 0.0171 - accuracy: 0.9988 - val_loss: 0.6704 - val_accuracy: 0.8131\n",
      "Epoch 68/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9969\n",
      "Epoch 00068: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 982us/sample - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.6808 - val_accuracy: 0.8083\n",
      "Epoch 69/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9969\n",
      "Epoch 00069: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 971us/sample - loss: 0.0196 - accuracy: 0.9963 - val_loss: 0.6833 - val_accuracy: 0.8131\n",
      "Epoch 70/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9988\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 959us/sample - loss: 0.0168 - accuracy: 0.9982 - val_loss: 0.6803 - val_accuracy: 0.8180\n",
      "Epoch 71/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9994\n",
      "Epoch 00071: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 974us/sample - loss: 0.0134 - accuracy: 0.9994 - val_loss: 0.6819 - val_accuracy: 0.8252\n",
      "Epoch 72/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9975\n",
      "Epoch 00072: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 969us/sample - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.6811 - val_accuracy: 0.8228\n",
      "Epoch 73/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9982\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 974us/sample - loss: 0.0166 - accuracy: 0.9982 - val_loss: 0.6780 - val_accuracy: 0.8228\n",
      "Epoch 74/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9994\n",
      "Epoch 00074: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 975us/sample - loss: 0.0191 - accuracy: 0.9982 - val_loss: 0.6746 - val_accuracy: 0.8155\n",
      "Epoch 75/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9951\n",
      "Epoch 00075: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 977us/sample - loss: 0.0229 - accuracy: 0.9951 - val_loss: 0.6745 - val_accuracy: 0.8131\n",
      "Epoch 76/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9994\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 969us/sample - loss: 0.0161 - accuracy: 0.9994 - val_loss: 0.6779 - val_accuracy: 0.8155\n",
      "Epoch 77/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9988\n",
      "Epoch 00077: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 970us/sample - loss: 0.0180 - accuracy: 0.9982 - val_loss: 0.6805 - val_accuracy: 0.8131\n",
      "Epoch 78/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9994\n",
      "Epoch 00078: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 981us/sample - loss: 0.0134 - accuracy: 0.9988 - val_loss: 0.6825 - val_accuracy: 0.8155\n",
      "Epoch 79/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9975\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 970us/sample - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.6828 - val_accuracy: 0.8180\n",
      "Epoch 80/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9994\n",
      "Epoch 00080: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 968us/sample - loss: 0.0152 - accuracy: 0.9988 - val_loss: 0.6838 - val_accuracy: 0.8155\n",
      "Epoch 81/200\n",
      "1632/1636 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9988\n",
      "Epoch 00081: val_accuracy did not improve from 0.83252\n",
      "1636/1636 [==============================] - 2s 969us/sample - loss: 0.0161 - accuracy: 0.9982 - val_loss: 0.6874 - val_accuracy: 0.8228\n"
     ]
    }
   ],
   "source": [
    "# implement k-fold cv \n",
    "def k_fold(k,files):  \n",
    "    folds = [] \n",
    "    fold_size = len(files) // k \n",
    "    for i in range(k): \n",
    "        if i == k-1:  \n",
    "            l = files[i*fold_size:] \n",
    "        else: \n",
    "            l = files[i*fold_size:(i+1)*fold_size]  \n",
    "        folds.append(l)   \n",
    "    return folds  \n",
    "\n",
    "x_train_folds = k_fold(5, x_train)\n",
    "y_train_folds = k_fold(5, y_train) \n",
    "letter_train_folds = k_fold(5,train_letters_numeric)\n",
    "\n",
    "for t in range(5):  \n",
    "    print(\"************ Fold {} training ************\".format(t+1)) \n",
    "    cur_val_x = x_train_folds[t] \n",
    "    cur_val_y = y_train_folds[t] \n",
    "    cur_val_letter = letter_train_folds[t]\n",
    "    train_folds_x = x_train_folds[0:t] + x_train_folds[t+1:] \n",
    "    train_folds_y = y_train_folds[0:t] + y_train_folds[t+1:]\n",
    "    train_fold_letter = letter_train_folds[0:t] + letter_train_folds[t+1:]\n",
    "    cur_train_x = [] \n",
    "    cur_train_y = [] \n",
    "    cur_letter = [] \n",
    "    for j in train_folds_x:  \n",
    "        for q in j:  \n",
    "            cur_train_x.append(q) \n",
    "    for j in train_folds_y:  \n",
    "        for q in j:  \n",
    "            cur_train_y.append(q)  \n",
    "    for j in train_fold_letter: \n",
    "        for q in j: \n",
    "            cur_letter.append(q) \n",
    "    cur_train_x = np.asarray(cur_train_x)\n",
    "    cur_train_y = np.asarray(cur_train_y)\n",
    "    cur_letter = np.asarray(cur_letter) \n",
    "    model_path = './storage/' + 'kfold' + str(t+1) + '/epoch_{epoch:03d}_val_{val_loss:.3f}_acc_{val_accuracy:.3f}.h5' \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.8)\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_accuracy',verbose=1,save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',patience=20)\n",
    "    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "    model = base_cnn_grade_4() \n",
    " \n",
    "    '''\n",
    "    history = model.fit_generator(\n",
    "        train_datagen.flow(cur_train_x, cur_train_y, batch_size = 32, shuffle = True),\n",
    "        epochs = 200, \n",
    "        steps_per_epoch = cur_train_x.shape[0]//32,\n",
    "        verbose = 1, \n",
    "        validation_data = (cur_val_x, cur_val_y),\n",
    "        callbacks=[learning_rate_reduction, checkpoint, early_stopping]\n",
    "    )\n",
    "    ''' \n",
    "    \n",
    "    history = model.fit([cur_train_x,cur_letter],\n",
    "                        cur_train_y,\n",
    "                       batch_size = 32,\n",
    "                       shuffle=True, \n",
    "                       validation_data = ([cur_val_x,cur_val_letter],cur_val_y),\n",
    "                       verbose = 1, \n",
    "                       epochs = 200,\n",
    "                       callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('./storage/kfold1/epoch_043_val_0.832_acc_0.817.h5')\n",
    "model2 = load_model('./storage/kfold2/epoch_024_val_0.754_acc_0.819.h5')\n",
    "model3 = load_model('./storage/kfold3/epoch_036_val_0.697_acc_0.826.h5')\n",
    "model4 = load_model('./storage/kfold4/epoch_032_val_0.696_acc_0.826.h5')\n",
    "model5 = load_model('./storage/kfold5/epoch_061_val_0.661_acc_0.833.h5')\n",
    "\n",
    "pred1 = model1.predict([x_test, test_letters_numeric])\n",
    "pred2 = model2.predict([x_test, test_letters_numeric])\n",
    "pred3 = model3.predict([x_test, test_letters_numeric])\n",
    "pred4 = model4.predict([x_test, test_letters_numeric])\n",
    "pred5 = model5.predict([x_test, test_letters_numeric])\n",
    "\n",
    "pred_avg = (pred1+pred2+pred3+pred4+pred5)/5.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 6, ..., 6, 1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_arr = [] \n",
    "for pred in pred_avg: \n",
    "    result_arr.append(np.argmax(pred))\n",
    "result_arr = np.asarray(result_arr)\n",
    "result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  digit\n",
       "0  2049      6\n",
       "1  2050      9\n",
       "2  2051      6\n",
       "3  2052      0\n",
       "4  2053      3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['digit'] = result_arr\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./storage/inception_5_fold_avg_no_generator.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
