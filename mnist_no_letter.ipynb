{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# environment: Paperspace Quadro P6000 GPU  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras # run pip install keras==2.3 beforehand for compatability \n",
    "from tensorflow.keras import Input, Model \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import random \n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import shuffle # shuffle dataset before splitting into folds \n",
    "from scipy.ndimage.filters import gaussian_filter # for elastic distortion \n",
    "from scipy.ndimage.interpolation import map_coordinates # for elastic distortion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in file and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './storage/modified_mnist_dataset/train.csv'  \n",
    "test_path = './storage/modified_mnist_dataset/test.csv' \n",
    "submission_path = './storage/modified_mnist_dataset/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path) \n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types of digit and letter columns to categorical \n",
    "#train.iloc[:,1] = pd.Categorical(train.iloc[:,1])\n",
    "#train.iloc[:,2] = pd.Categorical(train.iloc[:,2]) \n",
    "#test.iloc[:,1] = pd.Categorical(test.iloc[:,1])\n",
    "\n",
    "# define and re-format train and test data \n",
    "x_train = train.iloc[:,3:].values.reshape(-1,28,28,1).astype(np.float32) \n",
    "y_train = train.iloc[:,1].values\n",
    "train_letters = train.iloc[:,2].values\n",
    "\n",
    "x_test = test.iloc[:,2:].values.reshape(-1,28,28,1).astype(np.float32)  \n",
    "test_letters = test.iloc[:,1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 28, 28, 1), (2048,), (20480, 28, 28, 1), (2048, 26), (20480, 26))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letters_numeric = [] \n",
    "test_letters_numeric = [] \n",
    "for letter in train_letters: \n",
    "    train_letters_numeric.append(ord(letter) - ord(\"A\"))\n",
    "for letter in test_letters: \n",
    "    test_letters_numeric.append(ord(letter) - ord(\"A\")) \n",
    "    \n",
    "train_letters_numeric = np.asarray(train_letters_numeric) \n",
    "test_letters_numeric = np.asarray(test_letters_numeric) \n",
    "\n",
    "train_letters_numeric = to_categorical(train_letters_numeric, num_classes = 26) \n",
    "test_letters_numeric = to_categorical(test_letters_numeric, num_classes = 26)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, train_letters_numeric.shape, test_letters_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max scaling \n",
    "x_train /= 255.0 \n",
    "x_test /= 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rotations \n",
    "x_train_rotated = [] \n",
    "for x_data in x_train:\n",
    "    rotated_img = rotate(x_data, angle = random.randint(10,40))\n",
    "    x_train_rotated.append(rotated_img) \n",
    "x_train_rotated = np.asarray(x_train_rotated) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply clockwise rotations \n",
    "x_train_rotated_2 = [] \n",
    "for x_data in x_train: \n",
    "    rotated_img = rotate(x_data, angle = -random.randint(10,40)) \n",
    "    x_train_rotated_2.append(rotated_img)\n",
    "x_train_rotated_2 = np.asarray(x_train_rotated_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise \n",
    "x_noised = [] \n",
    "for x_data in x_train: \n",
    "    noised_img = random_noise(x_data) \n",
    "    x_noised.append(noised_img)\n",
    "x_noised = np.asarray(x_noised) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gaussian blur \n",
    "x_blurred = [] \n",
    "for x_data in x_train:\n",
    "    kernel_size = random.choice([3,5,9]) \n",
    "    blurred = cv2.GaussianBlur(x_data, (kernel_size, kernel_size), 0) \n",
    "    x_blurred.append(blurred)\n",
    "x_blurred = np.asarray(x_blurred)\n",
    "x_blurred = x_blurred.reshape(-1,28,28,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift image \n",
    "x_shifted = [] \n",
    "for x_data in x_train: \n",
    "    dx = random.choice([-2,-1,1,2])\n",
    "    dy = random.choice([-2,-1,1,2])\n",
    "    transform = AffineTransform(translation = (dx,dy))\n",
    "    warp_img = warp(x_data, transform, mode = \"wrap\")\n",
    "    x_shifted.append(warp_img) \n",
    "x_shifted = np.asarray(x_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply brightness modifications \n",
    "x_brightness = [] \n",
    "for x_data in x_train: \n",
    "    brightness = 0.5\n",
    "    alpha = 1.0 + random.uniform(-brightness, brightness) \n",
    "    brightness_modified = x_data * alpha \n",
    "    x_brightness.append(brightness_modified) \n",
    "\n",
    "x_brightness = np.asarray(x_brightness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply zca whitening \n",
    "def zca_whitening(sample): \n",
    "    sample = sample - sample.mean(axis=0)\n",
    "    cov = np.cov(sample, rowvar = False)\n",
    "    U,S,V = np.linalg.svd(cov) \n",
    "    epsilon = 0.1\n",
    "    X_ZCA = U.dot(np.diag(1.0/np.sqrt(S + epsilon))).dot(U.T).dot(sample.T).T\n",
    "    X_ZCA_rescaled = (X_ZCA - X_ZCA.min()) / (X_ZCA.max() - X_ZCA.min())\n",
    "    X_ZCA_rescaled = X_ZCA_rescaled.reshape((28,28,1)) \n",
    "    return X_ZCA_rescaled \n",
    "\n",
    "x_zca_whitened = [] \n",
    "for x_data in x_train: \n",
    "    zca_whitened = zca_whitening(x_data.reshape((28,28))) \n",
    "    x_zca_whitened.append(zca_whitened) \n",
    "    \n",
    "x_zca_whitened = np.asarray(x_zca_whitened) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random cropping (zooming effect)\n",
    "def random_crop(img): \n",
    "    img = img.copy() \n",
    "    size = random.randint(22,24) # this seems to be a good balance, since our image size is 28 by 28\n",
    "    crop_size = (size,size)\n",
    "    w,h = img.shape[:2]\n",
    "    x,y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
    "    img = img[y:y+crop_size[0], x:x+crop_size[1]] \n",
    "    return img \n",
    "\n",
    "x_random_crop = []\n",
    "for x_data in x_train: \n",
    "    cropped = random_crop(x_data) \n",
    "    cropped = resize(cropped, (28,28,1))\n",
    "    x_random_crop.append(cropped)\n",
    "\n",
    "x_random_crop = np.asarray(x_random_crop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add elastic distortions \n",
    "# from https://www.kaggle.com/babbler/mnist-data-augmentation-with-elastic-distortion\n",
    "def elastic_transform(image, alpha_range, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "       \n",
    "   # Arguments\n",
    "       image: Numpy array with shape (height, width, channels). \n",
    "       alpha_range: Float for fixed value or [lower, upper] for random value from uniform distribution.\n",
    "           Controls intensity of deformation.\n",
    "       sigma: Float, sigma of gaussian filter that smooths the displacement fields.\n",
    "       random_state: `numpy.random.RandomState` object for generating displacement fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "        \n",
    "    if np.isscalar(alpha_range):\n",
    "        alpha = alpha_range\n",
    "    else:\n",
    "        alpha = np.random.uniform(low=alpha_range[0], high=alpha_range[1])\n",
    "    \n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "    indices = np.reshape(x+dx, (-1, 1)), np.reshape(y+dy, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
    "\n",
    "x_elastic_distort = [] \n",
    "for x_data in x_train: \n",
    "    distorted = elastic_transform(x_data, [8,10], 3) \n",
    "    x_elastic_distort.append(distorted) \n",
    "    \n",
    "x_elastic_distort = np.asarray(x_elastic_distort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18432, 28, 28, 1), (18432,), (18432, 26))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating augmented data to the original \n",
    "x_train = np.concatenate((x_train, x_train_rotated, x_train_rotated_2, x_noised, x_blurred, x_shifted, x_brightness, x_zca_whitened, x_random_crop), axis = 0) \n",
    "y_train = np.concatenate((y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train, y_train), axis = 0) \n",
    "train_letters_numeric = np.concatenate((train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric, train_letters_numeric), axis = 0)\n",
    "\n",
    "x_train.shape, y_train.shape, train_letters_numeric.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test data generators \n",
    "# this \"replaces\" the train data. It does not add to it \n",
    "# I am not using this for now. I am directly adding augmented data \n",
    "train_datagen = ImageDataGenerator(width_shift_range = 0.1, \n",
    "                                  height_shift_range = 0.1, \n",
    "                                  shear_range = 0.1,\n",
    "                                  zoom_range = 0.1,\n",
    "                                  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses skip connections and also adds information from both MaxPooling2D and AveragePooling2D \n",
    "def conv2d_block(input_layer, n_filters, kernel):\n",
    "    conv1 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1) \n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv3 = Conv2D(n_filters, kernel, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2) \n",
    "    conv3 = Add()([conv3, conv1])   \n",
    "    conv3 = BatchNormalization()(conv3) \n",
    "    maxpool = MaxPooling2D((2,2))(conv3) \n",
    "    avgpool = AveragePooling2D((2,2))(conv3)\n",
    "    ret = Add()([maxpool,avgpool]) \n",
    "    return ret \n",
    "\n",
    "# trying grade 7 without letter input \n",
    "def base_cnn(): \n",
    "    inputs = Input((28,28,1))  \n",
    "    bn = BatchNormalization()(inputs)  \n",
    "    # 28x28 -> 14x14 \n",
    "    conv1 = conv2d_block(bn, 32, 7) \n",
    "    conv2 = conv2d_block(bn, 32, 5) \n",
    "    conv3 = conv2d_block(bn, 32, 3) \n",
    "    conv4 = conv2d_block(bn, 32, 1) \n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4]) \n",
    "    conv = BatchNormalization()(conv) \n",
    "    \n",
    "    # 14x14 -> 7x7 \n",
    "    conv1 = conv2d_block(conv, 64, 7) \n",
    "    conv2 = conv2d_block(conv, 64, 5) \n",
    "    conv3 = conv2d_block(conv, 64, 3) \n",
    "    conv4 = conv2d_block(conv, 64, 1) \n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4]) \n",
    "    conv = BatchNormalization()(conv) \n",
    "    \n",
    "    # 7x7 -> 3x3 \n",
    "    conv1 = conv2d_block(conv, 128, 7)\n",
    "    conv2 = conv2d_block(conv, 128, 5) \n",
    "    conv3 = conv2d_block(conv, 128, 3)\n",
    "    conv4 = conv2d_block(conv, 128, 1) \n",
    "    conv = Concatenate()([conv1,conv2,conv3,conv4]) \n",
    "    conv = BatchNormalization()(conv) \n",
    "    \n",
    "    # 3x3 -> 1x1 \n",
    "    conv1 = conv2d_block(conv, 256, 3) \n",
    "    conv2 = conv2d_block(conv, 256, 1) \n",
    "    conv = Concatenate()([conv1,conv2]) \n",
    "    conv = BatchNormalization()(conv) \n",
    "    \n",
    "    # flatten \n",
    "    outputs = Flatten()(conv) \n",
    "    \n",
    "    # dense resnet-layers\n",
    "    outputs = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(outputs) \n",
    "    outputs = BatchNormalization()(outputs) \n",
    "    res = outputs \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    \n",
    "    outputs = Dense(512, activation = 'relu', kernel_initializer = 'he_normal')(outputs) \n",
    "    outputs = Add()([res, outputs]) \n",
    "    outputs = BatchNormalization()(outputs) \n",
    "    outputs = Dropout(0.4)(outputs) \n",
    "    \n",
    "    # produce output and create tf map \n",
    "    outputs = Dense(10, activation = 'softmax')(outputs)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model  \n",
    "\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Fold 1 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 2.1229 - accuracy: 0.3417\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47423, saving model to ./storage/mnist_test_2/kfold1/epoch_001_val_1.922_acc_0.474.h5\n",
      "16589/16589 [==============================] - 36s 2ms/sample - loss: 2.1232 - accuracy: 0.3416 - val_loss: 1.9216 - val_accuracy: 0.4742\n",
      "Epoch 2/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 1.0962 - accuracy: 0.6372\n",
      "Epoch 00002: val_accuracy improved from 0.47423 to 0.72653, saving model to ./storage/mnist_test_2/kfold1/epoch_002_val_0.816_acc_0.727.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.0960 - accuracy: 0.6373 - val_loss: 0.8160 - val_accuracy: 0.7265\n",
      "Epoch 3/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.7088 - accuracy: 0.7661\n",
      "Epoch 00003: val_accuracy improved from 0.72653 to 0.77971, saving model to ./storage/mnist_test_2/kfold1/epoch_003_val_0.661_acc_0.780.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7091 - accuracy: 0.7660 - val_loss: 0.6615 - val_accuracy: 0.7797\n",
      "Epoch 4/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.8256\n",
      "Epoch 00004: val_accuracy improved from 0.77971 to 0.82528, saving model to ./storage/mnist_test_2/kfold1/epoch_004_val_0.544_acc_0.825.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5298 - accuracy: 0.8253 - val_loss: 0.5440 - val_accuracy: 0.8253\n",
      "Epoch 5/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.4046 - accuracy: 0.8668\n",
      "Epoch 00005: val_accuracy improved from 0.82528 to 0.83831, saving model to ./storage/mnist_test_2/kfold1/epoch_005_val_0.505_acc_0.838.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.4048 - accuracy: 0.8667 - val_loss: 0.5047 - val_accuracy: 0.8383\n",
      "Epoch 6/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.8966\n",
      "Epoch 00006: val_accuracy improved from 0.83831 to 0.86978, saving model to ./storage/mnist_test_2/kfold1/epoch_006_val_0.398_acc_0.870.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3197 - accuracy: 0.8966 - val_loss: 0.3979 - val_accuracy: 0.8698\n",
      "Epoch 7/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9171\n",
      "Epoch 00007: val_accuracy improved from 0.86978 to 0.88171, saving model to ./storage/mnist_test_2/kfold1/epoch_007_val_0.396_acc_0.882.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2547 - accuracy: 0.9171 - val_loss: 0.3959 - val_accuracy: 0.8817\n",
      "Epoch 8/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9315\n",
      "Epoch 00008: val_accuracy improved from 0.88171 to 0.89474, saving model to ./storage/mnist_test_2/kfold1/epoch_008_val_0.349_acc_0.895.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2069 - accuracy: 0.9315 - val_loss: 0.3493 - val_accuracy: 0.8947\n",
      "Epoch 9/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9407\n",
      "Epoch 00009: val_accuracy did not improve from 0.89474\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1778 - accuracy: 0.9407 - val_loss: 0.4024 - val_accuracy: 0.8844\n",
      "Epoch 10/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9515\n",
      "Epoch 00010: val_accuracy did not improve from 0.89474\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1520 - accuracy: 0.9515 - val_loss: 0.4598 - val_accuracy: 0.8714\n",
      "Epoch 11/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9567\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.89474\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1363 - accuracy: 0.9566 - val_loss: 0.3856 - val_accuracy: 0.8920\n",
      "Epoch 12/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9738\n",
      "Epoch 00012: val_accuracy improved from 0.89474 to 0.90884, saving model to ./storage/mnist_test_2/kfold1/epoch_012_val_0.327_acc_0.909.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0823 - accuracy: 0.9738 - val_loss: 0.3269 - val_accuracy: 0.9088\n",
      "Epoch 13/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9762\n",
      "Epoch 00013: val_accuracy improved from 0.90884 to 0.90993, saving model to ./storage/mnist_test_2/kfold1/epoch_013_val_0.305_acc_0.910.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0783 - accuracy: 0.9759 - val_loss: 0.3052 - val_accuracy: 0.9099\n",
      "Epoch 14/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9758\n",
      "Epoch 00014: val_accuracy improved from 0.90993 to 0.91698, saving model to ./storage/mnist_test_2/kfold1/epoch_014_val_0.314_acc_0.917.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0783 - accuracy: 0.9757 - val_loss: 0.3138 - val_accuracy: 0.9170\n",
      "Epoch 15/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9754\n",
      "Epoch 00015: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0772 - accuracy: 0.9754 - val_loss: 0.3801 - val_accuracy: 0.8991\n",
      "Epoch 16/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9780\n",
      "Epoch 00016: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0708 - accuracy: 0.9780 - val_loss: 0.3739 - val_accuracy: 0.9121\n",
      "Epoch 17/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9824\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0573 - accuracy: 0.9825 - val_loss: 0.3774 - val_accuracy: 0.9067\n",
      "Epoch 18/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0372 - accuracy: 0.9880\n",
      "Epoch 00018: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0371 - accuracy: 0.9881 - val_loss: 0.3707 - val_accuracy: 0.9154\n",
      "Epoch 19/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9888\n",
      "Epoch 00019: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0354 - accuracy: 0.9888 - val_loss: 0.3691 - val_accuracy: 0.9034\n",
      "Epoch 20/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9869\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.3973 - val_accuracy: 0.9132\n",
      "Epoch 21/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9933\n",
      "Epoch 00021: val_accuracy did not improve from 0.91698\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.3756 - val_accuracy: 0.9143\n",
      "Epoch 22/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9950\n",
      "Epoch 00022: val_accuracy improved from 0.91698 to 0.92295, saving model to ./storage/mnist_test_2/kfold1/epoch_022_val_0.342_acc_0.923.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.3419 - val_accuracy: 0.9230\n",
      "Epoch 23/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9938\n",
      "Epoch 00023: val_accuracy did not improve from 0.92295\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.3905 - val_accuracy: 0.9197\n",
      "Epoch 24/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9882\n",
      "Epoch 00024: val_accuracy improved from 0.92295 to 0.93001, saving model to ./storage/mnist_test_2/kfold1/epoch_024_val_0.304_acc_0.930.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.3045 - val_accuracy: 0.9300\n",
      "Epoch 25/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9943\n",
      "Epoch 00025: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.3552 - val_accuracy: 0.9235\n",
      "Epoch 26/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9936\n",
      "Epoch 00026: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.3493 - val_accuracy: 0.9278\n",
      "Epoch 27/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9919\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.4262 - val_accuracy: 0.9126\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9964\n",
      "Epoch 00028: val_accuracy improved from 0.93001 to 0.93272, saving model to ./storage/mnist_test_2/kfold1/epoch_028_val_0.336_acc_0.933.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.3360 - val_accuracy: 0.9327\n",
      "Epoch 29/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 00029: val_accuracy improved from 0.93272 to 0.93543, saving model to ./storage/mnist_test_2/kfold1/epoch_029_val_0.352_acc_0.935.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.3516 - val_accuracy: 0.9354\n",
      "Epoch 30/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 00030: val_accuracy improved from 0.93543 to 0.93652, saving model to ./storage/mnist_test_2/kfold1/epoch_030_val_0.338_acc_0.937.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.3381 - val_accuracy: 0.9365\n",
      "Epoch 31/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9963\n",
      "Epoch 00031: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.4185 - val_accuracy: 0.9192\n",
      "Epoch 32/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9943\n",
      "Epoch 00032: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.3720 - val_accuracy: 0.9289\n",
      "Epoch 33/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.3913 - val_accuracy: 0.9246\n",
      "Epoch 34/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 00034: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.3800 - val_accuracy: 0.9267\n",
      "Epoch 35/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 00035: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.3568 - val_accuracy: 0.9316\n",
      "Epoch 36/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.3757 - val_accuracy: 0.9354\n",
      "Epoch 37/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 00037: val_accuracy did not improve from 0.93652\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.3441 - val_accuracy: 0.9333\n",
      "Epoch 38/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 00038: val_accuracy improved from 0.93652 to 0.93977, saving model to ./storage/mnist_test_2/kfold1/epoch_038_val_0.327_acc_0.940.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.3274 - val_accuracy: 0.9398\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 00039: val_accuracy did not improve from 0.93977\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.3535 - val_accuracy: 0.9371\n",
      "Epoch 40/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 00040: val_accuracy improved from 0.93977 to 0.94628, saving model to ./storage/mnist_test_2/kfold1/epoch_040_val_0.321_acc_0.946.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.3212 - val_accuracy: 0.9463\n",
      "Epoch 41/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 00041: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.4056 - val_accuracy: 0.9278\n",
      "Epoch 42/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 00042: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.4257 - val_accuracy: 0.9289\n",
      "Epoch 43/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.3501 - val_accuracy: 0.9365\n",
      "Epoch 44/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00044: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.3424 - val_accuracy: 0.9392\n",
      "Epoch 45/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 00045: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.3549 - val_accuracy: 0.9414\n",
      "Epoch 46/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3634 - val_accuracy: 0.9409\n",
      "Epoch 47/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00047: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3685 - val_accuracy: 0.9376\n",
      "Epoch 48/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00048: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3756 - val_accuracy: 0.9381\n",
      "Epoch 49/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.3582 - val_accuracy: 0.9398\n",
      "Epoch 50/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 7.2347e-04 - accuracy: 0.9998\n",
      "Epoch 00050: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 7.2348e-04 - accuracy: 0.9998 - val_loss: 0.3663 - val_accuracy: 0.9430\n",
      "************ Fold 2 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 2.1177 - accuracy: 0.3418\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48454, saving model to ./storage/mnist_test_2/kfold2/epoch_001_val_1.690_acc_0.485.h5\n",
      "16589/16589 [==============================] - 35s 2ms/sample - loss: 2.1177 - accuracy: 0.3419 - val_loss: 1.6900 - val_accuracy: 0.4845\n",
      "Epoch 2/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 1.0958 - accuracy: 0.6350\n",
      "Epoch 00002: val_accuracy improved from 0.48454 to 0.71514, saving model to ./storage/mnist_test_2/kfold2/epoch_002_val_0.846_acc_0.715.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.0957 - accuracy: 0.6350 - val_loss: 0.8456 - val_accuracy: 0.7151\n",
      "Epoch 3/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.7270 - accuracy: 0.7574\n",
      "Epoch 00003: val_accuracy improved from 0.71514 to 0.76126, saving model to ./storage/mnist_test_2/kfold2/epoch_003_val_0.736_acc_0.761.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.7263 - accuracy: 0.7576 - val_loss: 0.7364 - val_accuracy: 0.7613\n",
      "Epoch 4/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.5196 - accuracy: 0.8289\n",
      "Epoch 00004: val_accuracy improved from 0.76126 to 0.81769, saving model to ./storage/mnist_test_2/kfold2/epoch_004_val_0.555_acc_0.818.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5195 - accuracy: 0.8289 - val_loss: 0.5546 - val_accuracy: 0.8177\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.3975 - accuracy: 0.8703\n",
      "Epoch 00005: val_accuracy improved from 0.81769 to 0.83831, saving model to ./storage/mnist_test_2/kfold2/epoch_005_val_0.473_acc_0.838.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3978 - accuracy: 0.8703 - val_loss: 0.4728 - val_accuracy: 0.8383\n",
      "Epoch 6/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.8973\n",
      "Epoch 00006: val_accuracy improved from 0.83831 to 0.84102, saving model to ./storage/mnist_test_2/kfold2/epoch_006_val_0.530_acc_0.841.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3143 - accuracy: 0.8974 - val_loss: 0.5303 - val_accuracy: 0.8410\n",
      "Epoch 7/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9125\n",
      "Epoch 00007: val_accuracy improved from 0.84102 to 0.87737, saving model to ./storage/mnist_test_2/kfold2/epoch_007_val_0.417_acc_0.877.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2654 - accuracy: 0.9124 - val_loss: 0.4168 - val_accuracy: 0.8774\n",
      "Epoch 8/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9315\n",
      "Epoch 00008: val_accuracy did not improve from 0.87737\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.2035 - accuracy: 0.9315 - val_loss: 0.4534 - val_accuracy: 0.8736\n",
      "Epoch 9/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1938 - accuracy: 0.9367\n",
      "Epoch 00009: val_accuracy did not improve from 0.87737\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1935 - accuracy: 0.9368 - val_loss: 0.4864 - val_accuracy: 0.8486\n",
      "Epoch 10/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9501\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87737\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1555 - accuracy: 0.9501 - val_loss: 0.5373 - val_accuracy: 0.8535\n",
      "Epoch 11/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9706\n",
      "Epoch 00011: val_accuracy improved from 0.87737 to 0.89474, saving model to ./storage/mnist_test_2/kfold2/epoch_011_val_0.416_acc_0.895.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0883 - accuracy: 0.9706 - val_loss: 0.4157 - val_accuracy: 0.8947\n",
      "Epoch 12/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0880 - accuracy: 0.9721\n",
      "Epoch 00012: val_accuracy improved from 0.89474 to 0.89854, saving model to ./storage/mnist_test_2/kfold2/epoch_012_val_0.416_acc_0.899.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0882 - accuracy: 0.9720 - val_loss: 0.4164 - val_accuracy: 0.8985\n",
      "Epoch 13/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9736\n",
      "Epoch 00013: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0815 - accuracy: 0.9736 - val_loss: 0.4389 - val_accuracy: 0.8893\n",
      "Epoch 14/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9759\n",
      "Epoch 00014: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0738 - accuracy: 0.9759 - val_loss: 0.4622 - val_accuracy: 0.8937\n",
      "Epoch 15/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9753\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0795 - accuracy: 0.9752 - val_loss: 0.4836 - val_accuracy: 0.8828\n",
      "Epoch 16/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9876\n",
      "Epoch 00016: val_accuracy improved from 0.89854 to 0.90830, saving model to ./storage/mnist_test_2/kfold2/epoch_016_val_0.400_acc_0.908.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.4000 - val_accuracy: 0.9083\n",
      "Epoch 17/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9889\n",
      "Epoch 00017: val_accuracy did not improve from 0.90830\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.4479 - val_accuracy: 0.8985\n",
      "Epoch 18/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9846\n",
      "Epoch 00018: val_accuracy did not improve from 0.90830\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0483 - accuracy: 0.9846 - val_loss: 0.4298 - val_accuracy: 0.9007\n",
      "Epoch 19/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9838\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.90830\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.4541 - val_accuracy: 0.8980\n",
      "Epoch 20/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9903\n",
      "Epoch 00020: val_accuracy did not improve from 0.90830\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.4286 - val_accuracy: 0.9072\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 00021: val_accuracy improved from 0.90830 to 0.91861, saving model to ./storage/mnist_test_2/kfold2/epoch_021_val_0.407_acc_0.919.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.4072 - val_accuracy: 0.9186\n",
      "Epoch 22/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9918\n",
      "Epoch 00022: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.4441 - val_accuracy: 0.9132\n",
      "Epoch 23/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9910\n",
      "Epoch 00023: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.4960 - val_accuracy: 0.8985\n",
      "Epoch 24/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.9932\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.5109 - val_accuracy: 0.9018\n",
      "Epoch 25/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 00025: val_accuracy improved from 0.91861 to 0.91915, saving model to ./storage/mnist_test_2/kfold2/epoch_025_val_0.365_acc_0.919.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.3650 - val_accuracy: 0.9192\n",
      "Epoch 26/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9955\n",
      "Epoch 00026: val_accuracy did not improve from 0.91915\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.4178 - val_accuracy: 0.9170\n",
      "Epoch 27/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9966\n",
      "Epoch 00027: val_accuracy improved from 0.91915 to 0.92295, saving model to ./storage/mnist_test_2/kfold2/epoch_027_val_0.417_acc_0.923.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.4171 - val_accuracy: 0.9230\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9961\n",
      "Epoch 00028: val_accuracy did not improve from 0.92295\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.4200 - val_accuracy: 0.9181\n",
      "Epoch 29/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9951\n",
      "Epoch 00029: val_accuracy did not improve from 0.92295\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.4350 - val_accuracy: 0.9110\n",
      "Epoch 30/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9934\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92295\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0228 - accuracy: 0.9934 - val_loss: 0.4857 - val_accuracy: 0.9137\n",
      "Epoch 31/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 00031: val_accuracy did not improve from 0.92295\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.4289 - val_accuracy: 0.9186\n",
      "Epoch 32/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9985\n",
      "Epoch 00032: val_accuracy improved from 0.92295 to 0.92349, saving model to ./storage/mnist_test_2/kfold2/epoch_032_val_0.427_acc_0.923.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.4271 - val_accuracy: 0.9235\n",
      "Epoch 33/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9972\n",
      "Epoch 00033: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.4723 - val_accuracy: 0.9121\n",
      "Epoch 34/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9976\n",
      "Epoch 00034: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.4282 - val_accuracy: 0.9224\n",
      "Epoch 35/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.4522 - val_accuracy: 0.9126\n",
      "Epoch 36/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00036: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.4453 - val_accuracy: 0.9137\n",
      "Epoch 37/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 00037: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4314 - val_accuracy: 0.9192\n",
      "Epoch 38/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.4652 - val_accuracy: 0.9219\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00039: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.4294 - val_accuracy: 0.9192\n",
      "Epoch 40/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 00040: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.4423 - val_accuracy: 0.9213\n",
      "Epoch 41/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.4708 - val_accuracy: 0.9202\n",
      "Epoch 42/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 00042: val_accuracy did not improve from 0.92349\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.4384 - val_accuracy: 0.9192\n",
      "************ Fold 3 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 2.1303 - accuracy: 0.3481\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.40423, saving model to ./storage/mnist_test_2/kfold3/epoch_001_val_2.371_acc_0.404.h5\n",
      "16589/16589 [==============================] - 35s 2ms/sample - loss: 2.1280 - accuracy: 0.3487 - val_loss: 2.3711 - val_accuracy: 0.4042\n",
      "Epoch 2/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 1.1388 - accuracy: 0.6293\n",
      "Epoch 00002: val_accuracy improved from 0.40423 to 0.71514, saving model to ./storage/mnist_test_2/kfold3/epoch_002_val_0.843_acc_0.715.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.1382 - accuracy: 0.6295 - val_loss: 0.8432 - val_accuracy: 0.7151\n",
      "Epoch 3/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.7171 - accuracy: 0.7653\n",
      "Epoch 00003: val_accuracy improved from 0.71514 to 0.78351, saving model to ./storage/mnist_test_2/kfold3/epoch_003_val_0.696_acc_0.784.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7174 - accuracy: 0.7652 - val_loss: 0.6962 - val_accuracy: 0.7835\n",
      "Epoch 4/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.5171 - accuracy: 0.8320\n",
      "Epoch 00004: val_accuracy improved from 0.78351 to 0.83180, saving model to ./storage/mnist_test_2/kfold3/epoch_004_val_0.554_acc_0.832.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5177 - accuracy: 0.8318 - val_loss: 0.5535 - val_accuracy: 0.8318\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.4023 - accuracy: 0.8706\n",
      "Epoch 00005: val_accuracy did not improve from 0.83180\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.4022 - accuracy: 0.8706 - val_loss: 0.5470 - val_accuracy: 0.8318\n",
      "Epoch 6/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.9021\n",
      "Epoch 00006: val_accuracy improved from 0.83180 to 0.85947, saving model to ./storage/mnist_test_2/kfold3/epoch_006_val_0.442_acc_0.859.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3080 - accuracy: 0.9021 - val_loss: 0.4418 - val_accuracy: 0.8595\n",
      "Epoch 7/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9159\n",
      "Epoch 00007: val_accuracy improved from 0.85947 to 0.88551, saving model to ./storage/mnist_test_2/kfold3/epoch_007_val_0.399_acc_0.886.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2570 - accuracy: 0.9161 - val_loss: 0.3986 - val_accuracy: 0.8855\n",
      "Epoch 8/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2120 - accuracy: 0.9316\n",
      "Epoch 00008: val_accuracy did not improve from 0.88551\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.2119 - accuracy: 0.9316 - val_loss: 0.4364 - val_accuracy: 0.8774\n",
      "Epoch 9/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9420\n",
      "Epoch 00009: val_accuracy improved from 0.88551 to 0.88606, saving model to ./storage/mnist_test_2/kfold3/epoch_009_val_0.388_acc_0.886.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1729 - accuracy: 0.9418 - val_loss: 0.3878 - val_accuracy: 0.8861\n",
      "Epoch 10/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9453\n",
      "Epoch 00010: val_accuracy did not improve from 0.88606\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1667 - accuracy: 0.9453 - val_loss: 0.4306 - val_accuracy: 0.8828\n",
      "Epoch 11/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9552\n",
      "Epoch 00011: val_accuracy improved from 0.88606 to 0.89908, saving model to ./storage/mnist_test_2/kfold3/epoch_011_val_0.390_acc_0.899.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1390 - accuracy: 0.9552 - val_loss: 0.3897 - val_accuracy: 0.8991\n",
      "Epoch 12/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9610\n",
      "Epoch 00012: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1205 - accuracy: 0.9611 - val_loss: 0.4378 - val_accuracy: 0.8877\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9651\n",
      "Epoch 00013: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1080 - accuracy: 0.9650 - val_loss: 0.4283 - val_accuracy: 0.8915\n",
      "Epoch 14/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9691\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1009 - accuracy: 0.9691 - val_loss: 0.4581 - val_accuracy: 0.8888\n",
      "Epoch 15/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9843\n",
      "Epoch 00015: val_accuracy improved from 0.89908 to 0.90396, saving model to ./storage/mnist_test_2/kfold3/epoch_015_val_0.429_acc_0.904.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0477 - accuracy: 0.9843 - val_loss: 0.4290 - val_accuracy: 0.9040\n",
      "Epoch 16/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.9851\n",
      "Epoch 00016: val_accuracy did not improve from 0.90396\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0555 - accuracy: 0.9851 - val_loss: 0.5074 - val_accuracy: 0.8931\n",
      "Epoch 17/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9817\n",
      "Epoch 00017: val_accuracy improved from 0.90396 to 0.90830, saving model to ./storage/mnist_test_2/kfold3/epoch_017_val_0.389_acc_0.908.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.3890 - val_accuracy: 0.9083\n",
      "Epoch 18/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9840\n",
      "Epoch 00018: val_accuracy improved from 0.90830 to 0.91319, saving model to ./storage/mnist_test_2/kfold3/epoch_018_val_0.386_acc_0.913.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0528 - accuracy: 0.9840 - val_loss: 0.3855 - val_accuracy: 0.9132\n",
      "Epoch 19/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9868\n",
      "Epoch 00019: val_accuracy did not improve from 0.91319\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0428 - accuracy: 0.9867 - val_loss: 0.4097 - val_accuracy: 0.9105\n",
      "Epoch 20/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9834\n",
      "Epoch 00020: val_accuracy did not improve from 0.91319\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0550 - accuracy: 0.9833 - val_loss: 0.4308 - val_accuracy: 0.9078\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9838\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91319\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0550 - accuracy: 0.9838 - val_loss: 0.3800 - val_accuracy: 0.9072\n",
      "Epoch 22/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 00022: val_accuracy improved from 0.91319 to 0.92132, saving model to ./storage/mnist_test_2/kfold3/epoch_022_val_0.381_acc_0.921.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.3808 - val_accuracy: 0.9213\n",
      "Epoch 23/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9920\n",
      "Epoch 00023: val_accuracy did not improve from 0.92132\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.4089 - val_accuracy: 0.9083\n",
      "Epoch 24/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9910\n",
      "Epoch 00024: val_accuracy did not improve from 0.92132\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0307 - accuracy: 0.9910 - val_loss: 0.3878 - val_accuracy: 0.9192\n",
      "Epoch 25/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9918\n",
      "Epoch 00025: val_accuracy improved from 0.92132 to 0.92241, saving model to ./storage/mnist_test_2/kfold3/epoch_025_val_0.399_acc_0.922.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.3987 - val_accuracy: 0.9224\n",
      "Epoch 26/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9895\n",
      "Epoch 00026: val_accuracy did not improve from 0.92241\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.4108 - val_accuracy: 0.9154\n",
      "Epoch 27/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9923\n",
      "Epoch 00027: val_accuracy did not improve from 0.92241\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.3879 - val_accuracy: 0.9202\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9943\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92241\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.4425 - val_accuracy: 0.9170\n",
      "Epoch 29/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 00029: val_accuracy improved from 0.92241 to 0.92946, saving model to ./storage/mnist_test_2/kfold3/epoch_029_val_0.358_acc_0.929.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.3584 - val_accuracy: 0.9295\n",
      "Epoch 30/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9966\n",
      "Epoch 00030: val_accuracy did not improve from 0.92946\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.3876 - val_accuracy: 0.9235\n",
      "Epoch 31/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9956\n",
      "Epoch 00031: val_accuracy did not improve from 0.92946\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3899 - val_accuracy: 0.9181\n",
      "Epoch 32/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9955\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92946\n",
      "16589/16589 [==============================] - 25s 2ms/sample - loss: 0.0186 - accuracy: 0.9955 - val_loss: 0.3917 - val_accuracy: 0.9213\n",
      "Epoch 33/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9960 ETA: 0s - loss: 0.0124 - accuracy\n",
      "Epoch 00033: val_accuracy improved from 0.92946 to 0.93055, saving model to ./storage/mnist_test_2/kfold3/epoch_033_val_0.348_acc_0.931.h5\n",
      "16589/16589 [==============================] - 27s 2ms/sample - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.3478 - val_accuracy: 0.9305\n",
      "Epoch 34/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9981\n",
      "Epoch 00034: val_accuracy did not improve from 0.93055\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.3728 - val_accuracy: 0.9289\n",
      "Epoch 35/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 00035: val_accuracy did not improve from 0.93055\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.4146 - val_accuracy: 0.9230\n",
      "Epoch 36/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9950\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93055\n",
      "16589/16589 [==============================] - 26s 2ms/sample - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.3952 - val_accuracy: 0.9273\n",
      "Epoch 37/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 00037: val_accuracy improved from 0.93055 to 0.93706, saving model to ./storage/mnist_test_2/kfold3/epoch_037_val_0.333_acc_0.937.h5\n",
      "16589/16589 [==============================] - 25s 2ms/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.3331 - val_accuracy: 0.9371\n",
      "Epoch 38/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00038: val_accuracy did not improve from 0.93706\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.4141 - val_accuracy: 0.9224\n",
      "Epoch 39/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9981\n",
      "Epoch 00039: val_accuracy did not improve from 0.93706\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.3611 - val_accuracy: 0.9343\n",
      "Epoch 40/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9978\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.93706\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.3505 - val_accuracy: 0.9349\n",
      "Epoch 41/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00041: val_accuracy improved from 0.93706 to 0.93760, saving model to ./storage/mnist_test_2/kfold3/epoch_041_val_0.334_acc_0.938.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.3335 - val_accuracy: 0.9376\n",
      "Epoch 42/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 00042: val_accuracy did not improve from 0.93760\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3636 - val_accuracy: 0.9333\n",
      "Epoch 43/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00043: val_accuracy did not improve from 0.93760\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.3787 - val_accuracy: 0.9300\n",
      "Epoch 44/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00044: val_accuracy improved from 0.93760 to 0.94140, saving model to ./storage/mnist_test_2/kfold3/epoch_044_val_0.335_acc_0.941.h5\n",
      "16589/16589 [==============================] - 25s 2ms/sample - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.3345 - val_accuracy: 0.9414\n",
      "Epoch 45/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 00045: val_accuracy did not improve from 0.94140\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.3499 - val_accuracy: 0.9409\n",
      "Epoch 46/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 00046: val_accuracy improved from 0.94140 to 0.94357, saving model to ./storage/mnist_test_2/kfold3/epoch_046_val_0.342_acc_0.944.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.3422 - val_accuracy: 0.9436\n",
      "Epoch 47/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00047: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4695 - val_accuracy: 0.9322\n",
      "Epoch 48/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9977\n",
      "Epoch 00048: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.4109 - val_accuracy: 0.9278\n",
      "Epoch 49/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.3896 - val_accuracy: 0.9305\n",
      "Epoch 50/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00050: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.3771 - val_accuracy: 0.9311\n",
      "Epoch 51/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00051: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.3783 - val_accuracy: 0.9316\n",
      "Epoch 52/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.4158 - val_accuracy: 0.9338\n",
      "Epoch 53/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 8.0745e-04 - accuracy: 0.9998\n",
      "Epoch 00053: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 8.0576e-04 - accuracy: 0.9998 - val_loss: 0.3795 - val_accuracy: 0.9333\n",
      "Epoch 54/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 4.1137e-04 - accuracy: 0.9998\n",
      "Epoch 00054: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 4.1045e-04 - accuracy: 0.9998 - val_loss: 0.3858 - val_accuracy: 0.9365\n",
      "Epoch 55/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.4403 - val_accuracy: 0.9284\n",
      "Epoch 56/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00056: val_accuracy did not improve from 0.94357\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3676 - val_accuracy: 0.9387\n",
      "************ Fold 4 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 2.1319 - accuracy: 0.3442\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48454, saving model to ./storage/mnist_test_2/kfold4/epoch_001_val_1.513_acc_0.485.h5\n",
      "16589/16589 [==============================] - 35s 2ms/sample - loss: 2.1297 - accuracy: 0.3447 - val_loss: 1.5131 - val_accuracy: 0.4845\n",
      "Epoch 2/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 1.1064 - accuracy: 0.6318\n",
      "Epoch 00002: val_accuracy improved from 0.48454 to 0.72219, saving model to ./storage/mnist_test_2/kfold4/epoch_002_val_0.867_acc_0.722.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 1.1055 - accuracy: 0.6322 - val_loss: 0.8672 - val_accuracy: 0.7222\n",
      "Epoch 3/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.7269 - accuracy: 0.7661\n",
      "Epoch 00003: val_accuracy improved from 0.72219 to 0.78133, saving model to ./storage/mnist_test_2/kfold4/epoch_003_val_0.645_acc_0.781.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7268 - accuracy: 0.7662 - val_loss: 0.6454 - val_accuracy: 0.7813\n",
      "Epoch 4/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.5290 - accuracy: 0.8267\n",
      "Epoch 00004: val_accuracy improved from 0.78133 to 0.83939, saving model to ./storage/mnist_test_2/kfold4/epoch_004_val_0.482_acc_0.839.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.5287 - accuracy: 0.8268 - val_loss: 0.4815 - val_accuracy: 0.8394\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.4060 - accuracy: 0.8656\n",
      "Epoch 00005: val_accuracy improved from 0.83939 to 0.87303, saving model to ./storage/mnist_test_2/kfold4/epoch_005_val_0.417_acc_0.873.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.4059 - accuracy: 0.8656 - val_loss: 0.4173 - val_accuracy: 0.8730\n",
      "Epoch 6/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8929\n",
      "Epoch 00006: val_accuracy did not improve from 0.87303\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3241 - accuracy: 0.8929 - val_loss: 0.4114 - val_accuracy: 0.8611\n",
      "Epoch 7/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2516 - accuracy: 0.9177\n",
      "Epoch 00007: val_accuracy improved from 0.87303 to 0.89311, saving model to ./storage/mnist_test_2/kfold4/epoch_007_val_0.354_acc_0.893.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.2514 - accuracy: 0.9178 - val_loss: 0.3540 - val_accuracy: 0.8931\n",
      "Epoch 8/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9307\n",
      "Epoch 00008: val_accuracy did not improve from 0.89311\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2141 - accuracy: 0.9307 - val_loss: 0.4078 - val_accuracy: 0.8850\n",
      "Epoch 9/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9436\n",
      "Epoch 00009: val_accuracy improved from 0.89311 to 0.89908, saving model to ./storage/mnist_test_2/kfold4/epoch_009_val_0.347_acc_0.899.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1769 - accuracy: 0.9436 - val_loss: 0.3466 - val_accuracy: 0.8991\n",
      "Epoch 10/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1431 - accuracy: 0.9537\n",
      "Epoch 00010: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1434 - accuracy: 0.9536 - val_loss: 0.4203 - val_accuracy: 0.8736\n",
      "Epoch 11/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9564\n",
      "Epoch 00011: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1385 - accuracy: 0.9563 - val_loss: 0.4093 - val_accuracy: 0.8812\n",
      "Epoch 12/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9617\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1201 - accuracy: 0.9614 - val_loss: 0.3985 - val_accuracy: 0.8931\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9748\n",
      "Epoch 00013: val_accuracy improved from 0.89908 to 0.90613, saving model to ./storage/mnist_test_2/kfold4/epoch_013_val_0.361_acc_0.906.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0742 - accuracy: 0.9749 - val_loss: 0.3610 - val_accuracy: 0.9061\n",
      "Epoch 14/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9799\n",
      "Epoch 00014: val_accuracy improved from 0.90613 to 0.91373, saving model to ./storage/mnist_test_2/kfold4/epoch_014_val_0.364_acc_0.914.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0626 - accuracy: 0.9799 - val_loss: 0.3639 - val_accuracy: 0.9137\n",
      "Epoch 15/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9754\n",
      "Epoch 00015: val_accuracy did not improve from 0.91373\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0730 - accuracy: 0.9753 - val_loss: 0.3869 - val_accuracy: 0.9012\n",
      "Epoch 16/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9834\n",
      "Epoch 00016: val_accuracy did not improve from 0.91373\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.3858 - val_accuracy: 0.9023\n",
      "Epoch 17/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.9788\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91373\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0694 - accuracy: 0.9787 - val_loss: 0.5358 - val_accuracy: 0.8812\n",
      "Epoch 18/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9870\n",
      "Epoch 00018: val_accuracy did not improve from 0.91373\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.3639 - val_accuracy: 0.9121\n",
      "Epoch 19/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9886\n",
      "Epoch 00019: val_accuracy did not improve from 0.91373\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.3635 - val_accuracy: 0.9072\n",
      "Epoch 20/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9887\n",
      "Epoch 00020: val_accuracy improved from 0.91373 to 0.92132, saving model to ./storage/mnist_test_2/kfold4/epoch_020_val_0.360_acc_0.921.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.3602 - val_accuracy: 0.9213\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9913\n",
      "Epoch 00021: val_accuracy did not improve from 0.92132\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.3626 - val_accuracy: 0.9170\n",
      "Epoch 22/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9881\n",
      "Epoch 00022: val_accuracy improved from 0.92132 to 0.92784, saving model to ./storage/mnist_test_2/kfold4/epoch_022_val_0.357_acc_0.928.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.3570 - val_accuracy: 0.9278\n",
      "Epoch 23/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9894\n",
      "Epoch 00023: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.3724 - val_accuracy: 0.9186\n",
      "Epoch 24/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9884\n",
      "Epoch 00024: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.3765 - val_accuracy: 0.9192\n",
      "Epoch 25/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9905\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0323 - accuracy: 0.9905 - val_loss: 0.3272 - val_accuracy: 0.9240\n",
      "Epoch 26/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9966\n",
      "Epoch 00026: val_accuracy improved from 0.92784 to 0.93001, saving model to ./storage/mnist_test_2/kfold4/epoch_026_val_0.317_acc_0.930.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.3171 - val_accuracy: 0.9300\n",
      "Epoch 27/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9945\n",
      "Epoch 00027: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.3407 - val_accuracy: 0.9273\n",
      "Epoch 28/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9958\n",
      "Epoch 00028: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.3484 - val_accuracy: 0.9278\n",
      "Epoch 29/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9953\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.3923 - val_accuracy: 0.9192\n",
      "Epoch 30/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 00030: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.3534 - val_accuracy: 0.9267\n",
      "Epoch 31/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 00031: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.3616 - val_accuracy: 0.9300\n",
      "Epoch 32/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 00032: val_accuracy improved from 0.93001 to 0.94194, saving model to ./storage/mnist_test_2/kfold4/epoch_032_val_0.321_acc_0.942.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.3210 - val_accuracy: 0.9419\n",
      "Epoch 33/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 00033: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.4006 - val_accuracy: 0.9208\n",
      "Epoch 34/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9959\n",
      "Epoch 00034: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.4302 - val_accuracy: 0.9246\n",
      "Epoch 35/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.3748 - val_accuracy: 0.9230\n",
      "Epoch 36/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 00036: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.3342 - val_accuracy: 0.9360\n",
      "Epoch 37/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00037: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.3844 - val_accuracy: 0.9295\n",
      "Epoch 38/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.3289 - val_accuracy: 0.9305\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00039: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.3281 - val_accuracy: 0.9392\n",
      "Epoch 40/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 00040: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.3318 - val_accuracy: 0.9387\n",
      "Epoch 41/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.3217 - val_accuracy: 0.9387\n",
      "Epoch 42/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00042: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.3460 - val_accuracy: 0.9338\n",
      "************ Fold 5 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 2.1191 - accuracy: 0.3525\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.45252, saving model to ./storage/mnist_test_2/kfold5/epoch_001_val_1.765_acc_0.453.h5\n",
      "16589/16589 [==============================] - 34s 2ms/sample - loss: 2.1174 - accuracy: 0.3528 - val_loss: 1.7651 - val_accuracy: 0.4525\n",
      "Epoch 2/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 1.1123 - accuracy: 0.6301\n",
      "Epoch 00002: val_accuracy improved from 0.45252 to 0.72979, saving model to ./storage/mnist_test_2/kfold5/epoch_002_val_0.809_acc_0.730.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.1110 - accuracy: 0.6304 - val_loss: 0.8091 - val_accuracy: 0.7298\n",
      "Epoch 3/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.7027 - accuracy: 0.7674\n",
      "Epoch 00003: val_accuracy improved from 0.72979 to 0.80521, saving model to ./storage/mnist_test_2/kfold5/epoch_003_val_0.610_acc_0.805.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7026 - accuracy: 0.7674 - val_loss: 0.6100 - val_accuracy: 0.8052\n",
      "Epoch 4/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.5234 - accuracy: 0.8251\n",
      "Epoch 00004: val_accuracy improved from 0.80521 to 0.83342, saving model to ./storage/mnist_test_2/kfold5/epoch_004_val_0.507_acc_0.833.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5236 - accuracy: 0.8249 - val_loss: 0.5071 - val_accuracy: 0.8334\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.4147 - accuracy: 0.8663\n",
      "Epoch 00005: val_accuracy improved from 0.83342 to 0.83722, saving model to ./storage/mnist_test_2/kfold5/epoch_005_val_0.494_acc_0.837.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.4148 - accuracy: 0.8662 - val_loss: 0.4935 - val_accuracy: 0.8372\n",
      "Epoch 6/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.3149 - accuracy: 0.8989\n",
      "Epoch 00006: val_accuracy did not improve from 0.83722\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.3148 - accuracy: 0.8988 - val_loss: 0.5520 - val_accuracy: 0.8307\n",
      "Epoch 7/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.9127\n",
      "Epoch 00007: val_accuracy did not improve from 0.83722\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.2689 - accuracy: 0.9127 - val_loss: 0.5585 - val_accuracy: 0.8302\n",
      "Epoch 8/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9297\n",
      "Epoch 00008: val_accuracy improved from 0.83722 to 0.87520, saving model to ./storage/mnist_test_2/kfold5/epoch_008_val_0.421_acc_0.875.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2160 - accuracy: 0.9299 - val_loss: 0.4210 - val_accuracy: 0.8752\n",
      "Epoch 9/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9431\n",
      "Epoch 00009: val_accuracy did not improve from 0.87520\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1749 - accuracy: 0.9432 - val_loss: 0.4614 - val_accuracy: 0.8611\n",
      "Epoch 10/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9485\n",
      "Epoch 00010: val_accuracy improved from 0.87520 to 0.87900, saving model to ./storage/mnist_test_2/kfold5/epoch_010_val_0.464_acc_0.879.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1634 - accuracy: 0.9485 - val_loss: 0.4644 - val_accuracy: 0.8790\n",
      "Epoch 11/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9524\n",
      "Epoch 00011: val_accuracy improved from 0.87900 to 0.88226, saving model to ./storage/mnist_test_2/kfold5/epoch_011_val_0.418_acc_0.882.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1486 - accuracy: 0.9524 - val_loss: 0.4180 - val_accuracy: 0.8823\n",
      "Epoch 12/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9643\n",
      "Epoch 00012: val_accuracy improved from 0.88226 to 0.90125, saving model to ./storage/mnist_test_2/kfold5/epoch_012_val_0.334_acc_0.901.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1115 - accuracy: 0.9644 - val_loss: 0.3337 - val_accuracy: 0.9012\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1078 - accuracy: 0.9649\n",
      "Epoch 00013: val_accuracy did not improve from 0.90125\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1077 - accuracy: 0.9649 - val_loss: 0.3807 - val_accuracy: 0.9007\n",
      "Epoch 14/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9690\n",
      "Epoch 00014: val_accuracy did not improve from 0.90125\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1018 - accuracy: 0.9690 - val_loss: 0.4110 - val_accuracy: 0.8904\n",
      "Epoch 15/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9712\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.90125\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0947 - accuracy: 0.9713 - val_loss: 0.3761 - val_accuracy: 0.8974\n",
      "Epoch 16/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9855\n",
      "Epoch 00016: val_accuracy improved from 0.90125 to 0.91101, saving model to ./storage/mnist_test_2/kfold5/epoch_016_val_0.349_acc_0.911.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.3493 - val_accuracy: 0.9110\n",
      "Epoch 17/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9846\n",
      "Epoch 00017: val_accuracy improved from 0.91101 to 0.92566, saving model to ./storage/mnist_test_2/kfold5/epoch_017_val_0.321_acc_0.926.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0520 - accuracy: 0.9846 - val_loss: 0.3213 - val_accuracy: 0.9257\n",
      "Epoch 18/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9832\n",
      "Epoch 00018: val_accuracy did not improve from 0.92566\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0532 - accuracy: 0.9831 - val_loss: 0.3818 - val_accuracy: 0.9083\n",
      "Epoch 19/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9822\n",
      "Epoch 00019: val_accuracy did not improve from 0.92566\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0563 - accuracy: 0.9822 - val_loss: 0.4169 - val_accuracy: 0.9061\n",
      "Epoch 20/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9873\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92566\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.3385 - val_accuracy: 0.9170\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9912\n",
      "Epoch 00021: val_accuracy did not improve from 0.92566\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.3866 - val_accuracy: 0.9116\n",
      "Epoch 22/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 00022: val_accuracy did not improve from 0.92566\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0311 - accuracy: 0.9907 - val_loss: 0.4711 - val_accuracy: 0.9099\n",
      "Epoch 23/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9878\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92566\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0383 - accuracy: 0.9877 - val_loss: 0.4071 - val_accuracy: 0.9083\n",
      "Epoch 24/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9935\n",
      "Epoch 00024: val_accuracy improved from 0.92566 to 0.92838, saving model to ./storage/mnist_test_2/kfold5/epoch_024_val_0.349_acc_0.928.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.3489 - val_accuracy: 0.9284\n",
      "Epoch 25/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9957\n",
      "Epoch 00025: val_accuracy did not improve from 0.92838\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.2982 - val_accuracy: 0.9284\n",
      "Epoch 26/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 00026: val_accuracy improved from 0.92838 to 0.93163, saving model to ./storage/mnist_test_2/kfold5/epoch_026_val_0.298_acc_0.932.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.2980 - val_accuracy: 0.9316\n",
      "Epoch 27/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9964\n",
      "Epoch 00027: val_accuracy did not improve from 0.93163\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.3907 - val_accuracy: 0.9137\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9932\n",
      "Epoch 00028: val_accuracy did not improve from 0.93163\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.3637 - val_accuracy: 0.9284\n",
      "Epoch 29/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9947\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.93163\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.3732 - val_accuracy: 0.9230\n",
      "Epoch 30/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 00030: val_accuracy did not improve from 0.93163\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4028 - val_accuracy: 0.9262\n",
      "Epoch 31/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9968\n",
      "Epoch 00031: val_accuracy did not improve from 0.93163\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.3242 - val_accuracy: 0.9305\n",
      "Epoch 32/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9958\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.93163\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.3564 - val_accuracy: 0.9295\n",
      "Epoch 33/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 00033: val_accuracy improved from 0.93163 to 0.93326, saving model to ./storage/mnist_test_2/kfold5/epoch_033_val_0.367_acc_0.933.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.3670 - val_accuracy: 0.9333\n",
      "Epoch 34/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 00034: val_accuracy did not improve from 0.93326\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.3356 - val_accuracy: 0.9322\n",
      "Epoch 35/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9983\n",
      "Epoch 00035: val_accuracy improved from 0.93326 to 0.93923, saving model to ./storage/mnist_test_2/kfold5/epoch_035_val_0.335_acc_0.939.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.3353 - val_accuracy: 0.9392\n",
      "Epoch 36/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 00036: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.3682 - val_accuracy: 0.9333\n",
      "Epoch 37/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00037: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.3759 - val_accuracy: 0.9354\n",
      "Epoch 38/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9975\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.4446 - val_accuracy: 0.9219\n",
      "Epoch 39/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 00039: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.4013 - val_accuracy: 0.9338\n",
      "Epoch 40/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 00040: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.3648 - val_accuracy: 0.9376\n",
      "Epoch 41/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9984 ETA: \n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 25s 2ms/sample - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.3810 - val_accuracy: 0.9354\n",
      "Epoch 42/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 00042: val_accuracy did not improve from 0.93923\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.3600 - val_accuracy: 0.9387\n",
      "Epoch 43/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 8.9154e-04 - accuracy: 0.9999\n",
      "Epoch 00043: val_accuracy improved from 0.93923 to 0.94249, saving model to ./storage/mnist_test_2/kfold5/epoch_043_val_0.345_acc_0.942.h5\n",
      "16589/16589 [==============================] - 27s 2ms/sample - loss: 8.8967e-04 - accuracy: 0.9999 - val_loss: 0.3450 - val_accuracy: 0.9425\n",
      "Epoch 44/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998    \n",
      "Epoch 00044: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3638 - val_accuracy: 0.9398\n",
      "Epoch 45/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00045: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4757 - val_accuracy: 0.9224\n",
      "Epoch 46/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9990\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.3622 - val_accuracy: 0.9403\n",
      "Epoch 47/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 00047: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.4100 - val_accuracy: 0.9371\n",
      "Epoch 48/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 00048: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3426 - val_accuracy: 0.9381\n",
      "Epoch 49/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3820 - val_accuracy: 0.9354\n",
      "Epoch 50/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 00050: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.3410 - val_accuracy: 0.9419\n",
      "Epoch 51/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 3.8967e-04 - accuracy: 0.9999\n",
      "Epoch 00051: val_accuracy did not improve from 0.94249\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 3.8956e-04 - accuracy: 0.9999 - val_loss: 0.3422 - val_accuracy: 0.9414\n",
      "Epoch 52/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 6.2809e-04 - accuracy: 0.9999\n",
      "Epoch 00052: val_accuracy improved from 0.94249 to 0.94574, saving model to ./storage/mnist_test_2/kfold5/epoch_052_val_0.351_acc_0.946.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 9.2764e-04 - accuracy: 0.9998 - val_loss: 0.3509 - val_accuracy: 0.9457\n",
      "Epoch 53/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 4.3140e-04 - accuracy: 0.9999\n",
      "Epoch 00053: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 4.3113e-04 - accuracy: 0.9999 - val_loss: 0.3428 - val_accuracy: 0.9419\n",
      "Epoch 54/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 4.6620e-04 - accuracy: 0.9999\n",
      "Epoch 00054: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 4.6531e-04 - accuracy: 0.9999 - val_loss: 0.3580 - val_accuracy: 0.9419\n",
      "Epoch 55/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.3937 - val_accuracy: 0.9365\n",
      "Epoch 56/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 8.4486e-04 - accuracy: 0.9998\n",
      "Epoch 00056: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 8.4259e-04 - accuracy: 0.9998 - val_loss: 0.3785 - val_accuracy: 0.9409\n",
      "Epoch 57/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 3.5814e-04 - accuracy: 0.9999\n",
      "Epoch 00057: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 3.5786e-04 - accuracy: 0.9999 - val_loss: 0.3641 - val_accuracy: 0.9409\n",
      "Epoch 58/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.3798 - val_accuracy: 0.9365\n",
      "Epoch 59/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 2.2823e-04 - accuracy: 0.9999\n",
      "Epoch 00059: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 2.2898e-04 - accuracy: 0.9999 - val_loss: 0.3604 - val_accuracy: 0.9447\n",
      "Epoch 60/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 7.3631e-04 - accuracy: 0.9998\n",
      "Epoch 00060: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 7.3432e-04 - accuracy: 0.9998 - val_loss: 0.3637 - val_accuracy: 0.9392\n",
      "Epoch 61/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.3534 - val_accuracy: 0.9419\n",
      "Epoch 62/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 1.2726e-04 - accuracy: 1.0000\n",
      "Epoch 00062: val_accuracy did not improve from 0.94574\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.2702e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9436\n",
      "************ Fold 6 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 2.1787 - accuracy: 0.3263\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53663, saving model to ./storage/mnist_test_2/kfold6/epoch_001_val_1.333_acc_0.537.h5\n",
      "16589/16589 [==============================] - 35s 2ms/sample - loss: 2.1762 - accuracy: 0.3271 - val_loss: 1.3331 - val_accuracy: 0.5366\n",
      "Epoch 2/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 1.1095 - accuracy: 0.6332\n",
      "Epoch 00002: val_accuracy improved from 0.53663 to 0.72002, saving model to ./storage/mnist_test_2/kfold6/epoch_002_val_0.838_acc_0.720.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.1092 - accuracy: 0.6334 - val_loss: 0.8384 - val_accuracy: 0.7200\n",
      "Epoch 3/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.7245 - accuracy: 0.7604\n",
      "Epoch 00003: val_accuracy improved from 0.72002 to 0.80195, saving model to ./storage/mnist_test_2/kfold6/epoch_003_val_0.611_acc_0.802.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7242 - accuracy: 0.7606 - val_loss: 0.6108 - val_accuracy: 0.8020\n",
      "Epoch 4/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.8263\n",
      "Epoch 00004: val_accuracy did not improve from 0.80195\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.5287 - accuracy: 0.8263 - val_loss: 0.6448 - val_accuracy: 0.7944\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.4094 - accuracy: 0.8631\n",
      "Epoch 00005: val_accuracy improved from 0.80195 to 0.85241, saving model to ./storage/mnist_test_2/kfold6/epoch_005_val_0.490_acc_0.852.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.4097 - accuracy: 0.8631 - val_loss: 0.4898 - val_accuracy: 0.8524\n",
      "Epoch 6/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8892\n",
      "Epoch 00006: val_accuracy did not improve from 0.85241\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3359 - accuracy: 0.8893 - val_loss: 0.4704 - val_accuracy: 0.8464\n",
      "Epoch 7/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.9170\n",
      "Epoch 00007: val_accuracy did not improve from 0.85241\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.2605 - accuracy: 0.9169 - val_loss: 0.5286 - val_accuracy: 0.8459\n",
      "Epoch 8/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2086 - accuracy: 0.9315\n",
      "Epoch 00008: val_accuracy improved from 0.85241 to 0.85513, saving model to ./storage/mnist_test_2/kfold6/epoch_008_val_0.504_acc_0.855.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.2087 - accuracy: 0.9314 - val_loss: 0.5038 - val_accuracy: 0.8551\n",
      "Epoch 9/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9415\n",
      "Epoch 00009: val_accuracy improved from 0.85513 to 0.85567, saving model to ./storage/mnist_test_2/kfold6/epoch_009_val_0.511_acc_0.856.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.1838 - accuracy: 0.9415 - val_loss: 0.5114 - val_accuracy: 0.8557\n",
      "Epoch 10/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1585 - accuracy: 0.9487\n",
      "Epoch 00010: val_accuracy improved from 0.85567 to 0.87629, saving model to ./storage/mnist_test_2/kfold6/epoch_010_val_0.412_acc_0.876.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.1585 - accuracy: 0.9488 - val_loss: 0.4116 - val_accuracy: 0.8763\n",
      "Epoch 11/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1318 - accuracy: 0.9585\n",
      "Epoch 00011: val_accuracy did not improve from 0.87629\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1319 - accuracy: 0.9585 - val_loss: 0.6239 - val_accuracy: 0.8530\n",
      "Epoch 12/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9583\n",
      "Epoch 00012: val_accuracy improved from 0.87629 to 0.87683, saving model to ./storage/mnist_test_2/kfold6/epoch_012_val_0.432_acc_0.877.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.1257 - accuracy: 0.9581 - val_loss: 0.4324 - val_accuracy: 0.8768\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.9627\n",
      "Epoch 00013: val_accuracy did not improve from 0.87683\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1154 - accuracy: 0.9626 - val_loss: 0.4490 - val_accuracy: 0.8736\n",
      "Epoch 14/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9674\n",
      "Epoch 00014: val_accuracy improved from 0.87683 to 0.88606, saving model to ./storage/mnist_test_2/kfold6/epoch_014_val_0.415_acc_0.886.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.0972 - accuracy: 0.9673 - val_loss: 0.4152 - val_accuracy: 0.8861\n",
      "Epoch 15/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9710\n",
      "Epoch 00015: val_accuracy improved from 0.88606 to 0.89854, saving model to ./storage/mnist_test_2/kfold6/epoch_015_val_0.403_acc_0.899.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.0932 - accuracy: 0.9710 - val_loss: 0.4026 - val_accuracy: 0.8985\n",
      "Epoch 16/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9732\n",
      "Epoch 00016: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0849 - accuracy: 0.9733 - val_loss: 0.5010 - val_accuracy: 0.8790\n",
      "Epoch 17/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 0.9735\n",
      "Epoch 00017: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0852 - accuracy: 0.9735 - val_loss: 0.4271 - val_accuracy: 0.8915\n",
      "Epoch 18/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9836\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.5407 - val_accuracy: 0.8823\n",
      "Epoch 19/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9853\n",
      "Epoch 00019: val_accuracy improved from 0.89854 to 0.90722, saving model to ./storage/mnist_test_2/kfold6/epoch_019_val_0.432_acc_0.907.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.4323 - val_accuracy: 0.9072\n",
      "Epoch 20/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9877\n",
      "Epoch 00020: val_accuracy did not improve from 0.90722\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.5094 - val_accuracy: 0.8866\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9861\n",
      "Epoch 00021: val_accuracy improved from 0.90722 to 0.90884, saving model to ./storage/mnist_test_2/kfold6/epoch_021_val_0.400_acc_0.909.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0445 - accuracy: 0.9860 - val_loss: 0.3995 - val_accuracy: 0.9088\n",
      "Epoch 22/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9848\n",
      "Epoch 00022: val_accuracy did not improve from 0.90884\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.4965 - val_accuracy: 0.9018\n",
      "Epoch 23/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9877\n",
      "Epoch 00023: val_accuracy improved from 0.90884 to 0.91861, saving model to ./storage/mnist_test_2/kfold6/epoch_023_val_0.366_acc_0.919.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0394 - accuracy: 0.9877 - val_loss: 0.3661 - val_accuracy: 0.9186\n",
      "Epoch 24/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9898\n",
      "Epoch 00024: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.5121 - val_accuracy: 0.8915\n",
      "Epoch 25/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9853\n",
      "Epoch 00025: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.4443 - val_accuracy: 0.9018\n",
      "Epoch 26/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9911\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0281 - accuracy: 0.9911 - val_loss: 0.4012 - val_accuracy: 0.9154\n",
      "Epoch 27/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9938\n",
      "Epoch 00027: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.3862 - val_accuracy: 0.9170\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9938\n",
      "Epoch 00028: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.4006 - val_accuracy: 0.9126\n",
      "Epoch 29/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9959\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.4091 - val_accuracy: 0.9137\n",
      "Epoch 30/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9947\n",
      "Epoch 00030: val_accuracy did not improve from 0.91861\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.4237 - val_accuracy: 0.9137\n",
      "Epoch 31/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 00031: val_accuracy improved from 0.91861 to 0.92187, saving model to ./storage/mnist_test_2/kfold6/epoch_031_val_0.406_acc_0.922.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.4056 - val_accuracy: 0.9219\n",
      "Epoch 32/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9984\n",
      "Epoch 00032: val_accuracy did not improve from 0.92187\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.6804 - val_accuracy: 0.8774\n",
      "Epoch 33/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9937\n",
      "Epoch 00033: val_accuracy did not improve from 0.92187\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.4269 - val_accuracy: 0.9159\n",
      "Epoch 34/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9956\n",
      "Epoch 00034: val_accuracy improved from 0.92187 to 0.92458, saving model to ./storage/mnist_test_2/kfold6/epoch_034_val_0.418_acc_0.925.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.4181 - val_accuracy: 0.9246\n",
      "Epoch 35/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 00035: val_accuracy did not improve from 0.92458\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.4825 - val_accuracy: 0.9078\n",
      "Epoch 36/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 00036: val_accuracy did not improve from 0.92458\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.4709 - val_accuracy: 0.9186\n",
      "Epoch 37/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.92458\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.4631 - val_accuracy: 0.9164\n",
      "Epoch 38/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9975\n",
      "Epoch 00038: val_accuracy improved from 0.92458 to 0.93380, saving model to ./storage/mnist_test_2/kfold6/epoch_038_val_0.359_acc_0.934.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.3591 - val_accuracy: 0.9338\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 00039: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.4384 - val_accuracy: 0.9213\n",
      "Epoch 40/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00040: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.4844 - val_accuracy: 0.9126\n",
      "Epoch 41/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.5313 - val_accuracy: 0.9143\n",
      "Epoch 42/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9984\n",
      "Epoch 00042: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.4152 - val_accuracy: 0.9235\n",
      "Epoch 43/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 00043: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.3943 - val_accuracy: 0.9251\n",
      "Epoch 44/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.4671 - val_accuracy: 0.9197\n",
      "Epoch 45/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00045: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.4133 - val_accuracy: 0.9327\n",
      "Epoch 46/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 00046: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4223 - val_accuracy: 0.9316\n",
      "Epoch 47/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.4660 - val_accuracy: 0.9219\n",
      "Epoch 48/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 00048: val_accuracy did not improve from 0.93380\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3968 - val_accuracy: 0.9300\n",
      "************ Fold 7 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 2.1478 - accuracy: 0.3342\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51709, saving model to ./storage/mnist_test_2/kfold7/epoch_001_val_1.525_acc_0.517.h5\n",
      "16589/16589 [==============================] - 34s 2ms/sample - loss: 2.1478 - accuracy: 0.3343 - val_loss: 1.5249 - val_accuracy: 0.5171\n",
      "Epoch 2/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 1.1285 - accuracy: 0.6253\n",
      "Epoch 00002: val_accuracy improved from 0.51709 to 0.69452, saving model to ./storage/mnist_test_2/kfold7/epoch_002_val_0.953_acc_0.695.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.1292 - accuracy: 0.6251 - val_loss: 0.9531 - val_accuracy: 0.6945\n",
      "Epoch 3/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.7427 - accuracy: 0.7547\n",
      "Epoch 00003: val_accuracy improved from 0.69452 to 0.78242, saving model to ./storage/mnist_test_2/kfold7/epoch_003_val_0.657_acc_0.782.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7426 - accuracy: 0.7547 - val_loss: 0.6575 - val_accuracy: 0.7824\n",
      "Epoch 4/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.8243\n",
      "Epoch 00004: val_accuracy improved from 0.78242 to 0.79816, saving model to ./storage/mnist_test_2/kfold7/epoch_004_val_0.576_acc_0.798.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5271 - accuracy: 0.8245 - val_loss: 0.5756 - val_accuracy: 0.7982\n",
      "Epoch 5/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.4109 - accuracy: 0.8633\n",
      "Epoch 00005: val_accuracy improved from 0.79816 to 0.86272, saving model to ./storage/mnist_test_2/kfold7/epoch_005_val_0.430_acc_0.863.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.4108 - accuracy: 0.8633 - val_loss: 0.4298 - val_accuracy: 0.8627\n",
      "Epoch 6/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8936\n",
      "Epoch 00006: val_accuracy did not improve from 0.86272\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.3307 - accuracy: 0.8936 - val_loss: 0.4724 - val_accuracy: 0.8502\n",
      "Epoch 7/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2497 - accuracy: 0.9175\n",
      "Epoch 00007: val_accuracy improved from 0.86272 to 0.87900, saving model to ./storage/mnist_test_2/kfold7/epoch_007_val_0.401_acc_0.879.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2493 - accuracy: 0.9177 - val_loss: 0.4005 - val_accuracy: 0.8790\n",
      "Epoch 8/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9326\n",
      "Epoch 00008: val_accuracy did not improve from 0.87900\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.2067 - accuracy: 0.9327 - val_loss: 0.4885 - val_accuracy: 0.8513\n",
      "Epoch 9/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9394\n",
      "Epoch 00009: val_accuracy improved from 0.87900 to 0.89365, saving model to ./storage/mnist_test_2/kfold7/epoch_009_val_0.350_acc_0.894.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1890 - accuracy: 0.9394 - val_loss: 0.3503 - val_accuracy: 0.8937\n",
      "Epoch 10/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9532\n",
      "Epoch 00010: val_accuracy did not improve from 0.89365\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1482 - accuracy: 0.9532 - val_loss: 0.4332 - val_accuracy: 0.8774\n",
      "Epoch 11/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9549\n",
      "Epoch 00011: val_accuracy did not improve from 0.89365\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1410 - accuracy: 0.9549 - val_loss: 0.4337 - val_accuracy: 0.8741\n",
      "Epoch 12/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9593\n",
      "Epoch 00012: val_accuracy improved from 0.89365 to 0.89528, saving model to ./storage/mnist_test_2/kfold7/epoch_012_val_0.360_acc_0.895.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1262 - accuracy: 0.9593 - val_loss: 0.3597 - val_accuracy: 0.8953\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.9624\n",
      "Epoch 00013: val_accuracy did not improve from 0.89528\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1153 - accuracy: 0.9624 - val_loss: 0.3731 - val_accuracy: 0.8947\n",
      "Epoch 14/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9714\n",
      "Epoch 00014: val_accuracy improved from 0.89528 to 0.89636, saving model to ./storage/mnist_test_2/kfold7/epoch_014_val_0.387_acc_0.896.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0933 - accuracy: 0.9714 - val_loss: 0.3866 - val_accuracy: 0.8964\n",
      "Epoch 15/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0940 - accuracy: 0.9706\n",
      "Epoch 00015: val_accuracy improved from 0.89636 to 0.89908, saving model to ./storage/mnist_test_2/kfold7/epoch_015_val_0.407_acc_0.899.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0947 - accuracy: 0.9705 - val_loss: 0.4072 - val_accuracy: 0.8991\n",
      "Epoch 16/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9758\n",
      "Epoch 00016: val_accuracy did not improve from 0.89908\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0794 - accuracy: 0.9758 - val_loss: 0.4406 - val_accuracy: 0.8904\n",
      "Epoch 17/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.9732\n",
      "Epoch 00017: val_accuracy improved from 0.89908 to 0.91590, saving model to ./storage/mnist_test_2/kfold7/epoch_017_val_0.344_acc_0.916.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0834 - accuracy: 0.9731 - val_loss: 0.3442 - val_accuracy: 0.9159\n",
      "Epoch 18/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9780\n",
      "Epoch 00018: val_accuracy did not improve from 0.91590\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.4471 - val_accuracy: 0.8823\n",
      "Epoch 19/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9786\n",
      "Epoch 00019: val_accuracy did not improve from 0.91590\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0685 - accuracy: 0.9786 - val_loss: 0.4479 - val_accuracy: 0.8931\n",
      "Epoch 20/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9816\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91590\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.4795 - val_accuracy: 0.8931\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9876\n",
      "Epoch 00021: val_accuracy did not improve from 0.91590\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0430 - accuracy: 0.9875 - val_loss: 0.3875 - val_accuracy: 0.9137\n",
      "Epoch 22/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9894\n",
      "Epoch 00022: val_accuracy did not improve from 0.91590\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0335 - accuracy: 0.9894 - val_loss: 0.4374 - val_accuracy: 0.9094\n",
      "Epoch 23/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9877\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91590\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.3745 - val_accuracy: 0.9110\n",
      "Epoch 24/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9932\n",
      "Epoch 00024: val_accuracy improved from 0.91590 to 0.92675, saving model to ./storage/mnist_test_2/kfold7/epoch_024_val_0.325_acc_0.927.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.3248 - val_accuracy: 0.9267\n",
      "Epoch 25/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9934\n",
      "Epoch 00025: val_accuracy did not improve from 0.92675\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.3594 - val_accuracy: 0.9208\n",
      "Epoch 26/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9927\n",
      "Epoch 00026: val_accuracy did not improve from 0.92675\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.3625 - val_accuracy: 0.9230\n",
      "Epoch 27/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9924\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92675\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.3917 - val_accuracy: 0.9099\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9940\n",
      "Epoch 00028: val_accuracy did not improve from 0.92675\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.3723 - val_accuracy: 0.9202\n",
      "Epoch 29/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 00029: val_accuracy did not improve from 0.92675\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.3931 - val_accuracy: 0.9197\n",
      "Epoch 30/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 00030: val_accuracy improved from 0.92675 to 0.92784, saving model to ./storage/mnist_test_2/kfold7/epoch_030_val_0.370_acc_0.928.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.3696 - val_accuracy: 0.9278\n",
      "Epoch 31/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9945\n",
      "Epoch 00031: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.4240 - val_accuracy: 0.9181\n",
      "Epoch 32/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 00032: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.4232 - val_accuracy: 0.9186\n",
      "Epoch 33/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9956\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.4077 - val_accuracy: 0.9230\n",
      "Epoch 34/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 00034: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.3851 - val_accuracy: 0.9251\n",
      "Epoch 35/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9980\n",
      "Epoch 00035: val_accuracy did not improve from 0.92784\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.3937 - val_accuracy: 0.9278\n",
      "Epoch 36/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 00036: val_accuracy improved from 0.92784 to 0.93543, saving model to ./storage/mnist_test_2/kfold7/epoch_036_val_0.406_acc_0.935.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.4063 - val_accuracy: 0.9354\n",
      "Epoch 37/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9984\n",
      "Epoch 00037: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.4367 - val_accuracy: 0.9186\n",
      "Epoch 38/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 00038: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.4996 - val_accuracy: 0.9132\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.4334 - val_accuracy: 0.9192\n",
      "Epoch 40/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00040: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.4014 - val_accuracy: 0.9230\n",
      "Epoch 41/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00041: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.4357 - val_accuracy: 0.9213\n",
      "Epoch 42/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.3839 - val_accuracy: 0.9267\n",
      "Epoch 43/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 00043: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.4020 - val_accuracy: 0.9327\n",
      "Epoch 44/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00044: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3757 - val_accuracy: 0.9316\n",
      "Epoch 45/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4136 - val_accuracy: 0.9316\n",
      "Epoch 46/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 00046: val_accuracy did not improve from 0.93543\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4179 - val_accuracy: 0.9349\n",
      "************ Fold 8 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 2.1624 - accuracy: 0.3332\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54531, saving model to ./storage/mnist_test_2/kfold8/epoch_001_val_1.403_acc_0.545.h5\n",
      "16589/16589 [==============================] - 33s 2ms/sample - loss: 2.1605 - accuracy: 0.3338 - val_loss: 1.4027 - val_accuracy: 0.5453\n",
      "Epoch 2/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 1.1423 - accuracy: 0.6213\n",
      "Epoch 00002: val_accuracy improved from 0.54531 to 0.71514, saving model to ./storage/mnist_test_2/kfold8/epoch_002_val_0.806_acc_0.715.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.1419 - accuracy: 0.6216 - val_loss: 0.8062 - val_accuracy: 0.7151\n",
      "Epoch 3/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.7471 - accuracy: 0.7512\n",
      "Epoch 00003: val_accuracy improved from 0.71514 to 0.75638, saving model to ./storage/mnist_test_2/kfold8/epoch_003_val_0.696_acc_0.756.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7471 - accuracy: 0.7513 - val_loss: 0.6958 - val_accuracy: 0.7564\n",
      "Epoch 4/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.8206\n",
      "Epoch 00004: val_accuracy improved from 0.75638 to 0.82637, saving model to ./storage/mnist_test_2/kfold8/epoch_004_val_0.535_acc_0.826.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5430 - accuracy: 0.8207 - val_loss: 0.5348 - val_accuracy: 0.8264\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.4100 - accuracy: 0.8661\n",
      "Epoch 00005: val_accuracy improved from 0.82637 to 0.83831, saving model to ./storage/mnist_test_2/kfold8/epoch_005_val_0.492_acc_0.838.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.4101 - accuracy: 0.8660 - val_loss: 0.4917 - val_accuracy: 0.8383\n",
      "Epoch 6/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.8930\n",
      "Epoch 00006: val_accuracy improved from 0.83831 to 0.86218, saving model to ./storage/mnist_test_2/kfold8/epoch_006_val_0.463_acc_0.862.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3212 - accuracy: 0.8931 - val_loss: 0.4631 - val_accuracy: 0.8622\n",
      "Epoch 7/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2632 - accuracy: 0.9145\n",
      "Epoch 00007: val_accuracy improved from 0.86218 to 0.86381, saving model to ./storage/mnist_test_2/kfold8/epoch_007_val_0.412_acc_0.864.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2630 - accuracy: 0.9146 - val_loss: 0.4124 - val_accuracy: 0.8638\n",
      "Epoch 8/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9293\n",
      "Epoch 00008: val_accuracy improved from 0.86381 to 0.88551, saving model to ./storage/mnist_test_2/kfold8/epoch_008_val_0.371_acc_0.886.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2156 - accuracy: 0.9293 - val_loss: 0.3711 - val_accuracy: 0.8855\n",
      "Epoch 9/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9437\n",
      "Epoch 00009: val_accuracy did not improve from 0.88551\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1763 - accuracy: 0.9437 - val_loss: 0.4363 - val_accuracy: 0.8757\n",
      "Epoch 10/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9484\n",
      "Epoch 00010: val_accuracy improved from 0.88551 to 0.88985, saving model to ./storage/mnist_test_2/kfold8/epoch_010_val_0.366_acc_0.890.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1558 - accuracy: 0.9485 - val_loss: 0.3656 - val_accuracy: 0.8899\n",
      "Epoch 11/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1385 - accuracy: 0.9556\n",
      "Epoch 00011: val_accuracy improved from 0.88985 to 0.89691, saving model to ./storage/mnist_test_2/kfold8/epoch_011_val_0.350_acc_0.897.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1384 - accuracy: 0.9556 - val_loss: 0.3498 - val_accuracy: 0.8969\n",
      "Epoch 12/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9624\n",
      "Epoch 00012: val_accuracy did not improve from 0.89691\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1180 - accuracy: 0.9625 - val_loss: 0.4465 - val_accuracy: 0.8866\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.9648\n",
      "Epoch 00013: val_accuracy did not improve from 0.89691\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1069 - accuracy: 0.9648 - val_loss: 0.4368 - val_accuracy: 0.8920\n",
      "Epoch 14/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9680\n",
      "Epoch 00014: val_accuracy improved from 0.89691 to 0.89854, saving model to ./storage/mnist_test_2/kfold8/epoch_014_val_0.377_acc_0.899.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1006 - accuracy: 0.9679 - val_loss: 0.3773 - val_accuracy: 0.8985\n",
      "Epoch 15/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9740\n",
      "Epoch 00015: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0827 - accuracy: 0.9738 - val_loss: 0.4387 - val_accuracy: 0.8882\n",
      "Epoch 16/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9723\n",
      "Epoch 00016: val_accuracy did not improve from 0.89854\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0859 - accuracy: 0.9722 - val_loss: 0.4209 - val_accuracy: 0.8953\n",
      "Epoch 17/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9769\n",
      "Epoch 00017: val_accuracy improved from 0.89854 to 0.91264, saving model to ./storage/mnist_test_2/kfold8/epoch_017_val_0.353_acc_0.913.h5\n",
      "16589/16589 [==============================] - 27s 2ms/sample - loss: 0.0745 - accuracy: 0.9770 - val_loss: 0.3530 - val_accuracy: 0.9126\n",
      "Epoch 18/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9765\n",
      "Epoch 00018: val_accuracy did not improve from 0.91264\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0783 - accuracy: 0.9764 - val_loss: 0.3783 - val_accuracy: 0.9040\n",
      "Epoch 19/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9798\n",
      "Epoch 00019: val_accuracy improved from 0.91264 to 0.92404, saving model to ./storage/mnist_test_2/kfold8/epoch_019_val_0.344_acc_0.924.h5\n",
      "16589/16589 [==============================] - 26s 2ms/sample - loss: 0.0633 - accuracy: 0.9798 - val_loss: 0.3441 - val_accuracy: 0.9240\n",
      "Epoch 20/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9797\n",
      "Epoch 00020: val_accuracy did not improve from 0.92404\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0633 - accuracy: 0.9797 - val_loss: 0.4095 - val_accuracy: 0.9040\n",
      "Epoch 21/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9842\n",
      "Epoch 00021: val_accuracy did not improve from 0.92404\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0522 - accuracy: 0.9841 - val_loss: 0.3467 - val_accuracy: 0.9154\n",
      "Epoch 22/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9816\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92404\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0580 - accuracy: 0.9815 - val_loss: 0.3113 - val_accuracy: 0.9224\n",
      "Epoch 23/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9890\n",
      "Epoch 00023: val_accuracy did not improve from 0.92404\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.3132 - val_accuracy: 0.9235\n",
      "Epoch 24/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9919\n",
      "Epoch 00024: val_accuracy did not improve from 0.92404\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.3340 - val_accuracy: 0.9235\n",
      "Epoch 25/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9900\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92404\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.3345 - val_accuracy: 0.9219\n",
      "Epoch 26/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9924\n",
      "Epoch 00026: val_accuracy improved from 0.92404 to 0.92946, saving model to ./storage/mnist_test_2/kfold8/epoch_026_val_0.296_acc_0.929.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.2962 - val_accuracy: 0.9295\n",
      "Epoch 27/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n",
      "Epoch 00027: val_accuracy improved from 0.92946 to 0.93435, saving model to ./storage/mnist_test_2/kfold8/epoch_027_val_0.309_acc_0.934.h5\n",
      "16589/16589 [==============================] - 25s 1ms/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.3093 - val_accuracy: 0.9343\n",
      "Epoch 28/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 00028: val_accuracy did not improve from 0.93435\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.4066 - val_accuracy: 0.9213\n",
      "Epoch 29/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9908\n",
      "Epoch 00029: val_accuracy did not improve from 0.93435\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.3481 - val_accuracy: 0.9289\n",
      "Epoch 30/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.93435\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.3483 - val_accuracy: 0.9322\n",
      "Epoch 31/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9963\n",
      "Epoch 00031: val_accuracy improved from 0.93435 to 0.94194, saving model to ./storage/mnist_test_2/kfold8/epoch_031_val_0.307_acc_0.942.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.3071 - val_accuracy: 0.9419\n",
      "Epoch 32/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 00032: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.3407 - val_accuracy: 0.9349\n",
      "Epoch 33/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 00033: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.3631 - val_accuracy: 0.9311\n",
      "Epoch 34/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9963\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.3617 - val_accuracy: 0.9354\n",
      "Epoch 35/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9951\n",
      "Epoch 00035: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.3067 - val_accuracy: 0.9349\n",
      "Epoch 36/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 00036: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.3852 - val_accuracy: 0.9295\n",
      "Epoch 37/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.3996 - val_accuracy: 0.9278\n",
      "Epoch 38/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00038: val_accuracy did not improve from 0.94194\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.3205 - val_accuracy: 0.9398\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 00039: val_accuracy improved from 0.94194 to 0.94303, saving model to ./storage/mnist_test_2/kfold8/epoch_039_val_0.325_acc_0.943.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.3250 - val_accuracy: 0.9430\n",
      "Epoch 40/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 00040: val_accuracy did not improve from 0.94303\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.2926 - val_accuracy: 0.9403\n",
      "Epoch 41/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 00041: val_accuracy improved from 0.94303 to 0.94845, saving model to ./storage/mnist_test_2/kfold8/epoch_041_val_0.287_acc_0.948.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2874 - val_accuracy: 0.9485\n",
      "Epoch 42/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00042: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.3452 - val_accuracy: 0.9327\n",
      "Epoch 43/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 00043: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.3657 - val_accuracy: 0.9398\n",
      "Epoch 44/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3310 - val_accuracy: 0.9419\n",
      "Epoch 45/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00045: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.3082 - val_accuracy: 0.9479\n",
      "Epoch 46/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 7.0482e-04 - accuracy: 0.9998\n",
      "Epoch 00046: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 7.0819e-04 - accuracy: 0.9998 - val_loss: 0.3091 - val_accuracy: 0.9474\n",
      "Epoch 47/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3577 - val_accuracy: 0.9381\n",
      "Epoch 48/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00048: val_accuracy did not improve from 0.94845\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.3352 - val_accuracy: 0.9441\n",
      "Epoch 49/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00049: val_accuracy improved from 0.94845 to 0.94900, saving model to ./storage/mnist_test_2/kfold8/epoch_049_val_0.322_acc_0.949.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3224 - val_accuracy: 0.9490\n",
      "Epoch 50/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 00050: val_accuracy improved from 0.94900 to 0.95225, saving model to ./storage/mnist_test_2/kfold8/epoch_050_val_0.294_acc_0.952.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2939 - val_accuracy: 0.9523\n",
      "Epoch 51/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 00051: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.3134 - val_accuracy: 0.9457\n",
      "Epoch 52/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 00052: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3516 - val_accuracy: 0.9447\n",
      "Epoch 53/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.3522 - val_accuracy: 0.9409\n",
      "Epoch 54/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00054: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.3315 - val_accuracy: 0.9403\n",
      "Epoch 55/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 7.5900e-04 - accuracy: 0.9998\n",
      "Epoch 00055: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 7.5699e-04 - accuracy: 0.9998 - val_loss: 0.3149 - val_accuracy: 0.9512\n",
      "Epoch 56/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 8.6080e-04 - accuracy: 0.9997\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 8.6014e-04 - accuracy: 0.9997 - val_loss: 0.3282 - val_accuracy: 0.9457\n",
      "Epoch 57/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 7.3688e-04 - accuracy: 0.9998\n",
      "Epoch 00057: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 7.3503e-04 - accuracy: 0.9998 - val_loss: 0.3185 - val_accuracy: 0.9485\n",
      "Epoch 58/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 1.7214e-04 - accuracy: 1.0000\n",
      "Epoch 00058: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 1.7209e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9485\n",
      "Epoch 59/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 8.6641e-05 - accuracy: 1.0000\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 9.4637e-05 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9501\n",
      "Epoch 60/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 2.3693e-04 - accuracy: 0.9999\n",
      "Epoch 00060: val_accuracy did not improve from 0.95225\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 2.3680e-04 - accuracy: 0.9999 - val_loss: 0.3444 - val_accuracy: 0.9506\n",
      "************ Fold 9 training ************\n",
      "Train on 16589 samples, validate on 1843 samples\n",
      "Epoch 1/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 2.1600 - accuracy: 0.3289\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50298, saving model to ./storage/mnist_test_2/kfold9/epoch_001_val_1.617_acc_0.503.h5\n",
      "16589/16589 [==============================] - 34s 2ms/sample - loss: 2.1574 - accuracy: 0.3298 - val_loss: 1.6169 - val_accuracy: 0.5030\n",
      "Epoch 2/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 1.1435 - accuracy: 0.6194\n",
      "Epoch 00002: val_accuracy improved from 0.50298 to 0.70808, saving model to ./storage/mnist_test_2/kfold9/epoch_002_val_0.832_acc_0.708.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 1.1433 - accuracy: 0.6194 - val_loss: 0.8319 - val_accuracy: 0.7081\n",
      "Epoch 3/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.7279 - accuracy: 0.7614\n",
      "Epoch 00003: val_accuracy improved from 0.70808 to 0.78568, saving model to ./storage/mnist_test_2/kfold9/epoch_003_val_0.611_acc_0.786.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.7276 - accuracy: 0.7615 - val_loss: 0.6112 - val_accuracy: 0.7857\n",
      "Epoch 4/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.8270\n",
      "Epoch 00004: val_accuracy improved from 0.78568 to 0.83831, saving model to ./storage/mnist_test_2/kfold9/epoch_004_val_0.503_acc_0.838.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.5227 - accuracy: 0.8269 - val_loss: 0.5035 - val_accuracy: 0.8383\n",
      "Epoch 5/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.4139 - accuracy: 0.8669\n",
      "Epoch 00005: val_accuracy improved from 0.83831 to 0.84753, saving model to ./storage/mnist_test_2/kfold9/epoch_005_val_0.475_acc_0.848.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.4141 - accuracy: 0.8668 - val_loss: 0.4747 - val_accuracy: 0.8475\n",
      "Epoch 6/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.8949\n",
      "Epoch 00006: val_accuracy improved from 0.84753 to 0.86001, saving model to ./storage/mnist_test_2/kfold9/epoch_006_val_0.458_acc_0.860.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.3205 - accuracy: 0.8949 - val_loss: 0.4585 - val_accuracy: 0.8600\n",
      "Epoch 7/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9220\n",
      "Epoch 00007: val_accuracy improved from 0.86001 to 0.86815, saving model to ./storage/mnist_test_2/kfold9/epoch_007_val_0.461_acc_0.868.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.2474 - accuracy: 0.9219 - val_loss: 0.4609 - val_accuracy: 0.8681\n",
      "Epoch 8/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9295\n",
      "Epoch 00008: val_accuracy did not improve from 0.86815\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.2188 - accuracy: 0.9294 - val_loss: 0.4723 - val_accuracy: 0.8638\n",
      "Epoch 9/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.9379\n",
      "Epoch 00009: val_accuracy improved from 0.86815 to 0.88280, saving model to ./storage/mnist_test_2/kfold9/epoch_009_val_0.408_acc_0.883.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1868 - accuracy: 0.9380 - val_loss: 0.4077 - val_accuracy: 0.8828\n",
      "Epoch 10/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9506\n",
      "Epoch 00010: val_accuracy improved from 0.88280 to 0.88877, saving model to ./storage/mnist_test_2/kfold9/epoch_010_val_0.385_acc_0.889.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1510 - accuracy: 0.9504 - val_loss: 0.3852 - val_accuracy: 0.8888\n",
      "Epoch 11/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.9565\n",
      "Epoch 00011: val_accuracy improved from 0.88877 to 0.89962, saving model to ./storage/mnist_test_2/kfold9/epoch_011_val_0.349_acc_0.900.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.1392 - accuracy: 0.9565 - val_loss: 0.3487 - val_accuracy: 0.8996\n",
      "Epoch 12/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.9665\n",
      "Epoch 00012: val_accuracy did not improve from 0.89962\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1035 - accuracy: 0.9664 - val_loss: 0.4048 - val_accuracy: 0.8953\n",
      "Epoch 13/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.9645\n",
      "Epoch 00013: val_accuracy did not improve from 0.89962\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.1123 - accuracy: 0.9644 - val_loss: 0.4072 - val_accuracy: 0.8931\n",
      "Epoch 14/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9701\n",
      "Epoch 00014: val_accuracy improved from 0.89962 to 0.90884, saving model to ./storage/mnist_test_2/kfold9/epoch_014_val_0.338_acc_0.909.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0960 - accuracy: 0.9701 - val_loss: 0.3379 - val_accuracy: 0.9088\n",
      "Epoch 15/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9727\n",
      "Epoch 00015: val_accuracy did not improve from 0.90884\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0894 - accuracy: 0.9728 - val_loss: 0.4115 - val_accuracy: 0.9018\n",
      "Epoch 16/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9733\n",
      "Epoch 00016: val_accuracy did not improve from 0.90884\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0842 - accuracy: 0.9734 - val_loss: 0.3304 - val_accuracy: 0.9088\n",
      "Epoch 17/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 0.9764\n",
      "Epoch 00017: val_accuracy improved from 0.90884 to 0.92187, saving model to ./storage/mnist_test_2/kfold9/epoch_017_val_0.320_acc_0.922.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0768 - accuracy: 0.9764 - val_loss: 0.3199 - val_accuracy: 0.9219\n",
      "Epoch 18/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9777\n",
      "Epoch 00018: val_accuracy did not improve from 0.92187\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0731 - accuracy: 0.9777 - val_loss: 0.3380 - val_accuracy: 0.9132\n",
      "Epoch 19/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9807\n",
      "Epoch 00019: val_accuracy did not improve from 0.92187\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0625 - accuracy: 0.9806 - val_loss: 0.3889 - val_accuracy: 0.9126\n",
      "Epoch 20/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9797\n",
      "Epoch 00020: val_accuracy improved from 0.92187 to 0.93001, saving model to ./storage/mnist_test_2/kfold9/epoch_020_val_0.291_acc_0.930.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0630 - accuracy: 0.9797 - val_loss: 0.2906 - val_accuracy: 0.9300\n",
      "Epoch 21/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9841\n",
      "Epoch 00021: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0547 - accuracy: 0.9841 - val_loss: 0.4185 - val_accuracy: 0.9045\n",
      "Epoch 22/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9829\n",
      "Epoch 00022: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0554 - accuracy: 0.9828 - val_loss: 0.3300 - val_accuracy: 0.9230\n",
      "Epoch 23/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9820\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0577 - accuracy: 0.9820 - val_loss: 0.3510 - val_accuracy: 0.9154\n",
      "Epoch 24/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9912\n",
      "Epoch 00024: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.4163 - val_accuracy: 0.9164\n",
      "Epoch 25/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9909\n",
      "Epoch 00025: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0301 - accuracy: 0.9908 - val_loss: 0.3868 - val_accuracy: 0.9181\n",
      "Epoch 26/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9898\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.93001\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0339 - accuracy: 0.9898 - val_loss: 0.3816 - val_accuracy: 0.9224\n",
      "Epoch 27/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9936\n",
      "Epoch 00027: val_accuracy improved from 0.93001 to 0.93326, saving model to ./storage/mnist_test_2/kfold9/epoch_027_val_0.314_acc_0.933.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.3135 - val_accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9949\n",
      "Epoch 00028: val_accuracy did not improve from 0.93326\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.3238 - val_accuracy: 0.9327\n",
      "Epoch 29/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 00029: val_accuracy did not improve from 0.93326\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.4110 - val_accuracy: 0.9284\n",
      "Epoch 30/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9944\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.93326\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.3818 - val_accuracy: 0.9278\n",
      "Epoch 31/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9938\n",
      "Epoch 00031: val_accuracy did not improve from 0.93326\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.3347 - val_accuracy: 0.9311\n",
      "Epoch 32/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9967\n",
      "Epoch 00032: val_accuracy improved from 0.93326 to 0.93597, saving model to ./storage/mnist_test_2/kfold9/epoch_032_val_0.300_acc_0.936.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.3004 - val_accuracy: 0.9360\n",
      "Epoch 33/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 00033: val_accuracy improved from 0.93597 to 0.93706, saving model to ./storage/mnist_test_2/kfold9/epoch_033_val_0.318_acc_0.937.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.3181 - val_accuracy: 0.9371\n",
      "Epoch 34/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9982\n",
      "Epoch 00034: val_accuracy did not improve from 0.93706\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.3373 - val_accuracy: 0.9333\n",
      "Epoch 35/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 00035: val_accuracy did not improve from 0.93706\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.3293 - val_accuracy: 0.9343\n",
      "Epoch 36/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9938\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93706\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.3956 - val_accuracy: 0.9208\n",
      "Epoch 37/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9960\n",
      "Epoch 00037: val_accuracy improved from 0.93706 to 0.93923, saving model to ./storage/mnist_test_2/kfold9/epoch_037_val_0.308_acc_0.939.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.3076 - val_accuracy: 0.9392\n",
      "Epoch 38/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 00038: val_accuracy improved from 0.93923 to 0.94628, saving model to ./storage/mnist_test_2/kfold9/epoch_038_val_0.283_acc_0.946.h5\n",
      "16589/16589 [==============================] - 24s 1ms/sample - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.2832 - val_accuracy: 0.9463\n",
      "Epoch 39/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00039: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.3178 - val_accuracy: 0.9381\n",
      "Epoch 40/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 00040: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.3949 - val_accuracy: 0.9300\n",
      "Epoch 41/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.3510 - val_accuracy: 0.9452\n",
      "Epoch 42/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 00042: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.3520 - val_accuracy: 0.9381\n",
      "Epoch 43/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 00043: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.3456 - val_accuracy: 0.9414\n",
      "Epoch 44/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.3476 - val_accuracy: 0.9430\n",
      "Epoch 45/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00045: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.3447 - val_accuracy: 0.9430\n",
      "Epoch 46/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 00046: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.3539 - val_accuracy: 0.9447\n",
      "Epoch 47/200\n",
      "16544/16589 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.3775 - val_accuracy: 0.9403\n",
      "Epoch 48/200\n",
      "16576/16589 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00048: val_accuracy did not improve from 0.94628\n",
      "16589/16589 [==============================] - 23s 1ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3568 - val_accuracy: 0.9425\n",
      "************ Fold 10 training ************\n",
      "Train on 16587 samples, validate on 1845 samples\n",
      "Epoch 1/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 2.1920 - accuracy: 0.3232\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51328, saving model to ./storage/mnist_test_2/kfold10/epoch_001_val_1.547_acc_0.513.h5\n",
      "16587/16587 [==============================] - 34s 2ms/sample - loss: 2.1911 - accuracy: 0.3237 - val_loss: 1.5473 - val_accuracy: 0.5133\n",
      "Epoch 2/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 1.1154 - accuracy: 0.6333\n",
      "Epoch 00002: val_accuracy improved from 0.51328 to 0.71003, saving model to ./storage/mnist_test_2/kfold10/epoch_002_val_0.857_acc_0.710.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 1.1144 - accuracy: 0.6338 - val_loss: 0.8572 - val_accuracy: 0.7100\n",
      "Epoch 3/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.7329 - accuracy: 0.7559\n",
      "Epoch 00003: val_accuracy improved from 0.71003 to 0.79946, saving model to ./storage/mnist_test_2/kfold10/epoch_003_val_0.615_acc_0.799.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.7327 - accuracy: 0.7560 - val_loss: 0.6147 - val_accuracy: 0.7995\n",
      "Epoch 4/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.5298 - accuracy: 0.8240\n",
      "Epoch 00004: val_accuracy improved from 0.79946 to 0.83631, saving model to ./storage/mnist_test_2/kfold10/epoch_004_val_0.516_acc_0.836.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.5297 - accuracy: 0.8240 - val_loss: 0.5157 - val_accuracy: 0.8363\n",
      "Epoch 5/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.4110 - accuracy: 0.8624\n",
      "Epoch 00005: val_accuracy improved from 0.83631 to 0.85041, saving model to ./storage/mnist_test_2/kfold10/epoch_005_val_0.497_acc_0.850.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.4112 - accuracy: 0.8624 - val_loss: 0.4966 - val_accuracy: 0.8504\n",
      "Epoch 6/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.8962\n",
      "Epoch 00006: val_accuracy improved from 0.85041 to 0.87805, saving model to ./storage/mnist_test_2/kfold10/epoch_006_val_0.365_acc_0.878.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.3142 - accuracy: 0.8961 - val_loss: 0.3655 - val_accuracy: 0.8780\n",
      "Epoch 7/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.9135\n",
      "Epoch 00007: val_accuracy did not improve from 0.87805\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.2624 - accuracy: 0.9134 - val_loss: 0.4648 - val_accuracy: 0.8569\n",
      "Epoch 8/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9272\n",
      "Epoch 00008: val_accuracy improved from 0.87805 to 0.88564, saving model to ./storage/mnist_test_2/kfold10/epoch_008_val_0.372_acc_0.886.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.2219 - accuracy: 0.9273 - val_loss: 0.3724 - val_accuracy: 0.8856\n",
      "Epoch 9/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9405\n",
      "Epoch 00009: val_accuracy improved from 0.88564 to 0.89864, saving model to ./storage/mnist_test_2/kfold10/epoch_009_val_0.345_acc_0.899.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.1775 - accuracy: 0.9404 - val_loss: 0.3445 - val_accuracy: 0.8986\n",
      "Epoch 10/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.9516\n",
      "Epoch 00010: val_accuracy did not improve from 0.89864\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.1519 - accuracy: 0.9516 - val_loss: 0.3908 - val_accuracy: 0.8916\n",
      "Epoch 11/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 0.9558\n",
      "Epoch 00011: val_accuracy did not improve from 0.89864\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.1392 - accuracy: 0.9557 - val_loss: 0.3869 - val_accuracy: 0.8949\n",
      "Epoch 12/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 0.9646\n",
      "Epoch 00012: val_accuracy improved from 0.89864 to 0.89973, saving model to ./storage/mnist_test_2/kfold10/epoch_012_val_0.379_acc_0.900.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.1185 - accuracy: 0.9647 - val_loss: 0.3786 - val_accuracy: 0.8997\n",
      "Epoch 13/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9645\n",
      "Epoch 00013: val_accuracy improved from 0.89973 to 0.91111, saving model to ./storage/mnist_test_2/kfold10/epoch_013_val_0.331_acc_0.911.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.1163 - accuracy: 0.9646 - val_loss: 0.3314 - val_accuracy: 0.9111\n",
      "Epoch 14/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9684\n",
      "Epoch 00014: val_accuracy did not improve from 0.91111\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.1018 - accuracy: 0.9683 - val_loss: 0.3874 - val_accuracy: 0.9008\n",
      "Epoch 15/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0885 - accuracy: 0.9707\n",
      "Epoch 00015: val_accuracy did not improve from 0.91111\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0884 - accuracy: 0.9707 - val_loss: 0.3777 - val_accuracy: 0.9041\n",
      "Epoch 16/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9781\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91111\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0741 - accuracy: 0.9781 - val_loss: 0.4049 - val_accuracy: 0.9041\n",
      "Epoch 17/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9851\n",
      "Epoch 00017: val_accuracy improved from 0.91111 to 0.91707, saving model to ./storage/mnist_test_2/kfold10/epoch_017_val_0.351_acc_0.917.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.3507 - val_accuracy: 0.9171\n",
      "Epoch 18/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9854\n",
      "Epoch 00018: val_accuracy improved from 0.91707 to 0.92141, saving model to ./storage/mnist_test_2/kfold10/epoch_018_val_0.356_acc_0.921.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.3561 - val_accuracy: 0.9214\n",
      "Epoch 19/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9837\n",
      "Epoch 00019: val_accuracy improved from 0.92141 to 0.92900, saving model to ./storage/mnist_test_2/kfold10/epoch_019_val_0.309_acc_0.929.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.3094 - val_accuracy: 0.9290\n",
      "Epoch 20/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.9862\n",
      "Epoch 00020: val_accuracy did not improve from 0.92900\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.3503 - val_accuracy: 0.9100\n",
      "Epoch 21/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9865\n",
      "Epoch 00021: val_accuracy did not improve from 0.92900\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0454 - accuracy: 0.9866 - val_loss: 0.3766 - val_accuracy: 0.9138\n",
      "Epoch 22/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9859\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92900\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.3148 - val_accuracy: 0.9279\n",
      "Epoch 23/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9938\n",
      "Epoch 00023: val_accuracy improved from 0.92900 to 0.93062, saving model to ./storage/mnist_test_2/kfold10/epoch_023_val_0.322_acc_0.931.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.3216 - val_accuracy: 0.9306\n",
      "Epoch 24/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 00024: val_accuracy did not improve from 0.93062\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.3325 - val_accuracy: 0.9230\n",
      "Epoch 25/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 00025: val_accuracy did not improve from 0.93062\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.3433 - val_accuracy: 0.9268\n",
      "Epoch 26/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9924\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.93062\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.3757 - val_accuracy: 0.9187\n",
      "Epoch 27/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.9940\n",
      "Epoch 00027: val_accuracy improved from 0.93062 to 0.93333, saving model to ./storage/mnist_test_2/kfold10/epoch_027_val_0.289_acc_0.933.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.2890 - val_accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9960\n",
      "Epoch 00028: val_accuracy did not improve from 0.93333\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.3458 - val_accuracy: 0.9312\n",
      "Epoch 29/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 00029: val_accuracy did not improve from 0.93333\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.3502 - val_accuracy: 0.9290\n",
      "Epoch 30/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9943\n",
      "Epoch 00030: val_accuracy improved from 0.93333 to 0.93388, saving model to ./storage/mnist_test_2/kfold10/epoch_030_val_0.334_acc_0.934.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.3335 - val_accuracy: 0.9339\n",
      "Epoch 31/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 00031: val_accuracy did not improve from 0.93388\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.3735 - val_accuracy: 0.9230\n",
      "Epoch 32/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9949\n",
      "Epoch 00032: val_accuracy did not improve from 0.93388\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.3180 - val_accuracy: 0.9301\n",
      "Epoch 33/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 00033: val_accuracy improved from 0.93388 to 0.93713, saving model to ./storage/mnist_test_2/kfold10/epoch_033_val_0.336_acc_0.937.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.3358 - val_accuracy: 0.9371\n",
      "Epoch 34/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9954\n",
      "Epoch 00034: val_accuracy did not improve from 0.93713\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.3401 - val_accuracy: 0.9306\n",
      "Epoch 35/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9954\n",
      "Epoch 00035: val_accuracy did not improve from 0.93713\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.3617 - val_accuracy: 0.9317\n",
      "Epoch 36/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93713\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.3673 - val_accuracy: 0.9290\n",
      "Epoch 37/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 00037: val_accuracy improved from 0.93713 to 0.94092, saving model to ./storage/mnist_test_2/kfold10/epoch_037_val_0.310_acc_0.941.h5\n",
      "16587/16587 [==============================] - 24s 1ms/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.3096 - val_accuracy: 0.9409\n",
      "Epoch 38/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 00038: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.3306 - val_accuracy: 0.9382\n",
      "Epoch 39/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00039: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.3975 - val_accuracy: 0.9312\n",
      "Epoch 40/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.3701 - val_accuracy: 0.9317\n",
      "Epoch 41/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00041: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.3468 - val_accuracy: 0.9322\n",
      "Epoch 42/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 00042: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.3452 - val_accuracy: 0.9366\n",
      "Epoch 43/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.3634 - val_accuracy: 0.9350\n",
      "Epoch 44/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 00044: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.3398 - val_accuracy: 0.9344\n",
      "Epoch 45/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00045: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.3520 - val_accuracy: 0.9371\n",
      "Epoch 46/200\n",
      "16576/16587 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94092\n",
      "16587/16587 [==============================] - 23s 1ms/sample - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.3725 - val_accuracy: 0.9322\n",
      "Epoch 47/200\n",
      "16544/16587 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992"
     ]
    }
   ],
   "source": [
    "# implement k-fold cv \n",
    "def k_fold(k,files):  \n",
    "    folds = [] \n",
    "    fold_size = len(files) // k \n",
    "    for i in range(k): \n",
    "        if i == k-1:  \n",
    "            l = files[i*fold_size:] \n",
    "        else: \n",
    "            l = files[i*fold_size:(i+1)*fold_size]  \n",
    "        folds.append(l)   \n",
    "    return folds  \n",
    "\n",
    "# uncomment below to shuffle before splitting data into folds \n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "# split data into 5 folds \n",
    "k = 10\n",
    "x_train_folds = k_fold(k, x_train)\n",
    "y_train_folds = k_fold(k, y_train) \n",
    "\n",
    "for t in range(k):  \n",
    "    print(\"************ Fold {} training ************\".format(t+1)) \n",
    "    cur_val_x = x_train_folds[t] \n",
    "    cur_val_y = y_train_folds[t] \n",
    "    train_folds_x = x_train_folds[0:t] + x_train_folds[t+1:] \n",
    "    train_folds_y = y_train_folds[0:t] + y_train_folds[t+1:]\n",
    "    cur_train_x = [] \n",
    "    cur_train_y = [] \n",
    "    for j in train_folds_x:  \n",
    "        for q in j:  \n",
    "            cur_train_x.append(q) \n",
    "    for j in train_folds_y:  \n",
    "        for q in j:  \n",
    "            cur_train_y.append(q)  \n",
    "    cur_train_x = np.asarray(cur_train_x)\n",
    "    cur_train_y = np.asarray(cur_train_y)\n",
    "    model_path = './storage/mnist_test_2/' + 'kfold' + str(t+1) + '/epoch_{epoch:03d}_val_{val_loss:.3f}_acc_{val_accuracy:.3f}.h5' \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.8)\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_accuracy',verbose=1,save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy',patience=10)\n",
    "    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) # possible alternative to ReduceLROnPlateau\n",
    "    model = base_cnn() \n",
    "    \n",
    "    history = model.fit(cur_train_x,\n",
    "                        cur_train_y,\n",
    "                       batch_size = 32,\n",
    "                       shuffle = True, \n",
    "                       validation_data = (cur_val_x,cur_val_y),\n",
    "                       verbose = 1, \n",
    "                       epochs = 200,\n",
    "                       callbacks = [learning_rate_reduction, checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict([x_test,test_letters_numeric]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 8, ..., 6, 8, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_arr = [] \n",
    "for p in pred: \n",
    "    result_arr.append(np.argmax(p))\n",
    "result_arr = np.asarray(result_arr)\n",
    "result_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  digit\n",
       "0  2049      6\n",
       "1  2050      9\n",
       "2  2051      8\n",
       "3  2052      0\n",
       "4  2053      3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['digit'] = result_arr\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./storage/bestof10fold.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
