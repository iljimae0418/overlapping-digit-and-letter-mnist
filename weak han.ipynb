{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# environment: Paperspace Quadro P6000 GPU  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras # run pip install keras==2.3 beforehand for compatability \n",
    "from tensorflow.keras import Input, Model \n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import random \n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils import shuffle # shuffle dataset before splitting into folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './storage/modified_mnist_dataset/train.csv'  \n",
    "test_path = './storage/modified_mnist_dataset/test.csv' \n",
    "submission_path = './storage/modified_mnist_dataset/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path) \n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types of digit and letter columns to categorical \n",
    "train.iloc[:,1] = pd.Categorical(train.iloc[:,1])\n",
    "train.iloc[:,2] = pd.Categorical(train.iloc[:,2]) \n",
    "test.iloc[:,1] = pd.Categorical(test.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and re-format train and test data \n",
    "# this time, we will standardize instead of normalize data \n",
    "x_train = train.iloc[:,3:].values.reshape(-1,28,28,1).astype(np.float32) \n",
    "# standardize - we assume train and test data have the same \"distribution\" \n",
    "mu = np.mean(x_train)\n",
    "sd = np.std(x_train)\n",
    "x_train -= mu \n",
    "x_train /= sd \n",
    "y_train = train.iloc[:,1].values\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = to_categorical(y_train, num_classes = 10)\n",
    "train_letters = train.iloc[:,2].values\n",
    "\n",
    "x_test = test.iloc[:,2:].values.reshape(-1,28,28,1).astype(np.float32)  \n",
    "x_test -= mu \n",
    "x_test /= sd \n",
    "test_letters = test.iloc[:,1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 28, 28, 1), (2048, 10), (20480, 28, 28, 1), (2048, 26), (20480, 26))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letters_numeric = [] \n",
    "test_letters_numeric = [] \n",
    "for letter in train_letters: \n",
    "    train_letters_numeric.append(ord(letter) - ord(\"A\"))\n",
    "for letter in test_letters: \n",
    "    test_letters_numeric.append(ord(letter) - ord(\"A\")) \n",
    "    \n",
    "train_letters_numeric = np.asarray(train_letters_numeric) \n",
    "test_letters_numeric = np.asarray(test_letters_numeric) \n",
    "\n",
    "train_letters_numeric = to_categorical(train_letters_numeric, num_classes = 26) \n",
    "test_letters_numeric = to_categorical(test_letters_numeric, num_classes = 26)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, train_letters_numeric.shape, test_letters_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running simple stacking ensemble (weak HAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 100), (20480, 100), (2048, 100), (20480, 100))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_x_train = np.load('./storage/meta_x_train.npy') \n",
    "meta_x_test = np.load('./storage/meta_x_test.npy') \n",
    "meta_x_train_grade_4 = np.load('./storage/meta_x_train_grade_4.npy')\n",
    "meta_x_test_grade_4 = np.load('./storage/meta_x_test_grade_4.npy')\n",
    "meta_x_train.shape, meta_x_test.shape, meta_x_train_grade_4.shape, meta_x_test_grade_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_x_train = np.concatenate([meta_x_train, meta_x_train_grade_4], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_x_test = np.concatenate([meta_x_test, meta_x_test_grade_4],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize for better performance \n",
    "mu = np.mean(meta_x_train) \n",
    "sd = np.std(meta_x_train)  \n",
    "\n",
    "meta_x_train -= mu \n",
    "meta_x_train /= sd \n",
    "\n",
    "meta_x_test -= mu \n",
    "meta_x_test /= sd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_model(): \n",
    "    inputs = Input((200,))\n",
    "    dense = Dense(256, activation = 'relu')(inputs)  \n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(128, activation = 'relu')(dense)  \n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dense(64, activation = 'relu')(dense)  \n",
    "    dense = BatchNormalization()(dense)\n",
    "    outputs = Dense(10, activation = 'softmax')(dense) \n",
    "    model = Model(inputs = inputs, outputs = outputs) \n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy']) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1843 samples, validate on 205 samples\n",
      "Epoch 1/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 0.0081 - accuracy: 0.9444\n",
      "Epoch 00001: val_loss improved from inf to 0.00237, saving model to ./storage/dense_net/split/epoch_001_val_0.002_acc_1.000.h5\n",
      "1843/1843 [==============================] - 2s 1ms/sample - loss: 0.0076 - accuracy: 0.9479 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 9.6501e-05 - accuracy: 1.0000\n",
      "Epoch 00002: val_loss improved from 0.00237 to 0.00029, saving model to ./storage/dense_net/split/epoch_002_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 232us/sample - loss: 9.2151e-05 - accuracy: 1.0000 - val_loss: 2.8536e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 6.4028e-05 - accuracy: 1.0000\n",
      "Epoch 00003: val_loss improved from 0.00029 to 0.00006, saving model to ./storage/dense_net/split/epoch_003_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 244us/sample - loss: 6.4030e-05 - accuracy: 1.0000 - val_loss: 5.8541e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 3.7844e-05 - accuracy: 1.0000\n",
      "Epoch 00004: val_loss improved from 0.00006 to 0.00002, saving model to ./storage/dense_net/split/epoch_004_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 257us/sample - loss: 3.7896e-05 - accuracy: 1.0000 - val_loss: 1.6300e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 3.2444e-05 - accuracy: 1.0000\n",
      "Epoch 00005: val_loss improved from 0.00002 to 0.00001, saving model to ./storage/dense_net/split/epoch_005_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 237us/sample - loss: 3.2971e-05 - accuracy: 1.0000 - val_loss: 7.5084e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 1.7630e-05 - accuracy: 1.0000\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00001 to 0.00000, saving model to ./storage/dense_net/split/epoch_006_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 246us/sample - loss: 1.8428e-05 - accuracy: 1.0000 - val_loss: 3.8729e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 1.5055e-05 - accuracy: 1.0000\n",
      "Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_007_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 235us/sample - loss: 1.7282e-05 - accuracy: 1.0000 - val_loss: 2.5170e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 1.2445e-05 - accuracy: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_008_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 241us/sample - loss: 1.3136e-05 - accuracy: 1.0000 - val_loss: 1.8192e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 1.0143e-05 - accuracy: 1.0000\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_009_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 1.1120e-05 - accuracy: 1.0000 - val_loss: 1.3435e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 1.1025e-05 - accuracy: 1.0000\n",
      "Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_010_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 1.0719e-05 - accuracy: 1.0000 - val_loss: 1.0709e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 1.0289e-05 - accuracy: 1.0000\n",
      "Epoch 00011: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_011_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 227us/sample - loss: 1.0675e-05 - accuracy: 1.0000 - val_loss: 9.7380e-07 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 9.3905e-06 - accuracy: 1.0000\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_012_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 267us/sample - loss: 9.9090e-06 - accuracy: 1.0000 - val_loss: 8.5420e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 8.3101e-06 - accuracy: 1.0000\n",
      "Epoch 00013: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_013_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 249us/sample - loss: 8.2273e-06 - accuracy: 1.0000 - val_loss: 7.8210e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 6.2736e-06 - accuracy: 1.0000\n",
      "Epoch 00014: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_014_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 1s 276us/sample - loss: 7.8866e-06 - accuracy: 1.0000 - val_loss: 7.1622e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1696/1843 [==========================>...] - ETA: 0s - loss: 7.7385e-06 - accuracy: 1.0000\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_015_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 246us/sample - loss: 1.2966e-05 - accuracy: 1.0000 - val_loss: 6.4608e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 8.4432e-06 - accuracy: 1.0000\n",
      "Epoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_016_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 231us/sample - loss: 8.5460e-06 - accuracy: 1.0000 - val_loss: 6.2049e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 6.8454e-06 - accuracy: 1.0000\n",
      "Epoch 00017: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_017_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 244us/sample - loss: 6.7995e-06 - accuracy: 1.0000 - val_loss: 5.5261e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 4.9077e-06 - accuracy: 1.0000\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_018_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 246us/sample - loss: 4.8522e-06 - accuracy: 1.0000 - val_loss: 5.2658e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 5.7425e-06 - accuracy: 1.0000\n",
      "Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_019_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 226us/sample - loss: 5.8356e-06 - accuracy: 1.0000 - val_loss: 4.9815e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 5.3092e-06 - accuracy: 1.0000\n",
      "Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_020_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 224us/sample - loss: 5.3912e-06 - accuracy: 1.0000 - val_loss: 4.6006e-07 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 4.6514e-06 - accuracy: 1.0000\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_021_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 238us/sample - loss: 5.1860e-06 - accuracy: 1.0000 - val_loss: 4.4573e-07 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 4.4118e-06 - accuracy: 1.0000\n",
      "Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_022_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 257us/sample - loss: 4.7305e-06 - accuracy: 1.0000 - val_loss: 4.1447e-07 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 5.3958e-06 - accuracy: 1.0000\n",
      "Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_023_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 245us/sample - loss: 5.4370e-06 - accuracy: 1.0000 - val_loss: 4.0649e-07 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 5.2243e-06 - accuracy: 1.0000\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_024_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 255us/sample - loss: 5.2268e-06 - accuracy: 1.0000 - val_loss: 3.8968e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 4.6421e-06 - accuracy: 1.0000\n",
      "Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_025_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 252us/sample - loss: 4.6602e-06 - accuracy: 1.0000 - val_loss: 3.7570e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 3.8360e-06 - accuracy: 1.0000\n",
      "Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_026_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 243us/sample - loss: 4.5590e-06 - accuracy: 1.0000 - val_loss: 3.6451e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.5223e-06 - accuracy: 1.0000\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_027_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 232us/sample - loss: 3.6057e-06 - accuracy: 1.0000 - val_loss: 3.4822e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 4.8484e-06 - accuracy: 1.0000\n",
      "Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_028_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 4.8220e-06 - accuracy: 1.0000 - val_loss: 3.3911e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 4.9826e-06 - accuracy: 1.0000\n",
      "Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_029_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 246us/sample - loss: 4.9721e-06 - accuracy: 1.0000 - val_loss: 3.2593e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 3.5223e-06 - accuracy: 1.0000\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_030_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 247us/sample - loss: 3.7162e-06 - accuracy: 1.0000 - val_loss: 3.1704e-07 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 3.7789e-06 - accuracy: 1.0000\n",
      "Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_031_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 239us/sample - loss: 3.7570e-06 - accuracy: 1.0000 - val_loss: 3.0685e-07 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 3.5322e-06 - accuracy: 1.0000\n",
      "Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_032_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 248us/sample - loss: 3.6317e-06 - accuracy: 1.0000 - val_loss: 3.0355e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 3.1918e-06 - accuracy: 1.0000\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_033_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 248us/sample - loss: 3.2518e-06 - accuracy: 1.0000 - val_loss: 2.9899e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 3.4229e-06 - accuracy: 1.0000\n",
      "Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_034_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 227us/sample - loss: 3.4564e-06 - accuracy: 1.0000 - val_loss: 2.9523e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 3.1564e-06 - accuracy: 1.0000\n",
      "Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_035_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 3.1332e-06 - accuracy: 1.0000 - val_loss: 2.9034e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 4.6478e-06 - accuracy: 1.0000\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_036_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 263us/sample - loss: 4.7196e-06 - accuracy: 1.0000 - val_loss: 2.8631e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1696/1843 [==========================>...] - ETA: 0s - loss: 3.1616e-06 - accuracy: 1.0000\n",
      "Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_037_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 258us/sample - loss: 3.0322e-06 - accuracy: 1.0000 - val_loss: 2.8570e-07 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 3.3443e-06 - accuracy: 1.0000\n",
      "Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_038_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 239us/sample - loss: 3.2985e-06 - accuracy: 1.0000 - val_loss: 2.7915e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 4.5956e-06 - accuracy: 1.0000\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_039_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 238us/sample - loss: 4.3095e-06 - accuracy: 1.0000 - val_loss: 2.7287e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 2.6869e-06 - accuracy: 1.0000\n",
      "Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_040_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 239us/sample - loss: 2.8435e-06 - accuracy: 1.0000 - val_loss: 2.7182e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 2.9981e-06 - accuracy: 1.0000\n",
      "Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_041_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 240us/sample - loss: 3.2313e-06 - accuracy: 1.0000 - val_loss: 2.6799e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 2.8405e-06 - accuracy: 1.0000\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_042_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 2.8491e-06 - accuracy: 1.0000 - val_loss: 2.6541e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 3.0303e-06 - accuracy: 1.0000\n",
      "Epoch 00043: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 198us/sample - loss: 2.9799e-06 - accuracy: 1.0000 - val_loss: 2.6597e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 3.7210e-06 - accuracy: 1.0000\n",
      "Epoch 00044: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 192us/sample - loss: 3.5215e-06 - accuracy: 1.0000 - val_loss: 2.6901e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.3550e-06 - accuracy: 1.0000\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 186us/sample - loss: 3.1147e-06 - accuracy: 1.0000 - val_loss: 2.6688e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 3.5204e-06 - accuracy: 1.0000\n",
      "Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_046_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 3.5017e-06 - accuracy: 1.0000 - val_loss: 2.6263e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 2.9267e-06 - accuracy: 1.0000\n",
      "Epoch 00047: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_047_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 234us/sample - loss: 3.1468e-06 - accuracy: 1.0000 - val_loss: 2.5743e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 2.7216e-06 - accuracy: 1.0000\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 193us/sample - loss: 2.6127e-06 - accuracy: 1.0000 - val_loss: 2.5826e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 3.7800e-06 - accuracy: 1.0000\n",
      "Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_049_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 249us/sample - loss: 3.7156e-06 - accuracy: 1.0000 - val_loss: 2.5392e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 2.6187e-06 - accuracy: 1.0000\n",
      "Epoch 00050: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 191us/sample - loss: 2.6671e-06 - accuracy: 1.0000 - val_loss: 2.5606e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 3.7504e-06 - accuracy: 1.0000\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_051_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 236us/sample - loss: 3.9262e-06 - accuracy: 1.0000 - val_loss: 2.4664e-07 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.1905e-06 - accuracy: 1.0000\n",
      "Epoch 00052: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 190us/sample - loss: 3.0452e-06 - accuracy: 1.0000 - val_loss: 2.4851e-07 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 2.5907e-06 - accuracy: 1.0000\n",
      "Epoch 00053: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 203us/sample - loss: 2.5319e-06 - accuracy: 1.0000 - val_loss: 2.4793e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1696/1843 [==========================>...] - ETA: 0s - loss: 2.7634e-06 - accuracy: 1.0000\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_054_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 1s 273us/sample - loss: 2.7396e-06 - accuracy: 1.0000 - val_loss: 2.4367e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 3.0941e-06 - accuracy: 1.0000\n",
      "Epoch 00055: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 193us/sample - loss: 3.1545e-06 - accuracy: 1.0000 - val_loss: 2.4594e-07 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 2.6103e-06 - accuracy: 1.0000\n",
      "Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_056_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 239us/sample - loss: 2.7199e-06 - accuracy: 1.0000 - val_loss: 2.4302e-07 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 2.4653e-06 - accuracy: 1.0000\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_057_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 226us/sample - loss: 2.4679e-06 - accuracy: 1.0000 - val_loss: 2.3660e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 4.3356e-06 - accuracy: 1.0000\n",
      "Epoch 00058: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 192us/sample - loss: 4.0392e-06 - accuracy: 1.0000 - val_loss: 2.3778e-07 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 2.4701e-06 - accuracy: 1.0000\n",
      "Epoch 00059: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 187us/sample - loss: 2.5990e-06 - accuracy: 1.0000 - val_loss: 2.3764e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 3.0259e-06 - accuracy: 1.0000\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_060_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 240us/sample - loss: 2.8887e-06 - accuracy: 1.0000 - val_loss: 2.3610e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 5.8905e-06 - accuracy: 1.0000\n",
      "Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_061_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 240us/sample - loss: 5.6047e-06 - accuracy: 1.0000 - val_loss: 2.3015e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 3.9539e-06 - accuracy: 1.0000\n",
      "Epoch 00062: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 204us/sample - loss: 3.8155e-06 - accuracy: 1.0000 - val_loss: 2.3038e-07 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 3.3091e-06 - accuracy: 1.0000\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_063_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 248us/sample - loss: 3.4738e-06 - accuracy: 1.0000 - val_loss: 2.2552e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 2.6051e-06 - accuracy: 1.0000\n",
      "Epoch 00064: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 200us/sample - loss: 2.5980e-06 - accuracy: 1.0000 - val_loss: 2.2634e-07 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.1932e-06 - accuracy: 1.0000\n",
      "Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_065_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 246us/sample - loss: 3.2112e-06 - accuracy: 1.0000 - val_loss: 2.2411e-07 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 2.5920e-06 - accuracy: 1.0000\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 194us/sample - loss: 2.5963e-06 - accuracy: 1.0000 - val_loss: 2.2787e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 3.8267e-06 - accuracy: 1.0000\n",
      "Epoch 00067: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 196us/sample - loss: 3.8157e-06 - accuracy: 1.0000 - val_loss: 2.2431e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.2391e-06 - accuracy: 1.0000\n",
      "Epoch 00068: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 191us/sample - loss: 3.1537e-06 - accuracy: 1.0000 - val_loss: 2.2564e-07 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 2.1973e-06 - accuracy: 1.0000\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 188us/sample - loss: 2.5805e-06 - accuracy: 1.0000 - val_loss: 2.2565e-07 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1792/1843 [============================>.] - ETA: 0s - loss: 2.7356e-06 - accuracy: 1.0000\n",
      "Epoch 00070: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_070_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 245us/sample - loss: 2.7073e-06 - accuracy: 1.0000 - val_loss: 2.2404e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 2.7191e-06 - accuracy: 1.0000\n",
      "Epoch 00071: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 190us/sample - loss: 2.6022e-06 - accuracy: 1.0000 - val_loss: 2.2570e-07 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1632/1843 [=========================>....] - ETA: 0s - loss: 2.3684e-06 - accuracy: 1.0000\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 186us/sample - loss: 2.3835e-06 - accuracy: 1.0000 - val_loss: 2.2725e-07 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.0520e-06 - accuracy: 1.0000\n",
      "Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_073_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 234us/sample - loss: 2.8980e-06 - accuracy: 1.0000 - val_loss: 2.2268e-07 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 3.2614e-06 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_074_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 238us/sample - loss: 3.1603e-06 - accuracy: 1.0000 - val_loss: 2.2211e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1728/1843 [===========================>..] - ETA: 0s - loss: 2.9023e-06 - accuracy: 1.0000\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 208us/sample - loss: 2.8107e-06 - accuracy: 1.0000 - val_loss: 2.2509e-07 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 2.5123e-06 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_076_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 240us/sample - loss: 2.6577e-06 - accuracy: 1.0000 - val_loss: 2.2123e-07 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1664/1843 [==========================>...] - ETA: 0s - loss: 2.4853e-06 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_077_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 261us/sample - loss: 2.5937e-06 - accuracy: 1.0000 - val_loss: 2.1913e-07 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 2.4260e-06 - accuracy: 1.0000\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 191us/sample - loss: 2.4940e-06 - accuracy: 1.0000 - val_loss: 2.1976e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 3.8248e-06 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 202us/sample - loss: 4.0853e-06 - accuracy: 1.0000 - val_loss: 2.2220e-07 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 3.6291e-06 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 190us/sample - loss: 3.5626e-06 - accuracy: 1.0000 - val_loss: 2.2253e-07 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 2.6062e-06 - accuracy: 1.0000\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.0223149224184457e-06.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to ./storage/dense_net/split/epoch_081_val_0.000_acc_1.000.h5\n",
      "1843/1843 [==============================] - 0s 241us/sample - loss: 2.7073e-06 - accuracy: 1.0000 - val_loss: 2.1719e-07 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1536/1843 [========================>.....] - ETA: 0s - loss: 2.6822e-06 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 191us/sample - loss: 2.5663e-06 - accuracy: 1.0000 - val_loss: 2.2014e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1568/1843 [========================>.....] - ETA: 0s - loss: 2.8680e-06 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 190us/sample - loss: 2.9592e-06 - accuracy: 1.0000 - val_loss: 2.2251e-07 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 2.4288e-06 - accuracy: 1.0000\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 2.4178520106943328e-06.\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 189us/sample - loss: 2.6933e-06 - accuracy: 1.0000 - val_loss: 2.2112e-07 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1600/1843 [=========================>....] - ETA: 0s - loss: 2.9170e-06 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 187us/sample - loss: 2.8491e-06 - accuracy: 1.0000 - val_loss: 2.2494e-07 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1664/1843 [==========================>...] - ETA: 0s - loss: 2.1517e-06 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 178us/sample - loss: 2.1994e-06 - accuracy: 1.0000 - val_loss: 2.2666e-07 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 2.7000e-06 - accuracy: 1.0000\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.9342816813150422e-06.\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 199us/sample - loss: 2.6793e-06 - accuracy: 1.0000 - val_loss: 2.2793e-07 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 2.8167e-06 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 198us/sample - loss: 2.8079e-06 - accuracy: 1.0000 - val_loss: 2.2633e-07 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1824/1843 [============================>.] - ETA: 0s - loss: 2.6318e-06 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 189us/sample - loss: 2.6146e-06 - accuracy: 1.0000 - val_loss: 2.2605e-07 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 2.5373e-06 - accuracy: 1.0000\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.547425381431822e-06.\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 202us/sample - loss: 2.7663e-06 - accuracy: 1.0000 - val_loss: 2.2068e-07 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1760/1843 [===========================>..] - ETA: 0s - loss: 2.2184e-06 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 0.00000\n",
      "1843/1843 [==============================] - 0s 204us/sample - loss: 2.3242e-06 - accuracy: 1.0000 - val_loss: 2.2299e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2dd04cb438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = meta_model()\n",
    "model_path = './storage/dense_net/split/epoch_{epoch:03d}_val_{val_loss:.3f}_acc_{val_accuracy:.3f}.h5' \n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.8)\n",
    "checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_loss',verbose=1,save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "model.fit(meta_x_train, y_train, validation_split = 0.1, shuffle=True, epochs = 100, \n",
    "          callbacks=[learning_rate_reduction,checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               51456     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 95,050\n",
      "Trainable params: 94,154\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "han = load_model('./storage/dense_net/split/epoch_081_val_0.000_acc_1.000.h5')\n",
    "han.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = han.predict(meta_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 8, ..., 6, 8, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_arr = [] \n",
    "for p in pred: \n",
    "    result_arr.append(np.argmax(p))\n",
    "result_arr = np.asarray(result_arr)\n",
    "result_arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  digit\n",
       "0  2049      6\n",
       "1  2050      9\n",
       "2  2051      8\n",
       "3  2052      0\n",
       "4  2053      3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['digit'] = result_arr \n",
    "submission.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./storage/weak_han_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
